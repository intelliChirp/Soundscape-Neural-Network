{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, Activation\n",
    "from keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('ant_cnn_model_all_smote.h5')\n",
    "\n",
    "# Summarize the model\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = loaded_model.predict(X_test)  # shape=(n_samples, 12)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=y_pred_labels)  # shape\n",
    "print(confusion_matrix)\n",
    "sum_avg = 0\n",
    "for class_i in range(len(labels)) :\n",
    "    indices = np.argwhere(y_test == class_i)\n",
    "    sum = 0\n",
    "    for index in indices:\n",
    "        sum += (y_test[index] == y_pred_labels[index])\n",
    "    if(len(indices) > 0) : mean = sum/len(indices)\n",
    "    else : mean = \"N/A\"\n",
    "    sum_avg += mean\n",
    "    print(\"Accuracy for class\", labels[class_i], \":\", mean)\n",
    "avg_mean = sum / len(labels)\n",
    "    \n",
    "print(\"Overall Accuracy :\", np.mean(y_test == y_pred_labels))\n",
    "print(\"Average Accuracy\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion_matrix, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "#ax.set_xticklabels([''] + labels)\n",
    "#ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, zero_one_loss\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "zero1loss = zero_one_loss(y_true=y_test, y_pred=y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_bool))\n",
    "print(\"Zero one loss\", zero1loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(labels)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_labels, pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "#fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred_labels.ravel())\n",
    "#roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "lw = 2\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(len(labels)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='class {0} (area = {1:0.2f})'\n",
    "             ''.format(labels[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the model\n",
    "\n",
    "n_mfcc = config.buckets\n",
    "max_len = config.max_len\n",
    "# convert file to wav2mfcc\n",
    "# Mel-frequency cepstral coefficients\n",
    "file_path = \"./prediction/nature_sc.wav\"\n",
    "big_wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "#print(wave.shape, sr)\n",
    "\n",
    "classification = []\n",
    "\n",
    "for sec_index in range( int(big_wave.shape[0] / sr) ) :\n",
    "    start_sec = sec_index\n",
    "    end_sec = sec_index + 1\n",
    "    \n",
    "    sec_to_trim = np.array( [ float(start_sec), float(end_sec) ] )\n",
    "    print(sec_to_trim)\n",
    "    sec_to_trim = np.ceil( sec_to_trim * sr )\n",
    "\n",
    "    wave = big_wave[int(sec_to_trim[0]) : int(sec_to_trim[1])]\n",
    "    print(wave)\n",
    "\n",
    "    wave = np.asfortranarray(wave[::3])\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    # Convert wav to MFCC\n",
    "    prediction_data = wav2mfcc('./prediction/nature_sc.wav')\n",
    "    prediction_data = mfcc\n",
    "    print(prediction_data.shape)\n",
    "    #print(wav2mfcc())\n",
    "    # Reshape to 4 dimensions\n",
    "    prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
    "    #prediction_data = prediction_data.reshape(1, 20, config.max_len, channels)\n",
    "\n",
    "    # Run the model on the inputted file\n",
    "    predicted = loaded_model.predict(prediction_data)\n",
    "\n",
    "    # Output the prediction values for each class\n",
    "    print ('PREDICTED VALUES')\n",
    "    labels_indices = range(len(labels))\n",
    "    max_value = 0\n",
    "    max_value_index = 0\n",
    "    for index in labels_indices:\n",
    "        print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
    "        if predicted[0,index] > max_value:\n",
    "            max_value_index = index\n",
    "            max_value = predicted[0,index]\n",
    "\n",
    "    # Output the prediction\n",
    "    if max_value < 0.5:\n",
    "        print(\"GUESS: Nothing\")\n",
    "        classification.append( { \"class\" : \"Nothing\", \"timestamp\" : start_sec } )\n",
    "    else:\n",
    "        print('\\n\\nGUESS: ', labels[max_value_index])\n",
    "        classification.append( { \"class\" : labels[max_value_index], \"timestamp\" : start_sec } )\n",
    "\n",
    "print(classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
