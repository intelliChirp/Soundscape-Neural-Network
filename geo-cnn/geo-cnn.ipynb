{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized/runs/k70rvi7p\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized/runs/k70rvi7p</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "Saving vectors of label - 'crackling_fire': 100%|██████████████████████████████████████| 40/40 [00:01<00:00, 23.58it/s]\n",
      "Saving vectors of label - 'helicopter': 100%|██████████████████████████████████████████| 40/40 [00:01<00:00, 25.01it/s]\n",
      "Saving vectors of label - 'rain': 100%|████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.18it/s]\n",
      "Saving vectors of label - 'thunderstorm': 100%|████████████████████████████████████████| 40/40 [00:01<00:00, 26.40it/s]\n",
      "Saving vectors of label - 'wind': 100%|████████████████████████████████████████████████| 40/40 [00:01<00:00, 27.30it/s]\n"
     ]
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "config.max_len = 11\n",
    "config.buckets = 20\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
    "\n",
    "labels=[\"crackling_fire\", \"helicopter\", \"rain\", \"thunderstorm\", \"wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    }
   ],
   "source": [
    "# Setting channels to 1 to generalize stereo sound to 1 channel\n",
    "channels = 1\n",
    "config.epochs = 50\n",
    "config.batch_size = 100\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 5\n",
    "\n",
    "# Reshape X_train and X_test to include a 4th dimension (channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spectrogram visualized of 0th element\n",
    "plt.imshow(X_train[1, :, :, 0])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting vector number where each number corresponds to a label\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "\n",
    "# Conv2D: \n",
    "#    Filters: 32\n",
    "#    Kernel_size: (3,3) (height/width of the 2D convolution window)     \n",
    "model.add(Conv2D(32, (3, 3),\n",
    "    input_shape=(config.buckets, config.max_len, channels),\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure CNN for training\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized/runs/1lhfwpdp\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized/runs/1lhfwpdp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 33.5508 - accuracy: 0.125 - 0s 2ms/step - loss: 18.1951 - accuracy: 0.1833 - val_loss: 10.3962 - val_accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 17.4644 - accuracy: 0.250 - 0s 472us/step - loss: 8.6679 - accuracy: 0.4583 - val_loss: 4.0171 - val_accuracy: 0.3625\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 2.5825 - accuracy: 0.53 - 0s 519us/step - loss: 3.3282 - accuracy: 0.5583 - val_loss: 5.4318 - val_accuracy: 0.4625\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 4.2256 - accuracy: 0.62 - 0s 599us/step - loss: 2.1849 - accuracy: 0.6417 - val_loss: 4.0702 - val_accuracy: 0.4625\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.8456 - accuracy: 0.59 - 0s 648us/step - loss: 1.7867 - accuracy: 0.6667 - val_loss: 2.7362 - val_accuracy: 0.5125\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.3590 - accuracy: 0.68 - 0s 697us/step - loss: 1.0915 - accuracy: 0.7500 - val_loss: 2.6797 - val_accuracy: 0.5875\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.3637 - accuracy: 0.75 - 0s 669us/step - loss: 1.0301 - accuracy: 0.7833 - val_loss: 2.0103 - val_accuracy: 0.6250\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.8696 - accuracy: 0.75 - 0s 583us/step - loss: 0.5904 - accuracy: 0.8250 - val_loss: 1.7943 - val_accuracy: 0.5625\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.81 - 0s 719us/step - loss: 0.4340 - accuracy: 0.8500 - val_loss: 2.0257 - val_accuracy: 0.5875\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.90 - 0s 540us/step - loss: 0.4555 - accuracy: 0.9000 - val_loss: 1.9874 - val_accuracy: 0.5875\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.90 - 0s 522us/step - loss: 0.2692 - accuracy: 0.9417 - val_loss: 1.6319 - val_accuracy: 0.5625\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.90 - 0s 637us/step - loss: 0.2545 - accuracy: 0.9167 - val_loss: 1.5142 - val_accuracy: 0.6250\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 1.00 - 0s 538us/step - loss: 0.1525 - accuracy: 0.9750 - val_loss: 1.7884 - val_accuracy: 0.5750\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.90 - 0s 459us/step - loss: 0.1651 - accuracy: 0.9417 - val_loss: 1.5603 - val_accuracy: 0.6375\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.96 - 0s 482us/step - loss: 0.0835 - accuracy: 0.9917 - val_loss: 1.4115 - val_accuracy: 0.6750\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 1.00 - 0s 487us/step - loss: 0.0952 - accuracy: 0.9750 - val_loss: 1.4902 - val_accuracy: 0.6125\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 1.00 - 0s 487us/step - loss: 0.0658 - accuracy: 0.9917 - val_loss: 1.5738 - val_accuracy: 0.5875\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 1.00 - 0s 496us/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 1.8580 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 1.00 - 0s 560us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 1.6093 - val_accuracy: 0.6500\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 1.00 - 0s 488us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.4074 - val_accuracy: 0.6625\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 1.00 - 0s 557us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.5700 - val_accuracy: 0.6375\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.00 - 0s 489us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.6343 - val_accuracy: 0.6250\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 470us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.6625\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - 0s 504us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.4808 - val_accuracy: 0.6625\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 1.00 - 0s 559us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.5529 - val_accuracy: 0.6750\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 550us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.6750\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 567us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.4762 - val_accuracy: 0.6375\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.00 - 0s 510us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.5035 - val_accuracy: 0.6500\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - 0s 624us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.5444 - val_accuracy: 0.6750\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 575us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.5185 - val_accuracy: 0.6875\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 1.00 - 0s 747us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.4934 - val_accuracy: 0.6750\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.00 - 0s 423us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.4942 - val_accuracy: 0.6750\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 521us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.6750\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 506us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.5412 - val_accuracy: 0.6750\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 513us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.5457 - val_accuracy: 0.6750\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.00 - 0s 563us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.5149 - val_accuracy: 0.6750\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 475us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.4925 - val_accuracy: 0.6625\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 542us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.5301 - val_accuracy: 0.6750\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 495us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.5482 - val_accuracy: 0.6750\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.00 - 0s 613us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.5142 - val_accuracy: 0.6500\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 305us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.5218 - val_accuracy: 0.6625\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 509us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.6875\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 650us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.5745 - val_accuracy: 0.6875\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 387us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.5305 - val_accuracy: 0.6625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 492us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.5451 - val_accuracy: 0.6750\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 600us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.5218 - val_accuracy: 0.6750\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 382us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5415 - val_accuracy: 0.6750\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 454us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5488 - val_accuracy: 0.6750\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 771us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5506 - val_accuracy: 0.6750\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 542us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.6750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1da2d108208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "\n",
    "# Train the CNN model\n",
    "#    X_train: Input data\n",
    "#    y_train_hot: Target data\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_test, y_test_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the keras model\n",
    "model.save(\"geo_cnn_model.h5\")\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the IntelliChirp Biophony CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('geo_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 18, 9, 32)         320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 148,549\n",
      "Trainable params: 148,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED VALUES\n",
      "\n",
      " crackling_fire :  0.42179796\n",
      "\n",
      " helicopter :  0.00178161\n",
      "\n",
      " rain :  0.00269044\n",
      "\n",
      " thunderstorm :  0.57372999\n",
      "\n",
      " wind :  0.00000001\n",
      "\n",
      "\n",
      "GUESS:  thunderstorm\n",
      "[4.2179796e-01 1.7816082e-03 2.6904407e-03 5.7372999e-01 1.4333640e-08]\n"
     ]
    }
   ],
   "source": [
    "## Running the model\n",
    "\n",
    "# Convert wav to MFCC\n",
    "prediction_data = wav2mfcc('./prediction/wind.wav')\n",
    "\n",
    "# Reshape to 4 dimensions\n",
    "prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
    "\n",
    "# Run the model on the inputted file\n",
    "predicted = loaded_model.predict(prediction_data)\n",
    "\n",
    "# Output the prediction values for each class\n",
    "print ('PREDICTED VALUES')\n",
    "labels_indices = range(len(labels))\n",
    "max_value = 0\n",
    "max_value_index = 0\n",
    "for index in labels_indices:\n",
    "    print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
    "    if predicted[0,index] > max_value:\n",
    "        max_value_index = index\n",
    "        max_value = predicted[0,index]\n",
    "\n",
    "# Output the prediction\n",
    "if max_value < 0.5:\n",
    "    print(\"GUESS: Nothing\")\n",
    "else:\n",
    "    print('\\n\\nGUESS: ', labels[max_value_index])\n",
    "    \n",
    "print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggleNotebook",
   "language": "python",
   "name": "kagglenotebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
