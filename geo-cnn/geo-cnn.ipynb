{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, Activation\n",
    "from keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1p0xwnhq\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1p0xwnhq</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'GOC': 100%|█████████████████████████████████████████████████| 15/15 [00:00<00:00, 28.56it/s]\n",
      "Saving vectors of label - 'GRA': 100%|███████████████████████████████████████████████| 133/133 [00:03<00:00, 40.92it/s]\n",
      "Saving vectors of label - 'GST': 100%|█████████████████████████████████████████████████| 20/20 [00:00<00:00, 76.07it/s]\n",
      "Saving vectors of label - 'GWC': 100%|███████████████████████████████████████████████| 100/100 [00:01<00:00, 59.24it/s]\n",
      "Saving vectors of label - 'GWG': 100%|█████████████████████████████████████████████████| 52/52 [00:01<00:00, 37.26it/s]\n"
     ]
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "config.max_len = 21\n",
    "config.buckets = 50\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
    "\n",
    "#labels=np.array([\"chirping_birds\", \"crickets\", \"crow\", \n",
    "#                 \"frog\", \"insects\"])\n",
    "labels=np.array([\"GOC\", \"GRA\", \"GST\", \n",
    "                 \"GWG\", \"GWC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test set\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting channels to 1 to generalize stereo sound to 1 channel\n",
    "channels = 1\n",
    "config.epochs = 50\n",
    "config.batch_size = 100\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 5\n",
    "\n",
    "# Reshape X_train and X_test to include a 4th dimension (channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len, channels)\n",
    "X_val = X_val.reshape(X_val.shape[0], config.buckets, config.max_len, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 50, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "# Spectrogram visualized of 0th element\n",
    "print(X_train.shape)\n",
    "#plt.imshow(X_train[500, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting vector number where each number corresponds to a label\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_val_hot = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 19, 24)        240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 7, 48)         10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 3, 48)          6960      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 100,949\n",
      "Trainable params: 100,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"model.add(Conv2D(32, (3, 3),\\n    input_shape=(config.buckets, config.max_len, channels),\\n    activation='relu'))\\n\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n\\nmodel.add(Flatten())\\n\\nmodel.add(Dense(128, activation='relu'))\\nmodel.add(Dense(num_classes, activation='softmax'))\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape= (config.buckets, config.max_len, channels)\n",
    "\n",
    "model.add(Conv2D(24, (3, 3), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(len(labels)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "# Conv2D: \n",
    "#    Filters: 32\n",
    "#    Kernel_size: (3,3) (height/width of the 2D convolution window)     \n",
    "'''model.add(Conv2D(32, (3, 3),\n",
    "    input_shape=(config.buckets, config.max_len, channels),\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure CNN for training\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/2vo4ed9m\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/2vo4ed9m</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 5)\n",
      "(5,)\n",
      "(153, 50, 21, 1)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 153 samples, validate on 103 samples\n",
      "Epoch 1/50\n",
      "153/153 [==============================] - ETA: 4s - loss: 6.3866 - accuracy: 0.25 - ETA: 1s - loss: 5.2013 - accuracy: 0.32 - ETA: 0s - loss: 4.6251 - accuracy: 0.32 - 1s 10ms/step - loss: 3.9702 - accuracy: 0.3137 - val_loss: 1.6140 - val_accuracy: 0.4466\n",
      "Epoch 2/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 2.3227 - accuracy: 0.37 - ETA: 0s - loss: 2.1149 - accuracy: 0.35 - ETA: 0s - loss: 2.0037 - accuracy: 0.36 - 0s 2ms/step - loss: 2.0069 - accuracy: 0.3529 - val_loss: 1.3922 - val_accuracy: 0.4078\n",
      "Epoch 3/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.5084 - accuracy: 0.43 - ETA: 0s - loss: 1.4560 - accuracy: 0.45 - ETA: 0s - loss: 1.4355 - accuracy: 0.46 - 0s 2ms/step - loss: 1.4195 - accuracy: 0.4837 - val_loss: 1.3732 - val_accuracy: 0.4078\n",
      "Epoch 4/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.4537 - accuracy: 0.43 - ETA: 0s - loss: 1.3506 - accuracy: 0.43 - ETA: 0s - loss: 1.4725 - accuracy: 0.39 - 0s 2ms/step - loss: 1.4542 - accuracy: 0.4118 - val_loss: 1.3443 - val_accuracy: 0.4078\n",
      "Epoch 5/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.3869 - accuracy: 0.40 - ETA: 0s - loss: 1.4816 - accuracy: 0.40 - ETA: 0s - loss: 1.4119 - accuracy: 0.42 - 0s 2ms/step - loss: 1.4027 - accuracy: 0.4314 - val_loss: 1.3292 - val_accuracy: 0.4757\n",
      "Epoch 6/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.3862 - accuracy: 0.46 - ETA: 0s - loss: 1.3544 - accuracy: 0.46 - ETA: 0s - loss: 1.3542 - accuracy: 0.47 - 0s 2ms/step - loss: 1.3211 - accuracy: 0.4706 - val_loss: 1.3037 - val_accuracy: 0.4466\n",
      "Epoch 7/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.3200 - accuracy: 0.34 - ETA: 0s - loss: 1.3224 - accuracy: 0.42 - 0s 1ms/step - loss: 1.2395 - accuracy: 0.4837 - val_loss: 1.2936 - val_accuracy: 0.4369\n",
      "Epoch 8/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.3623 - accuracy: 0.50 - ETA: 0s - loss: 1.3141 - accuracy: 0.46 - ETA: 0s - loss: 1.2266 - accuracy: 0.51 - 0s 1ms/step - loss: 1.2209 - accuracy: 0.5163 - val_loss: 1.2187 - val_accuracy: 0.5146\n",
      "Epoch 9/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.1934 - accuracy: 0.34 - ETA: 0s - loss: 1.1643 - accuracy: 0.39 - 0s 1ms/step - loss: 1.1357 - accuracy: 0.4575 - val_loss: 1.1976 - val_accuracy: 0.5049\n",
      "Epoch 10/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.56 - ETA: 0s - loss: 1.1591 - accuracy: 0.54 - ETA: 0s - loss: 1.1097 - accuracy: 0.58 - 0s 2ms/step - loss: 1.0830 - accuracy: 0.5882 - val_loss: 1.1705 - val_accuracy: 0.5340\n",
      "Epoch 11/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.2887 - accuracy: 0.37 - ETA: 0s - loss: 1.0803 - accuracy: 0.45 - ETA: 0s - loss: 1.1370 - accuracy: 0.45 - 0s 1ms/step - loss: 1.1050 - accuracy: 0.5033 - val_loss: 1.1343 - val_accuracy: 0.5728\n",
      "Epoch 12/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.2405 - accuracy: 0.40 - ETA: 0s - loss: 1.1210 - accuracy: 0.46 - ETA: 0s - loss: 1.1123 - accuracy: 0.50 - ETA: 0s - loss: 1.0951 - accuracy: 0.50 - 0s 2ms/step - loss: 1.0832 - accuracy: 0.5294 - val_loss: 1.0968 - val_accuracy: 0.5922\n",
      "Epoch 13/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.9516 - accuracy: 0.65 - ETA: 0s - loss: 0.9774 - accuracy: 0.63 - ETA: 0s - loss: 1.0336 - accuracy: 0.59 - 0s 2ms/step - loss: 1.0565 - accuracy: 0.5817 - val_loss: 1.1216 - val_accuracy: 0.4854\n",
      "Epoch 14/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.2312 - accuracy: 0.59 - ETA: 0s - loss: 1.0978 - accuracy: 0.54 - ETA: 0s - loss: 1.0304 - accuracy: 0.57 - 0s 2ms/step - loss: 1.0210 - accuracy: 0.5882 - val_loss: 1.0382 - val_accuracy: 0.6214\n",
      "Epoch 15/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.59 - ETA: 0s - loss: 0.9756 - accuracy: 0.57 - ETA: 0s - loss: 0.9771 - accuracy: 0.58 - 0s 2ms/step - loss: 0.9759 - accuracy: 0.5817 - val_loss: 0.9818 - val_accuracy: 0.6602\n",
      "Epoch 16/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - ETA: 0s - loss: 0.8810 - accuracy: 0.62 - 0s 1ms/step - loss: 0.8879 - accuracy: 0.6209 - val_loss: 0.9492 - val_accuracy: 0.6214\n",
      "Epoch 17/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 1.0282 - accuracy: 0.62 - ETA: 0s - loss: 0.9504 - accuracy: 0.60 - ETA: 0s - loss: 0.9344 - accuracy: 0.61 - 0s 2ms/step - loss: 0.8968 - accuracy: 0.6536 - val_loss: 0.9202 - val_accuracy: 0.6311\n",
      "Epoch 18/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.9575 - accuracy: 0.59 - ETA: 0s - loss: 0.9697 - accuracy: 0.60 - ETA: 0s - loss: 0.9030 - accuracy: 0.65 - 0s 2ms/step - loss: 0.8963 - accuracy: 0.6405 - val_loss: 0.9100 - val_accuracy: 0.6408\n",
      "Epoch 19/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.6282 - accuracy: 0.75 - ETA: 0s - loss: 0.7136 - accuracy: 0.71 - ETA: 0s - loss: 0.7317 - accuracy: 0.68 - ETA: 0s - loss: 0.7683 - accuracy: 0.67 - 0s 2ms/step - loss: 0.8042 - accuracy: 0.6405 - val_loss: 0.9191 - val_accuracy: 0.6408\n",
      "Epoch 20/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.65 - ETA: 0s - loss: 0.8270 - accuracy: 0.66 - ETA: 0s - loss: 0.8451 - accuracy: 0.63 - 0s 2ms/step - loss: 0.8113 - accuracy: 0.6536 - val_loss: 0.8860 - val_accuracy: 0.6699\n",
      "Epoch 21/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.9631 - accuracy: 0.62 - ETA: 0s - loss: 0.8104 - accuracy: 0.66 - ETA: 0s - loss: 0.7721 - accuracy: 0.67 - 0s 2ms/step - loss: 0.8146 - accuracy: 0.6536 - val_loss: 0.8761 - val_accuracy: 0.6214\n",
      "Epoch 22/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.71 - ETA: 0s - loss: 0.6684 - accuracy: 0.67 - ETA: 0s - loss: 0.7393 - accuracy: 0.68 - 0s 1ms/step - loss: 0.7830 - accuracy: 0.6601 - val_loss: 0.7972 - val_accuracy: 0.6796\n",
      "Epoch 23/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.71 - ETA: 0s - loss: 0.7172 - accuracy: 0.70 - 0s 2ms/step - loss: 0.6911 - accuracy: 0.7255 - val_loss: 0.9297 - val_accuracy: 0.5922\n",
      "Epoch 24/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.65 - ETA: 0s - loss: 0.7964 - accuracy: 0.62 - ETA: 0s - loss: 0.7546 - accuracy: 0.65 - ETA: 0s - loss: 0.7473 - accuracy: 0.67 - 0s 2ms/step - loss: 0.7155 - accuracy: 0.7124 - val_loss: 0.8498 - val_accuracy: 0.6796\n",
      "Epoch 25/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.8153 - accuracy: 0.75 - ETA: 0s - loss: 0.7639 - accuracy: 0.73 - ETA: 0s - loss: 0.6701 - accuracy: 0.77 - ETA: 0s - loss: 0.6613 - accuracy: 0.78 - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7712 - val_loss: 0.9295 - val_accuracy: 0.5922\n",
      "Epoch 26/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.6784 - accuracy: 0.68 - ETA: 0s - loss: 0.6413 - accuracy: 0.69 - ETA: 0s - loss: 0.6783 - accuracy: 0.68 - 0s 2ms/step - loss: 0.6419 - accuracy: 0.7190 - val_loss: 0.8407 - val_accuracy: 0.6602\n",
      "Epoch 27/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.75 - ETA: 0s - loss: 0.6384 - accuracy: 0.71 - ETA: 0s - loss: 0.6218 - accuracy: 0.72 - ETA: 0s - loss: 0.5947 - accuracy: 0.75 - 0s 3ms/step - loss: 0.6059 - accuracy: 0.7516 - val_loss: 0.8170 - val_accuracy: 0.6990\n",
      "Epoch 28/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.6753 - accuracy: 0.68 - ETA: 0s - loss: 0.6670 - accuracy: 0.71 - ETA: 0s - loss: 0.6598 - accuracy: 0.71 - ETA: 0s - loss: 0.6217 - accuracy: 0.75 - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7451 - val_loss: 0.8114 - val_accuracy: 0.6990\n",
      "Epoch 29/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.87 - ETA: 0s - loss: 0.5034 - accuracy: 0.81 - ETA: 0s - loss: 0.5310 - accuracy: 0.82 - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7974 - val_loss: 0.8053 - val_accuracy: 0.6990\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.87 - ETA: 0s - loss: 0.6072 - accuracy: 0.79 - ETA: 0s - loss: 0.5735 - accuracy: 0.81 - ETA: 0s - loss: 0.5855 - accuracy: 0.80 - 0s 3ms/step - loss: 0.6218 - accuracy: 0.7843 - val_loss: 0.8452 - val_accuracy: 0.6214\n",
      "Epoch 31/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.84 - ETA: 0s - loss: 0.4928 - accuracy: 0.82 - ETA: 0s - loss: 0.4840 - accuracy: 0.82 - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8301 - val_loss: 0.8403 - val_accuracy: 0.6505\n",
      "Epoch 32/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.78 - ETA: 0s - loss: 0.4730 - accuracy: 0.81 - ETA: 0s - loss: 0.5190 - accuracy: 0.79 - ETA: 0s - loss: 0.5050 - accuracy: 0.76 - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7582 - val_loss: 0.8160 - val_accuracy: 0.6505\n",
      "Epoch 33/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.87 - ETA: 0s - loss: 0.5673 - accuracy: 0.79 - ETA: 0s - loss: 0.5003 - accuracy: 0.82 - ETA: 0s - loss: 0.4495 - accuracy: 0.85 - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8235 - val_loss: 0.8013 - val_accuracy: 0.6699\n",
      "Epoch 34/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.87 - ETA: 0s - loss: 0.3633 - accuracy: 0.89 - ETA: 0s - loss: 0.4177 - accuracy: 0.83 - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8170 - val_loss: 0.7904 - val_accuracy: 0.6893\n",
      "Epoch 35/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.78 - ETA: 0s - loss: 0.4697 - accuracy: 0.76 - ETA: 0s - loss: 0.4518 - accuracy: 0.78 - ETA: 0s - loss: 0.4722 - accuracy: 0.78 - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7974 - val_loss: 0.9129 - val_accuracy: 0.6311\n",
      "Epoch 36/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.78 - ETA: 0s - loss: 0.5228 - accuracy: 0.79 - ETA: 0s - loss: 0.4156 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8562 - val_loss: 0.7916 - val_accuracy: 0.6893\n",
      "Epoch 37/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.81 - ETA: 0s - loss: 0.4199 - accuracy: 0.81 - ETA: 0s - loss: 0.4407 - accuracy: 0.79 - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8235 - val_loss: 0.8457 - val_accuracy: 0.6505\n",
      "Epoch 38/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.81 - ETA: 0s - loss: 0.2833 - accuracy: 0.89 - ETA: 0s - loss: 0.3223 - accuracy: 0.86 - ETA: 0s - loss: 0.3587 - accuracy: 0.85 - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8693 - val_loss: 0.8708 - val_accuracy: 0.6505\n",
      "Epoch 39/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.90 - ETA: 0s - loss: 0.3264 - accuracy: 0.87 - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8562 - val_loss: 0.8935 - val_accuracy: 0.6311\n",
      "Epoch 40/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.93 - ETA: 0s - loss: 0.3152 - accuracy: 0.89 - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8954 - val_loss: 0.8991 - val_accuracy: 0.6019\n",
      "Epoch 41/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.90 - ETA: 0s - loss: 0.4166 - accuracy: 0.85 - ETA: 0s - loss: 0.4115 - accuracy: 0.83 - ETA: 0s - loss: 0.3855 - accuracy: 0.86 - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8889 - val_loss: 0.9376 - val_accuracy: 0.6311\n",
      "Epoch 42/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.96 - ETA: 0s - loss: 0.2204 - accuracy: 0.96 - ETA: 0s - loss: 0.2729 - accuracy: 0.93 - ETA: 0s - loss: 0.2830 - accuracy: 0.92 - 0s 3ms/step - loss: 0.2918 - accuracy: 0.9346 - val_loss: 0.9197 - val_accuracy: 0.6505\n",
      "Epoch 43/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.90 - ETA: 0s - loss: 0.2709 - accuracy: 0.93 - ETA: 0s - loss: 0.3022 - accuracy: 0.91 - 0s 2ms/step - loss: 0.3081 - accuracy: 0.9020 - val_loss: 0.9597 - val_accuracy: 0.6019\n",
      "Epoch 44/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.84 - ETA: 0s - loss: 0.2597 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8954 - val_loss: 1.1554 - val_accuracy: 0.6214\n",
      "Epoch 45/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.87 - ETA: 0s - loss: 0.2935 - accuracy: 0.86 - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9020 - val_loss: 0.9416 - val_accuracy: 0.6408\n",
      "Epoch 46/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3229 - accuracy: 0.87 - ETA: 0s - loss: 0.2180 - accuracy: 0.93 - ETA: 0s - loss: 0.2860 - accuracy: 0.90 - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8954 - val_loss: 0.9346 - val_accuracy: 0.6214\n",
      "Epoch 47/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.96 - ETA: 0s - loss: 0.1778 - accuracy: 0.96 - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9739 - val_loss: 0.9422 - val_accuracy: 0.6311\n",
      "Epoch 48/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.87 - ETA: 0s - loss: 0.2801 - accuracy: 0.92 - ETA: 0s - loss: 0.2451 - accuracy: 0.93 - 0s 2ms/step - loss: 0.2557 - accuracy: 0.9281 - val_loss: 0.8760 - val_accuracy: 0.6990\n",
      "Epoch 49/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.96 - ETA: 0s - loss: 0.2024 - accuracy: 0.93 - ETA: 0s - loss: 0.2545 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9150 - val_loss: 0.8919 - val_accuracy: 0.6796\n",
      "Epoch 50/50\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 1.00 - ETA: 0s - loss: 0.2337 - accuracy: 0.93 - ETA: 0s - loss: 0.2107 - accuracy: 0.94 - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9412 - val_loss: 1.0747 - val_accuracy: 0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c113933bc8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "print(y_train_hot.shape)\n",
    "print(labels.shape)\n",
    "print(X_train.shape)\n",
    "# Train the CNN model\n",
    "#    X_train: Input data\n",
    "#    y_train_hot: Target data\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_val, y_val_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the keras model\n",
    "model.save(\"geo_cnn_model.h5\")\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the IntelliChirp Biophony CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('ant_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 19, 24)        240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 7, 48)         10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 3, 48)          6960      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 100,949\n",
      "Trainable params: 100,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0]\n",
      " [ 0 21  0  5  0]\n",
      " [ 0  2  0  1  0]\n",
      " [ 0  9  0 10  4]\n",
      " [ 0  2  0  2  4]]\n",
      "Accuracy for class GOC : [1.]\n",
      "Accuracy for class GRA : [0.80769231]\n",
      "Accuracy for class GST : [0.]\n",
      "Accuracy for class GWG : [0.43478261]\n",
      "Accuracy for class GWC : [0.5]\n",
      "Overall Accuracy : 0.609375\n"
     ]
    }
   ],
   "source": [
    "y_pred_ohe = loaded_model.predict(X_test)  # shape=(n_samples, 12)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=y_pred_labels)  # shape\n",
    "print(confusion_matrix)\n",
    "\n",
    "for class_i in range(len(labels)) :\n",
    "    indices = np.argwhere(y_test == class_i)\n",
    "    sum = 0\n",
    "    for index in indices:\n",
    "        sum += (y_test[index] == y_pred_labels[index])\n",
    "    if(len(indices) > 0) : mean = sum/len(indices)\n",
    "    else : mean = \"N/A\"\n",
    "    print(\"Accuracy for class\", labels[class_i], \":\", mean)\n",
    "\n",
    "print(\"Overall Accuracy :\", np.mean(y_test == y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[ 0.0000000e+00  1.5258789e-05  0.0000000e+00 ...  3.3020020e-02\n",
      "  1.2680054e-02 -8.7432861e-03]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00110971\n",
      "\n",
      " GRA :  0.00687433\n",
      "\n",
      " GST :  0.00060519\n",
      "\n",
      " GWG :  0.28046575\n",
      "\n",
      " GWC :  0.71094495\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[1. 2.]\n",
      "[-0.03717041 -0.05769348 -0.06455994 ...  0.01766968  0.01895142\n",
      "  0.01779175]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000150\n",
      "\n",
      " GRA :  0.66413796\n",
      "\n",
      " GST :  0.00009404\n",
      "\n",
      " GWG :  0.00712661\n",
      "\n",
      " GWC :  0.32863984\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[2. 3.]\n",
      "[ 0.02345276  0.02101135  0.01712036 ... -0.01161194 -0.0141449\n",
      " -0.01431274]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00008299\n",
      "\n",
      " GRA :  0.22556210\n",
      "\n",
      " GST :  0.00302639\n",
      "\n",
      " GWG :  0.10296817\n",
      "\n",
      " GWC :  0.66836035\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[3. 4.]\n",
      "[-0.01583862 -0.01066589 -0.00762939 ... -0.0377655  -0.03556824\n",
      " -0.02685547]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00076802\n",
      "\n",
      " GRA :  0.19427927\n",
      "\n",
      " GST :  0.00463253\n",
      "\n",
      " GWG :  0.03950845\n",
      "\n",
      " GWC :  0.76081169\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[4. 5.]\n",
      "[-0.02836609 -0.02510071 -0.02012634 ...  0.0138855  -0.00386047\n",
      " -0.00904846]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00053637\n",
      "\n",
      " GRA :  0.19687678\n",
      "\n",
      " GST :  0.01669122\n",
      "\n",
      " GWG :  0.42333746\n",
      "\n",
      " GWC :  0.36255816\n",
      "GUESS: Nothing\n",
      "[5. 6.]\n",
      "[-0.00526428  0.00822449  0.01951599 ...  0.02729797  0.02156067\n",
      "  0.01234436]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00001735\n",
      "\n",
      " GRA :  0.67453504\n",
      "\n",
      " GST :  0.00068860\n",
      "\n",
      " GWG :  0.01727903\n",
      "\n",
      " GWC :  0.30747995\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[6. 7.]\n",
      "[ 0.00544739  0.00053406  0.00970459 ... -0.02848816 -0.01611328\n",
      " -0.01091003]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00041052\n",
      "\n",
      " GRA :  0.01402403\n",
      "\n",
      " GST :  0.00038692\n",
      "\n",
      " GWG :  0.17212571\n",
      "\n",
      " GWC :  0.81305289\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[7. 8.]\n",
      "[-0.0177002  -0.02372742 -0.02700806 ... -0.04304504 -0.04063416\n",
      " -0.03363037]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000991\n",
      "\n",
      " GRA :  0.94457138\n",
      "\n",
      " GST :  0.00616840\n",
      "\n",
      " GWG :  0.03336105\n",
      "\n",
      " GWC :  0.01588919\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[8. 9.]\n",
      "[-0.01539612 -0.00108337  0.00718689 ...  0.01161194  0.01818848\n",
      "  0.02700806]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00008726\n",
      "\n",
      " GRA :  0.81412381\n",
      "\n",
      " GST :  0.01158650\n",
      "\n",
      " GWG :  0.09921984\n",
      "\n",
      " GWC :  0.07498255\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[ 9. 10.]\n",
      "[ 0.03549194  0.04856873  0.05519104 ... -0.02171326 -0.03634644\n",
      " -0.03912354]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00191176\n",
      "\n",
      " GRA :  0.09809754\n",
      "\n",
      " GST :  0.00213318\n",
      "\n",
      " GWG :  0.23002826\n",
      "\n",
      " GWC :  0.66782933\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[10. 11.]\n",
      "[-0.02934265 -0.0115509   0.00445557 ... -0.03616333 -0.03759766\n",
      " -0.0304718 ]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000013\n",
      "\n",
      " GRA :  0.99877483\n",
      "\n",
      " GST :  0.00003083\n",
      "\n",
      " GWG :  0.00113827\n",
      "\n",
      " GWC :  0.00005597\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[11. 12.]\n",
      "[-0.03358459 -0.03901672 -0.03933716 ... -0.02337646 -0.02124023\n",
      " -0.02107239]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00022642\n",
      "\n",
      " GRA :  0.13672589\n",
      "\n",
      " GST :  0.00204764\n",
      "\n",
      " GWG :  0.66154647\n",
      "\n",
      " GWC :  0.19945353\n",
      "\n",
      "\n",
      "GUESS:  GWG\n",
      "[12. 13.]\n",
      "[-0.00846863  0.00444031  0.00852966 ... -0.00604248 -0.00845337\n",
      " -0.00497437]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00307768\n",
      "\n",
      " GRA :  0.21987155\n",
      "\n",
      " GST :  0.01730751\n",
      "\n",
      " GWG :  0.38038778\n",
      "\n",
      " GWC :  0.37935549\n",
      "GUESS: Nothing\n",
      "[13. 14.]\n",
      "[-0.00427246 -0.00718689 -0.00811768 ... -0.01966858 -0.01296997\n",
      " -0.01628113]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00033389\n",
      "\n",
      " GRA :  0.24240135\n",
      "\n",
      " GST :  0.01909669\n",
      "\n",
      " GWG :  0.65060490\n",
      "\n",
      " GWC :  0.08756324\n",
      "\n",
      "\n",
      "GUESS:  GWG\n",
      "[14. 15.]\n",
      "[-0.02262878 -0.01573181 -0.00117493 ... -0.08956909 -0.0695343\n",
      " -0.04067993]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00019831\n",
      "\n",
      " GRA :  0.09028011\n",
      "\n",
      " GST :  0.00338028\n",
      "\n",
      " GWG :  0.46894377\n",
      "\n",
      " GWC :  0.43719757\n",
      "GUESS: Nothing\n",
      "[15. 16.]\n",
      "[-0.02532959 -0.01031494 -0.00280762 ... -0.07128906 -0.07106018\n",
      " -0.05839539]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00002741\n",
      "\n",
      " GRA :  0.01345812\n",
      "\n",
      " GST :  0.00017061\n",
      "\n",
      " GWG :  0.00623927\n",
      "\n",
      " GWC :  0.98010468\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[16. 17.]\n",
      "[-0.04600525 -0.02149963  0.00523376 ... -0.02526855 -0.02735901\n",
      " -0.03106689]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000000\n",
      "\n",
      " GRA :  0.99911612\n",
      "\n",
      " GST :  0.00000119\n",
      "\n",
      " GWG :  0.00087264\n",
      "\n",
      " GWC :  0.00001005\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[17. 18.]\n",
      "[-0.02043152 -0.01174927 -0.02088928 ...  0.10055542  0.08653259\n",
      "  0.06604004]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00001004\n",
      "\n",
      " GRA :  0.98751462\n",
      "\n",
      " GST :  0.00235241\n",
      "\n",
      " GWG :  0.00240187\n",
      "\n",
      " GWC :  0.00772112\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[18. 19.]\n",
      "[ 0.04153442  0.01223755 -0.00654602 ...  0.03269958  0.02374268\n",
      "  0.02774048]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000010\n",
      "\n",
      " GRA :  0.99923599\n",
      "\n",
      " GST :  0.00000878\n",
      "\n",
      " GWG :  0.00006613\n",
      "\n",
      " GWC :  0.00068900\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[19. 20.]\n",
      "[0.02185059 0.02069092 0.01451111 ... 0.03469849 0.03985596 0.04600525]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000007\n",
      "\n",
      " GRA :  0.99936324\n",
      "\n",
      " GST :  0.00004567\n",
      "\n",
      " GWG :  0.00001874\n",
      "\n",
      " GWC :  0.00057223\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[20. 21.]\n",
      "[ 0.0353241   0.01567078 -0.00102234 ...  0.1058197   0.10365295\n",
      "  0.09759521]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00001078\n",
      "\n",
      " GRA :  0.97431314\n",
      "\n",
      " GST :  0.00149824\n",
      "\n",
      " GWG :  0.00516652\n",
      "\n",
      " GWC :  0.01901135\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[21. 22.]\n",
      "[ 0.09413147  0.07905579  0.05625916 ... -0.01145935 -0.00245667\n",
      "  0.00479126]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00001107\n",
      "\n",
      " GRA :  0.85995126\n",
      "\n",
      " GST :  0.01212410\n",
      "\n",
      " GWG :  0.12441237\n",
      "\n",
      " GWC :  0.00350112\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[22. 23.]\n",
      "[ 0.0037384   0.01168823  0.01628113 ... -0.03440857 -0.05511475\n",
      " -0.08209229]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000007\n",
      "\n",
      " GRA :  0.99817920\n",
      "\n",
      " GST :  0.00064762\n",
      "\n",
      " GWG :  0.00114116\n",
      "\n",
      " GWC :  0.00003188\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[23. 24.]\n",
      "[-0.1026001  -0.12590027 -0.14944458 ...  0.03462219  0.02537537\n",
      "  0.02354431]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000003\n",
      "\n",
      " GRA :  0.99974483\n",
      "\n",
      " GST :  0.00003395\n",
      "\n",
      " GWG :  0.00001006\n",
      "\n",
      " GWC :  0.00021120\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[24. 25.]\n",
      "[ 0.0196991   0.02836609  0.03103638 ... -0.03009033 -0.03392029\n",
      " -0.03681946]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000000\n",
      "\n",
      " GRA :  0.99998176\n",
      "\n",
      " GST :  0.00001182\n",
      "\n",
      " GWG :  0.00000516\n",
      "\n",
      " GWC :  0.00000131\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[25. 26.]\n",
      "[-0.04151917 -0.03933716 -0.03703308 ...  0.05451965  0.0519104\n",
      "  0.05206299]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00003238\n",
      "\n",
      " GRA :  0.97408438\n",
      "\n",
      " GST :  0.00137138\n",
      "\n",
      " GWG :  0.00180984\n",
      "\n",
      " GWC :  0.02270207\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[26. 27.]\n",
      "[ 0.05670166  0.06253052  0.07643127 ... -0.00396729  0.00715637\n",
      "  0.00585938]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00031376\n",
      "\n",
      " GRA :  0.18696703\n",
      "\n",
      " GST :  0.00742342\n",
      "\n",
      " GWG :  0.34027183\n",
      "\n",
      " GWC :  0.46502385\n",
      "GUESS: Nothing\n",
      "[27. 28.]\n",
      "[-0.00222778 -0.01303101 -0.02310181 ...  0.01165771  0.01649475\n",
      "  0.0194397 ]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00005648\n",
      "\n",
      " GRA :  0.13421611\n",
      "\n",
      " GST :  0.00141173\n",
      "\n",
      " GWG :  0.47746155\n",
      "\n",
      " GWC :  0.38685405\n",
      "GUESS: Nothing\n",
      "[28. 29.]\n",
      "[0.01657104 0.01519775 0.00924683 ... 0.03746033 0.03282166 0.02775574]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00001463\n",
      "\n",
      " GRA :  0.36573434\n",
      "\n",
      " GST :  0.00021427\n",
      "\n",
      " GWG :  0.02339190\n",
      "\n",
      " GWC :  0.61064482\n",
      "\n",
      "\n",
      "GUESS:  GWC\n",
      "[29. 30.]\n",
      "[ 0.01919556  0.0135498   0.01724243 ... -0.00575256 -0.01502991\n",
      " -0.02742004]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000170\n",
      "\n",
      " GRA :  0.99406528\n",
      "\n",
      " GST :  0.00014316\n",
      "\n",
      " GWG :  0.00414455\n",
      "\n",
      " GWC :  0.00164524\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[30. 31.]\n",
      "[-0.0322876  -0.0365448  -0.03544617 ... -0.0218811  -0.02978516\n",
      " -0.04052734]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00073814\n",
      "\n",
      " GRA :  0.86860937\n",
      "\n",
      " GST :  0.00153848\n",
      "\n",
      " GWG :  0.04801571\n",
      "\n",
      " GWC :  0.08109826\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[31. 32.]\n",
      "[-0.04328918 -0.03413391 -0.03421021 ...  0.05908203  0.06370544\n",
      "  0.05949402]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00002089\n",
      "\n",
      " GRA :  0.80240065\n",
      "\n",
      " GST :  0.00016713\n",
      "\n",
      " GWG :  0.10498895\n",
      "\n",
      " GWC :  0.09242238\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[32. 33.]\n",
      "[ 0.06063843  0.06056213  0.06610107 ... -0.12741089 -0.13371277\n",
      " -0.12313843]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000001\n",
      "\n",
      " GRA :  0.99997139\n",
      "\n",
      " GST :  0.00000195\n",
      "\n",
      " GWG :  0.00000346\n",
      "\n",
      " GWC :  0.00002330\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[33. 34.]\n",
      "[-0.09968567 -0.06376648 -0.03105164 ... -0.0138092  -0.01574707\n",
      " -0.01896667]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000411\n",
      "\n",
      " GRA :  0.98667425\n",
      "\n",
      " GST :  0.00016910\n",
      "\n",
      " GWG :  0.00259384\n",
      "\n",
      " GWC :  0.01055874\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[34. 35.]\n",
      "[-0.00811768  0.00149536  0.00953674 ... -0.004776   -0.0010376\n",
      "  0.00231934]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00000309\n",
      "\n",
      " GRA :  0.97966915\n",
      "\n",
      " GST :  0.00049880\n",
      "\n",
      " GWG :  0.01601271\n",
      "\n",
      " GWC :  0.00381629\n",
      "\n",
      "\n",
      "GUESS:  GRA\n",
      "[35. 36.]\n",
      "[ 0.00238037  0.00236511  0.00231934 ... -0.00193787  0.0068512\n",
      "  0.00695801]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " GOC :  0.00061579\n",
      "\n",
      " GRA :  0.24607882\n",
      "\n",
      " GST :  0.00648576\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GWG :  0.40232626\n",
      "\n",
      " GWC :  0.34449333\n",
      "GUESS: Nothing\n",
      "[{'class': 'GWC', 'timestamp': 0}, {'class': 'GRA', 'timestamp': 1}, {'class': 'GWC', 'timestamp': 2}, {'class': 'GWC', 'timestamp': 3}, {'class': 'Nothing', 'timestamp': 4}, {'class': 'GRA', 'timestamp': 5}, {'class': 'GWC', 'timestamp': 6}, {'class': 'GRA', 'timestamp': 7}, {'class': 'GRA', 'timestamp': 8}, {'class': 'GWC', 'timestamp': 9}, {'class': 'GRA', 'timestamp': 10}, {'class': 'GWG', 'timestamp': 11}, {'class': 'Nothing', 'timestamp': 12}, {'class': 'GWG', 'timestamp': 13}, {'class': 'Nothing', 'timestamp': 14}, {'class': 'GWC', 'timestamp': 15}, {'class': 'GRA', 'timestamp': 16}, {'class': 'GRA', 'timestamp': 17}, {'class': 'GRA', 'timestamp': 18}, {'class': 'GRA', 'timestamp': 19}, {'class': 'GRA', 'timestamp': 20}, {'class': 'GRA', 'timestamp': 21}, {'class': 'GRA', 'timestamp': 22}, {'class': 'GRA', 'timestamp': 23}, {'class': 'GRA', 'timestamp': 24}, {'class': 'GRA', 'timestamp': 25}, {'class': 'Nothing', 'timestamp': 26}, {'class': 'Nothing', 'timestamp': 27}, {'class': 'GWC', 'timestamp': 28}, {'class': 'GRA', 'timestamp': 29}, {'class': 'GRA', 'timestamp': 30}, {'class': 'GRA', 'timestamp': 31}, {'class': 'GRA', 'timestamp': 32}, {'class': 'GRA', 'timestamp': 33}, {'class': 'GRA', 'timestamp': 34}, {'class': 'Nothing', 'timestamp': 35}]\n"
     ]
    }
   ],
   "source": [
    "## Running the model\n",
    "\n",
    "n_mfcc = config.buckets\n",
    "max_len = config.max_len\n",
    "# convert file to wav2mfcc\n",
    "# Mel-frequency cepstral coefficients\n",
    "file_path = \"./prediction/nature_sc.wav\"\n",
    "big_wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "#print(wave.shape, sr)\n",
    "\n",
    "classification = []\n",
    "\n",
    "for sec_index in range( int(big_wave.shape[0] / sr) ) :\n",
    "    start_sec = sec_index\n",
    "    end_sec = sec_index + 1\n",
    "    \n",
    "    sec_to_trim = np.array( [ float(start_sec), float(end_sec) ] )\n",
    "    print(sec_to_trim)\n",
    "    sec_to_trim = np.ceil( sec_to_trim * sr )\n",
    "\n",
    "    wave = big_wave[int(sec_to_trim[0]) : int(sec_to_trim[1])]\n",
    "    print(wave)\n",
    "\n",
    "    wave = np.asfortranarray(wave[::3])\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    # Convert wav to MFCC\n",
    "    prediction_data = wav2mfcc('./prediction/nature_sc.wav')\n",
    "    prediction_data = mfcc\n",
    "    print(prediction_data.shape)\n",
    "    #print(wav2mfcc())\n",
    "    # Reshape to 4 dimensions\n",
    "    prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
    "    #prediction_data = prediction_data.reshape(1, 20, config.max_len, channels)\n",
    "\n",
    "    # Run the model on the inputted file\n",
    "    predicted = loaded_model.predict(prediction_data)\n",
    "\n",
    "    # Output the prediction values for each class\n",
    "    print ('PREDICTED VALUES')\n",
    "    labels_indices = range(len(labels))\n",
    "    max_value = 0\n",
    "    max_value_index = 0\n",
    "    for index in labels_indices:\n",
    "        print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
    "        if predicted[0,index] > max_value:\n",
    "            max_value_index = index\n",
    "            max_value = predicted[0,index]\n",
    "\n",
    "    # Output the prediction\n",
    "    if max_value < 0.5:\n",
    "        print(\"GUESS: Nothing\")\n",
    "        classification.append( { \"class\" : \"Nothing\", \"timestamp\" : start_sec } )\n",
    "    else:\n",
    "        print('\\n\\nGUESS: ', labels[max_value_index])\n",
    "        classification.append( { \"class\" : labels[max_value_index], \"timestamp\" : start_sec } )\n",
    "\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
