{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, Activation\n",
    "from keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/ftl7qqh6\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/ftl7qqh6</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'AAT': 100%|███████████████████████████████████████████████| 205/205 [00:03<00:00, 59.44it/s]\n",
      "Saving vectors of label - 'AHV': 100%|█████████████████████████████████████████████████| 33/33 [00:00<00:00, 41.21it/s]\n",
      "Saving vectors of label - 'AMA': 100%|█████████████████████████████████████████████████| 94/94 [00:02<00:00, 34.51it/s]\n",
      "Saving vectors of label - 'ART': 100%|████████████████████████████████████████████████| 21/21 [00:00<00:00, 151.48it/s]\n",
      "Saving vectors of label - 'ASI': 100%|████████████████████████████████████████████████| 17/17 [00:00<00:00, 146.96it/s]\n",
      "Saving vectors of label - 'AVH': 100%|████████████████████████████████████████████████| 35/35 [00:00<00:00, 137.62it/s]\n",
      "Saving vectors of label - 'AVT': 100%|██████████████████████████████████████████████| 965/965 [00:07<00:00, 129.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Saving vectors of label - 'AAT': 100%|█████████████████████████████████████████████████| 58/58 [00:01<00:00, 54.05it/s]\\nSaving vectors of label - 'AHV': 100%|█████████████████████████████████████████████████| 16/16 [00:00<00:00, 65.22it/s]\\nSaving vectors of label - 'AMA': 100%|█████████████████████████████████████████████████| 30/30 [00:00<00:00, 61.26it/s]\\nSaving vectors of label - 'ART': 100%|███████████████████████████████████████████████████| 5/5 [00:00<00:00, 53.90it/s]\\nSaving vectors of label - 'ASI': 100%|███████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.81it/s]\\nSaving vectors of label - 'AVH': 100%|█████████████████████████████████████████████████| 18/18 [00:00<00:00, 96.00it/s]\\nSaving vectors of label - 'AVT': 100%|███████████████████████████████████████████████| 222/222 [00:04<00:00, 50.72it/s]\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "config.max_len = 32\n",
    "config.buckets = 128\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
    "\n",
    "#labels=np.array([\"chirping_birds\", \"crickets\", \"crow\", \n",
    "#                 \"frog\", \"insects\"])\n",
    "labels=np.array([\"AAT\", \"AHV\", \"AMA\", \n",
    "                 \"ART\", \"ASI\", \"AVH\",\n",
    "                \"AVT\",\n",
    "                \"BRA\", \"BAM\", \"BBI\", \n",
    "                 \"BMA\", \"BIN\",\n",
    "                \"GOC\", \"GRA\", \"GST\", \n",
    "                 \"GWG\", \"GWC\",\n",
    "                \"OPI\", \"OQU\", \"OQY\", \"QOU\"])\n",
    "\n",
    "'''Saving vectors of label - 'AAT': 100%|█████████████████████████████████████████████████| 58/58 [00:01<00:00, 54.05it/s]\n",
    "Saving vectors of label - 'AHV': 100%|█████████████████████████████████████████████████| 16/16 [00:00<00:00, 65.22it/s]\n",
    "Saving vectors of label - 'AMA': 100%|█████████████████████████████████████████████████| 30/30 [00:00<00:00, 61.26it/s]\n",
    "Saving vectors of label - 'ART': 100%|███████████████████████████████████████████████████| 5/5 [00:00<00:00, 53.90it/s]\n",
    "Saving vectors of label - 'ASI': 100%|███████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.81it/s]\n",
    "Saving vectors of label - 'AVH': 100%|█████████████████████████████████████████████████| 18/18 [00:00<00:00, 96.00it/s]\n",
    "Saving vectors of label - 'AVT': 100%|███████████████████████████████████████████████| 222/222 [00:04<00:00, 50.72it/s]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test set\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 128, 32)\n"
     ]
    }
   ],
   "source": [
    "# Setting channels to 1 to generalize stereo sound to 1 channel\n",
    "channels = 1\n",
    "config.epochs = 17\n",
    "config.batch_size = 100\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 7\n",
    "print(X_train.shape)\n",
    "# Reshape X_train and X_test to include a 4th dimension (channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len, channels)\n",
    "X_val = X_val.reshape(X_val.shape[0], config.buckets, config.max_len, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 128, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a47642788>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spectrogram visualized of 0th element\n",
    "print(X_train.shape)\n",
    "plt.imshow(X_train[200, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting vector number where each number corresponds to a label\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_val_hot = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 126, 30, 21)       210       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 63, 15, 21)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 63, 15, 21)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 61, 13, 48)        9120      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 6, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 6, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 6, 48)         6960      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 28, 6, 48)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8064)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8064)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                516160    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 532,905\n",
      "Trainable params: 532,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"model.add(Conv2D(32, (3, 3),\\n    input_shape=(config.buckets, config.max_len, channels),\\n    activation='relu'))\\n\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n\\nmodel.add(Flatten())\\n\\nmodel.add(Dense(128, activation='relu'))\\nmodel.add(Dense(num_classes, activation='softmax'))\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape= (config.buckets, config.max_len, channels)\n",
    "\n",
    "model.add(Conv2D(21, (3, 3), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(len(labels)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "# Conv2D: \n",
    "#    Filters: 32\n",
    "#    Kernel_size: (3,3) (height/width of the 2D convolution window)     \n",
    "'''model.add(Conv2D(32, (3, 3),\n",
    "    input_shape=(config.buckets, config.max_len, channels),\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure CNN for training\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/2rtny7n6\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/2rtny7n6</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 7)\n",
      "(7,)\n",
      "(657, 128, 32, 1)\n",
      "Train on 657 samples, validate on 439 samples\n",
      "Epoch 1/17\n",
      "657/657 [==============================] - ETA: 19s - loss: 4.0558 - accuracy: 0.156 - ETA: 10s - loss: 3.1060 - accuracy: 0.406 - ETA: 7s - loss: 3.2798 - accuracy: 0.447 - ETA: 6s - loss: 3.0464 - accuracy: 0.45 - ETA: 5s - loss: 2.8030 - accuracy: 0.46 - ETA: 4s - loss: 2.6097 - accuracy: 0.45 - ETA: 3s - loss: 2.4701 - accuracy: 0.42 - ETA: 3s - loss: 2.3784 - accuracy: 0.42 - ETA: 3s - loss: 2.2925 - accuracy: 0.43 - ETA: 2s - loss: 2.2017 - accuracy: 0.44 - ETA: 2s - loss: 2.1122 - accuracy: 0.46 - ETA: 2s - loss: 2.0394 - accuracy: 0.47 - ETA: 1s - loss: 1.9996 - accuracy: 0.48 - ETA: 1s - loss: 1.9450 - accuracy: 0.49 - ETA: 1s - loss: 1.9012 - accuracy: 0.50 - ETA: 1s - loss: 1.8715 - accuracy: 0.50 - ETA: 0s - loss: 1.8469 - accuracy: 0.52 - ETA: 0s - loss: 1.8115 - accuracy: 0.52 - ETA: 0s - loss: 1.7669 - accuracy: 0.53 - ETA: 0s - loss: 1.7500 - accuracy: 0.54 - 6s 9ms/step - loss: 1.7466 - accuracy: 0.5403 - val_loss: 0.9263 - val_accuracy: 0.7403\n",
      "Epoch 2/17\n",
      "657/657 [==============================] - ETA: 4s - loss: 1.1509 - accuracy: 0.65 - ETA: 4s - loss: 1.2885 - accuracy: 0.65 - ETA: 3s - loss: 1.2698 - accuracy: 0.63 - ETA: 3s - loss: 1.2546 - accuracy: 0.62 - ETA: 3s - loss: 1.2028 - accuracy: 0.65 - ETA: 2s - loss: 1.2129 - accuracy: 0.64 - ETA: 2s - loss: 1.2027 - accuracy: 0.63 - ETA: 2s - loss: 1.1956 - accuracy: 0.62 - ETA: 2s - loss: 1.1730 - accuracy: 0.63 - ETA: 2s - loss: 1.1439 - accuracy: 0.64 - ETA: 1s - loss: 1.1532 - accuracy: 0.65 - ETA: 1s - loss: 1.1592 - accuracy: 0.65 - ETA: 1s - loss: 1.1075 - accuracy: 0.66 - ETA: 1s - loss: 1.1140 - accuracy: 0.66 - ETA: 1s - loss: 1.1062 - accuracy: 0.67 - ETA: 1s - loss: 1.0849 - accuracy: 0.67 - ETA: 0s - loss: 1.0751 - accuracy: 0.68 - ETA: 0s - loss: 1.0769 - accuracy: 0.67 - ETA: 0s - loss: 1.0793 - accuracy: 0.68 - ETA: 0s - loss: 1.0833 - accuracy: 0.67 - 7s 11ms/step - loss: 1.0879 - accuracy: 0.6773 - val_loss: 0.7706 - val_accuracy: 0.7950\n",
      "Epoch 3/17\n",
      "657/657 [==============================] - ETA: 3s - loss: 0.9944 - accuracy: 0.78 - ETA: 4s - loss: 1.0090 - accuracy: 0.71 - ETA: 3s - loss: 1.0620 - accuracy: 0.69 - ETA: 3s - loss: 0.9736 - accuracy: 0.72 - ETA: 3s - loss: 0.9877 - accuracy: 0.72 - ETA: 3s - loss: 1.0172 - accuracy: 0.71 - ETA: 3s - loss: 0.9724 - accuracy: 0.72 - ETA: 3s - loss: 0.9700 - accuracy: 0.73 - ETA: 2s - loss: 0.9516 - accuracy: 0.74 - ETA: 2s - loss: 0.9033 - accuracy: 0.75 - ETA: 2s - loss: 0.9295 - accuracy: 0.75 - ETA: 2s - loss: 0.9624 - accuracy: 0.75 - ETA: 1s - loss: 1.0083 - accuracy: 0.73 - ETA: 1s - loss: 0.9966 - accuracy: 0.73 - ETA: 1s - loss: 0.9908 - accuracy: 0.73 - ETA: 1s - loss: 0.9704 - accuracy: 0.74 - ETA: 0s - loss: 0.9569 - accuracy: 0.74 - ETA: 0s - loss: 0.9406 - accuracy: 0.74 - ETA: 0s - loss: 0.9327 - accuracy: 0.74 - ETA: 0s - loss: 0.9367 - accuracy: 0.74 - 7s 11ms/step - loss: 0.9294 - accuracy: 0.7397 - val_loss: 0.6112 - val_accuracy: 0.8132\n",
      "Epoch 4/17\n",
      "657/657 [==============================] - ETA: 4s - loss: 0.9354 - accuracy: 0.75 - ETA: 5s - loss: 0.7274 - accuracy: 0.81 - ETA: 6s - loss: 0.7188 - accuracy: 0.80 - ETA: 6s - loss: 0.7575 - accuracy: 0.78 - ETA: 6s - loss: 0.7361 - accuracy: 0.78 - ETA: 5s - loss: 0.7440 - accuracy: 0.78 - ETA: 4s - loss: 0.7807 - accuracy: 0.76 - ETA: 4s - loss: 0.7925 - accuracy: 0.76 - ETA: 3s - loss: 0.7831 - accuracy: 0.76 - ETA: 3s - loss: 0.7635 - accuracy: 0.76 - ETA: 3s - loss: 0.7662 - accuracy: 0.76 - ETA: 3s - loss: 0.8079 - accuracy: 0.75 - ETA: 2s - loss: 0.8197 - accuracy: 0.75 - ETA: 2s - loss: 0.8151 - accuracy: 0.75 - ETA: 2s - loss: 0.8265 - accuracy: 0.74 - ETA: 1s - loss: 0.8232 - accuracy: 0.74 - ETA: 1s - loss: 0.8224 - accuracy: 0.74 - ETA: 0s - loss: 0.8200 - accuracy: 0.75 - ETA: 0s - loss: 0.8059 - accuracy: 0.75 - ETA: 0s - loss: 0.7877 - accuracy: 0.76 - 9s 14ms/step - loss: 0.7801 - accuracy: 0.7626 - val_loss: 0.5614 - val_accuracy: 0.8292\n",
      "Epoch 5/17\n",
      "657/657 [==============================] - ETA: 4s - loss: 0.8717 - accuracy: 0.78 - ETA: 3s - loss: 0.7388 - accuracy: 0.79 - ETA: 3s - loss: 0.7251 - accuracy: 0.79 - ETA: 3s - loss: 0.9180 - accuracy: 0.72 - ETA: 3s - loss: 0.8470 - accuracy: 0.74 - ETA: 3s - loss: 0.8564 - accuracy: 0.73 - ETA: 2s - loss: 0.7896 - accuracy: 0.76 - ETA: 2s - loss: 0.7865 - accuracy: 0.76 - ETA: 2s - loss: 0.7887 - accuracy: 0.74 - ETA: 2s - loss: 0.7887 - accuracy: 0.75 - ETA: 2s - loss: 0.8024 - accuracy: 0.74 - ETA: 2s - loss: 0.7989 - accuracy: 0.74 - ETA: 1s - loss: 0.7856 - accuracy: 0.75 - ETA: 1s - loss: 0.7943 - accuracy: 0.75 - ETA: 1s - loss: 0.7788 - accuracy: 0.76 - ETA: 1s - loss: 0.7626 - accuracy: 0.76 - ETA: 0s - loss: 0.7563 - accuracy: 0.77 - ETA: 0s - loss: 0.7758 - accuracy: 0.76 - ETA: 0s - loss: 0.7528 - accuracy: 0.77 - ETA: 0s - loss: 0.7622 - accuracy: 0.76 - 7s 11ms/step - loss: 0.7514 - accuracy: 0.7702 - val_loss: 0.4817 - val_accuracy: 0.8497\n",
      "Epoch 6/17\n",
      "657/657 [==============================] - ETA: 4s - loss: 0.8847 - accuracy: 0.78 - ETA: 4s - loss: 0.7266 - accuracy: 0.78 - ETA: 4s - loss: 0.7128 - accuracy: 0.80 - ETA: 4s - loss: 0.7204 - accuracy: 0.77 - ETA: 4s - loss: 0.7218 - accuracy: 0.77 - ETA: 4s - loss: 0.7009 - accuracy: 0.78 - ETA: 3s - loss: 0.6731 - accuracy: 0.79 - ETA: 3s - loss: 0.6392 - accuracy: 0.81 - ETA: 3s - loss: 0.6047 - accuracy: 0.82 - ETA: 2s - loss: 0.5835 - accuracy: 0.82 - ETA: 2s - loss: 0.5918 - accuracy: 0.81 - ETA: 2s - loss: 0.5608 - accuracy: 0.82 - ETA: 2s - loss: 0.6113 - accuracy: 0.81 - ETA: 1s - loss: 0.6224 - accuracy: 0.81 - ETA: 1s - loss: 0.6306 - accuracy: 0.80 - ETA: 1s - loss: 0.6313 - accuracy: 0.79 - ETA: 1s - loss: 0.6271 - accuracy: 0.79 - ETA: 0s - loss: 0.6260 - accuracy: 0.79 - ETA: 0s - loss: 0.6283 - accuracy: 0.79 - ETA: 0s - loss: 0.6135 - accuracy: 0.80 - 10s 15ms/step - loss: 0.6093 - accuracy: 0.8006 - val_loss: 0.4722 - val_accuracy: 0.8542\n",
      "Epoch 7/17\n",
      "640/657 [============================>.] - ETA: 23s - loss: 0.7458 - accuracy: 0.750 - ETA: 17s - loss: 0.6467 - accuracy: 0.812 - ETA: 15s - loss: 0.5985 - accuracy: 0.812 - ETA: 13s - loss: 0.6466 - accuracy: 0.796 - ETA: 12s - loss: 0.6417 - accuracy: 0.793 - ETA: 13s - loss: 0.6491 - accuracy: 0.786 - ETA: 11s - loss: 0.6074 - accuracy: 0.803 - ETA: 10s - loss: 0.5828 - accuracy: 0.812 - ETA: 10s - loss: 0.5942 - accuracy: 0.809 - ETA: 9s - loss: 0.5959 - accuracy: 0.806 - ETA: 7s - loss: 0.5921 - accuracy: 0.80 - ETA: 6s - loss: 0.5746 - accuracy: 0.81 - ETA: 5s - loss: 0.5906 - accuracy: 0.79 - ETA: 4s - loss: 0.5923 - accuracy: 0.80 - ETA: 3s - loss: 0.5961 - accuracy: 0.79 - ETA: 3s - loss: 0.5974 - accuracy: 0.79 - ETA: 2s - loss: 0.6017 - accuracy: 0.79 - ETA: 1s - loss: 0.5861 - accuracy: 0.79 - ETA: 0s - loss: 0.5895 - accuracy: 0.79 - ETA: 0s - loss: 0.5829 - accuracy: 0.8016"
     ]
    }
   ],
   "source": [
    "wandb.init()\n",
    "print(y_train_hot.shape)\n",
    "print(labels.shape)\n",
    "print(X_train.shape)\n",
    "# Train the CNN model\n",
    "#    X_train: Input data\n",
    "#    y_train_hot: Target data\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_val, y_val_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the keras model\n",
    "model.save(\"ant_cnn_model.h5\")\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the IntelliChirp Biophony CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('ant_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = loaded_model.predict(X_test)  # shape=(n_samples, 12)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=y_pred_labels)  # shape\n",
    "print(confusion_matrix)\n",
    "\n",
    "for class_i in range(len(labels)) :\n",
    "    indices = np.argwhere(y_test == class_i)\n",
    "    sum = 0\n",
    "    for index in indices:\n",
    "        sum += (y_test[index] == y_pred_labels[index])\n",
    "    if(len(indices) > 0) : mean = sum/len(indices)\n",
    "    else : mean = \"N/A\"\n",
    "    print(\"Accuracy for class\", labels[class_i], \":\", mean)\n",
    "\n",
    "print(\"Overall Accuracy :\", np.mean(y_test == y_pred_labels))\n",
    "\n",
    "'''Accuracy for class AAT : [0.46666667]\n",
    "Accuracy for class AHV : [0.33333333]\n",
    "Accuracy for class AMA : [0.125]\n",
    "Accuracy for class ART : 0\n",
    "Accuracy for class ASI : [0.]\n",
    "Accuracy for class AVH : [0.6]\n",
    "Accuracy for class AVT : [0.92307692]\n",
    "Overall Accuracy : 0.676056338028169'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the model\n",
    "\n",
    "n_mfcc = config.buckets\n",
    "max_len = config.max_len\n",
    "# convert file to wav2mfcc\n",
    "# Mel-frequency cepstral coefficients\n",
    "file_path = \"./prediction/nature_sc.wav\"\n",
    "big_wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "#print(wave.shape, sr)\n",
    "\n",
    "classification = []\n",
    "\n",
    "for sec_index in range( int(big_wave.shape[0] / sr) ) :\n",
    "    start_sec = sec_index\n",
    "    end_sec = sec_index + 1\n",
    "    \n",
    "    sec_to_trim = np.array( [ float(start_sec), float(end_sec) ] )\n",
    "    print(sec_to_trim)\n",
    "    sec_to_trim = np.ceil( sec_to_trim * sr )\n",
    "\n",
    "    wave = big_wave[int(sec_to_trim[0]) : int(sec_to_trim[1])]\n",
    "    print(wave)\n",
    "\n",
    "    wave = np.asfortranarray(wave[::3])\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    # Convert wav to MFCC\n",
    "    prediction_data = wav2mfcc('./prediction/nature_sc.wav')\n",
    "    prediction_data = mfcc\n",
    "    print(prediction_data.shape)\n",
    "    #print(wav2mfcc())\n",
    "    # Reshape to 4 dimensions\n",
    "    prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
    "    #prediction_data = prediction_data.reshape(1, 20, config.max_len, channels)\n",
    "\n",
    "    # Run the model on the inputted file\n",
    "    predicted = loaded_model.predict(prediction_data)\n",
    "\n",
    "    # Output the prediction values for each class\n",
    "    print ('PREDICTED VALUES')\n",
    "    labels_indices = range(len(labels))\n",
    "    max_value = 0\n",
    "    max_value_index = 0\n",
    "    for index in labels_indices:\n",
    "        print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
    "        if predicted[0,index] > max_value:\n",
    "            max_value_index = index\n",
    "            max_value = predicted[0,index]\n",
    "\n",
    "    # Output the prediction\n",
    "    if max_value < 0.5:\n",
    "        print(\"GUESS: Nothing\")\n",
    "        classification.append( { \"class\" : \"Nothing\", \"timestamp\" : start_sec } )\n",
    "    else:\n",
    "        print('\\n\\nGUESS: ', labels[max_value_index])\n",
    "        classification.append( { \"class\" : labels[max_value_index], \"timestamp\" : start_sec } )\n",
    "\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
