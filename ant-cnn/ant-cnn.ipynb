{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, Activation\n",
    "from keras.utils import to_categorical\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/5iidzo5p\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/5iidzo5p</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'AAT': 100%|█████████████████████████████████████████████████| 58/58 [00:01<00:00, 54.05it/s]\n",
      "Saving vectors of label - 'AHV': 100%|█████████████████████████████████████████████████| 16/16 [00:00<00:00, 65.22it/s]\n",
      "Saving vectors of label - 'AMA': 100%|█████████████████████████████████████████████████| 30/30 [00:00<00:00, 61.26it/s]\n",
      "Saving vectors of label - 'ART': 100%|███████████████████████████████████████████████████| 5/5 [00:00<00:00, 53.90it/s]\n",
      "Saving vectors of label - 'ASI': 100%|███████████████████████████████████████████████████| 4/4 [00:00<00:00, 35.81it/s]\n",
      "Saving vectors of label - 'AVH': 100%|█████████████████████████████████████████████████| 18/18 [00:00<00:00, 96.00it/s]\n",
      "Saving vectors of label - 'AVT': 100%|███████████████████████████████████████████████| 222/222 [00:04<00:00, 50.72it/s]\n"
     ]
    }
   ],
   "source": [
    "wandb.init()\n",
    "config = wandb.config\n",
    "\n",
    "config.max_len = 21\n",
    "config.buckets = 50\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
    "\n",
    "#labels=np.array([\"chirping_birds\", \"crickets\", \"crow\", \n",
    "#                 \"frog\", \"insects\"])\n",
    "labels=np.array([\"AAT\", \"AHV\", \"AMA\", \n",
    "                 \"ART\", \"ASI\", \"AVH\",\n",
    "                \"AVT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading train/test set\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting channels to 1 to generalize stereo sound to 1 channel\n",
    "channels = 1\n",
    "config.epochs = 50\n",
    "config.batch_size = 100\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 7\n",
    "\n",
    "# Reshape X_train and X_test to include a 4th dimension (channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], config.buckets, config.max_len, channels)\n",
    "X_val = X_val.reshape(X_val.shape[0], config.buckets, config.max_len, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 50, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "# Spectrogram visualized of 0th element\n",
    "print(X_train.shape)\n",
    "#plt.imshow(X_train[500, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting vector number where each number corresponds to a label\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_val_hot = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 19, 24)        240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 7, 48)         10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 3, 48)          6960      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 101,079\n",
      "Trainable params: 101,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"model.add(Conv2D(32, (3, 3),\\n    input_shape=(config.buckets, config.max_len, channels),\\n    activation='relu'))\\n\\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\\n\\nmodel.add(Flatten())\\n\\nmodel.add(Dense(128, activation='relu'))\\nmodel.add(Dense(num_classes, activation='softmax'))\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "\n",
    "input_shape= (config.buckets, config.max_len, channels)\n",
    "\n",
    "model.add(Conv2D(24, (3, 3), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3), padding=\"valid\"))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 1), padding=\"valid\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(len(labels)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "# Conv2D: \n",
    "#    Filters: 32\n",
    "#    Kernel_size: (3,3) (height/width of the 2D convolution window)     \n",
    "'''model.add(Conv2D(32, (3, 3),\n",
    "    input_shape=(config.buckets, config.max_len, channels),\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure CNN for training\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1r446vev\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1r446vev</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to connect to W&B servers after 10 seconds.                    Letting user process proceed while attempting to reconnect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 7)\n",
      "(7,)\n",
      "(169, 50, 21, 1)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 169 samples, validate on 113 samples\n",
      "Epoch 1/50\n",
      "169/169 [==============================] - ETA: 3s - loss: 7.2267 - accuracy: 0.12 - ETA: 1s - loss: 5.7420 - accuracy: 0.15 - ETA: 0s - loss: 4.6317 - accuracy: 0.25 - ETA: 0s - loss: 3.7351 - accuracy: 0.34 - 1s 8ms/step - loss: 3.6083 - accuracy: 0.3609 - val_loss: 1.2447 - val_accuracy: 0.6991\n",
      "Epoch 2/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.5250 - accuracy: 0.50 - ETA: 0s - loss: 1.6566 - accuracy: 0.50 - ETA: 0s - loss: 1.7947 - accuracy: 0.47 - ETA: 0s - loss: 1.8819 - accuracy: 0.46 - 0s 2ms/step - loss: 1.9045 - accuracy: 0.4675 - val_loss: 1.2482 - val_accuracy: 0.6991\n",
      "Epoch 3/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.7073 - accuracy: 0.43 - ETA: 0s - loss: 2.0419 - accuracy: 0.39 - ETA: 0s - loss: 1.8637 - accuracy: 0.43 - ETA: 0s - loss: 1.8119 - accuracy: 0.40 - ETA: 0s - loss: 1.7048 - accuracy: 0.43 - 0s 3ms/step - loss: 1.6837 - accuracy: 0.4438 - val_loss: 1.1829 - val_accuracy: 0.7168\n",
      "Epoch 4/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.6658 - accuracy: 0.46 - ETA: 0s - loss: 1.4895 - accuracy: 0.55 - ETA: 0s - loss: 1.5428 - accuracy: 0.52 - 0s 1ms/step - loss: 1.5334 - accuracy: 0.5325 - val_loss: 1.1670 - val_accuracy: 0.6991\n",
      "Epoch 5/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1465 - accuracy: 0.75 - ETA: 0s - loss: 1.4339 - accuracy: 0.59 - ETA: 0s - loss: 1.4026 - accuracy: 0.58 - 0s 2ms/step - loss: 1.3955 - accuracy: 0.5917 - val_loss: 1.0805 - val_accuracy: 0.7080\n",
      "Epoch 6/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0407 - accuracy: 0.68 - ETA: 0s - loss: 1.2186 - accuracy: 0.61 - ETA: 0s - loss: 1.3785 - accuracy: 0.55 - 0s 2ms/step - loss: 1.3789 - accuracy: 0.5621 - val_loss: 0.9999 - val_accuracy: 0.7080\n",
      "Epoch 7/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3955 - accuracy: 0.59 - ETA: 0s - loss: 1.3306 - accuracy: 0.59 - ETA: 0s - loss: 1.3788 - accuracy: 0.54 - ETA: 0s - loss: 1.3117 - accuracy: 0.58 - 0s 2ms/step - loss: 1.3064 - accuracy: 0.5858 - val_loss: 1.0428 - val_accuracy: 0.7168\n",
      "Epoch 8/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3417 - accuracy: 0.59 - ETA: 0s - loss: 1.2640 - accuracy: 0.60 - ETA: 0s - loss: 1.2015 - accuracy: 0.65 - 0s 1ms/step - loss: 1.2218 - accuracy: 0.6568 - val_loss: 0.9011 - val_accuracy: 0.7257\n",
      "Epoch 9/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1504 - accuracy: 0.62 - ETA: 0s - loss: 1.2459 - accuracy: 0.60 - ETA: 0s - loss: 1.1888 - accuracy: 0.63 - 0s 2ms/step - loss: 1.1826 - accuracy: 0.6272 - val_loss: 0.8624 - val_accuracy: 0.7522\n",
      "Epoch 10/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.3000 - accuracy: 0.46 - ETA: 0s - loss: 1.2544 - accuracy: 0.57 - ETA: 0s - loss: 1.1616 - accuracy: 0.60 - ETA: 0s - loss: 1.0447 - accuracy: 0.64 - ETA: 0s - loss: 1.0728 - accuracy: 0.63 - 0s 2ms/step - loss: 1.0814 - accuracy: 0.6331 - val_loss: 0.8037 - val_accuracy: 0.7522\n",
      "Epoch 11/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9429 - accuracy: 0.68 - ETA: 0s - loss: 0.8877 - accuracy: 0.71 - ETA: 0s - loss: 0.8898 - accuracy: 0.71 - ETA: 0s - loss: 0.9820 - accuracy: 0.68 - 0s 2ms/step - loss: 0.9709 - accuracy: 0.6864 - val_loss: 0.7861 - val_accuracy: 0.7522\n",
      "Epoch 12/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9820 - accuracy: 0.75 - ETA: 0s - loss: 0.9991 - accuracy: 0.71 - ETA: 0s - loss: 0.9899 - accuracy: 0.68 - 0s 1ms/step - loss: 1.0027 - accuracy: 0.6686 - val_loss: 0.8406 - val_accuracy: 0.7699\n",
      "Epoch 13/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0651 - accuracy: 0.65 - ETA: 0s - loss: 1.0189 - accuracy: 0.62 - ETA: 0s - loss: 1.0346 - accuracy: 0.64 - ETA: 0s - loss: 1.0537 - accuracy: 0.64 - 0s 2ms/step - loss: 1.0476 - accuracy: 0.6509 - val_loss: 0.8063 - val_accuracy: 0.7611\n",
      "Epoch 14/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.1256 - accuracy: 0.68 - ETA: 0s - loss: 1.0219 - accuracy: 0.67 - ETA: 0s - loss: 0.9018 - accuracy: 0.71 - ETA: 0s - loss: 0.8877 - accuracy: 0.71 - 0s 2ms/step - loss: 0.8748 - accuracy: 0.7219 - val_loss: 0.7731 - val_accuracy: 0.7345\n",
      "Epoch 15/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9091 - accuracy: 0.62 - ETA: 0s - loss: 0.7913 - accuracy: 0.73 - ETA: 0s - loss: 0.8411 - accuracy: 0.71 - ETA: 0s - loss: 0.8311 - accuracy: 0.72 - ETA: 0s - loss: 0.8319 - accuracy: 0.71 - 0s 2ms/step - loss: 0.8334 - accuracy: 0.7160 - val_loss: 0.7657 - val_accuracy: 0.7522\n",
      "Epoch 16/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.78 - ETA: 0s - loss: 0.9101 - accuracy: 0.68 - ETA: 0s - loss: 0.9246 - accuracy: 0.70 - 0s 1ms/step - loss: 0.9141 - accuracy: 0.7101 - val_loss: 0.7534 - val_accuracy: 0.8053\n",
      "Epoch 17/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8091 - accuracy: 0.78 - ETA: 0s - loss: 0.7497 - accuracy: 0.79 - ETA: 0s - loss: 0.7920 - accuracy: 0.75 - ETA: 0s - loss: 0.8153 - accuracy: 0.76 - 0s 2ms/step - loss: 0.8270 - accuracy: 0.7633 - val_loss: 0.7277 - val_accuracy: 0.8053\n",
      "Epoch 18/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7300 - accuracy: 0.78 - ETA: 0s - loss: 0.7829 - accuracy: 0.73 - ETA: 0s - loss: 0.7741 - accuracy: 0.75 - 0s 1ms/step - loss: 0.7750 - accuracy: 0.7515 - val_loss: 0.7245 - val_accuracy: 0.7876\n",
      "Epoch 19/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.68 - ETA: 0s - loss: 0.8704 - accuracy: 0.72 - ETA: 0s - loss: 0.8279 - accuracy: 0.74 - ETA: 0s - loss: 0.7921 - accuracy: 0.74 - 0s 2ms/step - loss: 0.7880 - accuracy: 0.7396 - val_loss: 0.7006 - val_accuracy: 0.7965\n",
      "Epoch 20/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7603 - accuracy: 0.75 - ETA: 0s - loss: 0.7032 - accuracy: 0.70 - ETA: 0s - loss: 0.7083 - accuracy: 0.73 - 0s 1ms/step - loss: 0.7161 - accuracy: 0.7278 - val_loss: 0.7300 - val_accuracy: 0.7788\n",
      "Epoch 21/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0.84 - ETA: 0s - loss: 0.6065 - accuracy: 0.78 - ETA: 0s - loss: 0.5819 - accuracy: 0.80 - ETA: 0s - loss: 0.6834 - accuracy: 0.76 - 0s 2ms/step - loss: 0.7078 - accuracy: 0.7515 - val_loss: 0.7210 - val_accuracy: 0.8142\n",
      "Epoch 22/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.71 - ETA: 0s - loss: 0.6816 - accuracy: 0.76 - ETA: 0s - loss: 0.6543 - accuracy: 0.80 - ETA: 0s - loss: 0.7259 - accuracy: 0.77 - 0s 2ms/step - loss: 0.7513 - accuracy: 0.7574 - val_loss: 0.7256 - val_accuracy: 0.8142\n",
      "Epoch 23/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7937 - accuracy: 0.62 - ETA: 0s - loss: 0.6402 - accuracy: 0.75 - ETA: 0s - loss: 0.7434 - accuracy: 0.75 - ETA: 0s - loss: 0.7842 - accuracy: 0.73 - 0s 2ms/step - loss: 0.7803 - accuracy: 0.7337 - val_loss: 0.7280 - val_accuracy: 0.8230\n",
      "Epoch 24/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.7734 - accuracy: 0.68 - ETA: 0s - loss: 0.6359 - accuracy: 0.75 - ETA: 0s - loss: 0.6038 - accuracy: 0.76 - 0s 1ms/step - loss: 0.6388 - accuracy: 0.7811 - val_loss: 0.6599 - val_accuracy: 0.8053\n",
      "Epoch 25/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.78 - ETA: 0s - loss: 0.7275 - accuracy: 0.73 - ETA: 0s - loss: 0.6392 - accuracy: 0.75 - ETA: 0s - loss: 0.6209 - accuracy: 0.77 - ETA: 0s - loss: 0.6329 - accuracy: 0.77 - 0s 3ms/step - loss: 0.6385 - accuracy: 0.7751 - val_loss: 0.6739 - val_accuracy: 0.8142\n",
      "Epoch 26/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6213 - accuracy: 0.75 - ETA: 0s - loss: 0.5333 - accuracy: 0.83 - ETA: 0s - loss: 0.5309 - accuracy: 0.83 - ETA: 0s - loss: 0.5055 - accuracy: 0.83 - 0s 2ms/step - loss: 0.5163 - accuracy: 0.8225 - val_loss: 0.7551 - val_accuracy: 0.7965\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.81 - ETA: 0s - loss: 0.5882 - accuracy: 0.72 - ETA: 0s - loss: 0.6115 - accuracy: 0.74 - ETA: 0s - loss: 0.5959 - accuracy: 0.76 - 0s 2ms/step - loss: 0.6150 - accuracy: 0.7574 - val_loss: 0.6825 - val_accuracy: 0.8053\n",
      "Epoch 28/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.78 - ETA: 0s - loss: 0.6044 - accuracy: 0.80 - 0s 814us/step - loss: 0.5800 - accuracy: 0.8107 - val_loss: 0.6592 - val_accuracy: 0.8142\n",
      "Epoch 29/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.84 - ETA: 0s - loss: 0.4826 - accuracy: 0.84 - ETA: 0s - loss: 0.4482 - accuracy: 0.86 - ETA: 0s - loss: 0.5395 - accuracy: 0.82 - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8284 - val_loss: 0.7025 - val_accuracy: 0.8053\n",
      "Epoch 30/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.90 - ETA: 0s - loss: 0.3292 - accuracy: 0.89 - ETA: 0s - loss: 0.4548 - accuracy: 0.86 - ETA: 0s - loss: 0.4912 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8462 - val_loss: 0.7280 - val_accuracy: 0.8230\n",
      "Epoch 31/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.90 - ETA: 0s - loss: 0.3632 - accuracy: 0.92 - ETA: 0s - loss: 0.3875 - accuracy: 0.89 - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8698 - val_loss: 0.7389 - val_accuracy: 0.8142\n",
      "Epoch 32/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.84 - ETA: 0s - loss: 0.4224 - accuracy: 0.85 - ETA: 0s - loss: 0.4240 - accuracy: 0.85 - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8402 - val_loss: 0.6243 - val_accuracy: 0.8319\n",
      "Epoch 33/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.90 - ETA: 0s - loss: 0.3529 - accuracy: 0.89 - ETA: 0s - loss: 0.4116 - accuracy: 0.86 - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8698 - val_loss: 0.6090 - val_accuracy: 0.8230\n",
      "Epoch 34/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.81 - ETA: 0s - loss: 0.4574 - accuracy: 0.82 - ETA: 0s - loss: 0.4332 - accuracy: 0.83 - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8462 - val_loss: 0.6882 - val_accuracy: 0.8407\n",
      "Epoch 35/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4266 - accuracy: 0.84 - ETA: 0s - loss: 0.3725 - accuracy: 0.87 - ETA: 0s - loss: 0.3253 - accuracy: 0.90 - ETA: 0s - loss: 0.3170 - accuracy: 0.91 - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8994 - val_loss: 0.6899 - val_accuracy: 0.8407\n",
      "Epoch 36/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.84 - ETA: 0s - loss: 0.3540 - accuracy: 0.89 - ETA: 0s - loss: 0.3619 - accuracy: 0.89 - ETA: 0s - loss: 0.3928 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8698 - val_loss: 0.6528 - val_accuracy: 0.8319\n",
      "Epoch 37/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.90 - ETA: 0s - loss: 0.3725 - accuracy: 0.82 - ETA: 0s - loss: 0.4067 - accuracy: 0.88 - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8817 - val_loss: 0.9041 - val_accuracy: 0.7876\n",
      "Epoch 38/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.87 - ETA: 0s - loss: 0.3818 - accuracy: 0.86 - ETA: 0s - loss: 0.3725 - accuracy: 0.86 - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8639 - val_loss: 0.7236 - val_accuracy: 0.8230\n",
      "Epoch 39/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.84 - ETA: 0s - loss: 0.3247 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3705 - accuracy: 0.84 - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8462 - val_loss: 0.7642 - val_accuracy: 0.8053\n",
      "Epoch 40/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2920 - accuracy: 0.90 - ETA: 0s - loss: 0.2666 - accuracy: 0.93 - ETA: 0s - loss: 0.2923 - accuracy: 0.92 - ETA: 0s - loss: 0.2533 - accuracy: 0.93 - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9231 - val_loss: 0.8567 - val_accuracy: 0.7965\n",
      "Epoch 41/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.87 - ETA: 0s - loss: 0.3698 - accuracy: 0.88 - ETA: 0s - loss: 0.3593 - accuracy: 0.89 - ETA: 0s - loss: 0.3353 - accuracy: 0.89 - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8994 - val_loss: 0.7658 - val_accuracy: 0.7965\n",
      "Epoch 42/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.96 - ETA: 0s - loss: 0.1956 - accuracy: 0.95 - ETA: 0s - loss: 0.2661 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2734 - accuracy: 0.8994 - val_loss: 0.7690 - val_accuracy: 0.8142\n",
      "Epoch 43/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.90 - ETA: 0s - loss: 0.3154 - accuracy: 0.87 - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8757 - val_loss: 0.8100 - val_accuracy: 0.7876\n",
      "Epoch 44/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.87 - ETA: 0s - loss: 0.2914 - accuracy: 0.92 - ETA: 0s - loss: 0.2265 - accuracy: 0.93 - ETA: 0s - loss: 0.2922 - accuracy: 0.90 - ETA: 0s - loss: 0.3184 - accuracy: 0.89 - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8994 - val_loss: 0.8384 - val_accuracy: 0.8319\n",
      "Epoch 45/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.96 - ETA: 0s - loss: 0.3334 - accuracy: 0.88 - ETA: 0s - loss: 0.2989 - accuracy: 0.89 - ETA: 0s - loss: 0.2841 - accuracy: 0.89 - 0s 2ms/step - loss: 0.2695 - accuracy: 0.8994 - val_loss: 0.8613 - val_accuracy: 0.8319\n",
      "Epoch 46/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.93 - ETA: 0s - loss: 0.2121 - accuracy: 0.95 - ETA: 0s - loss: 0.2208 - accuracy: 0.94 - ETA: 0s - loss: 0.2141 - accuracy: 0.95 - ETA: 0s - loss: 0.2053 - accuracy: 0.95 - 1s 3ms/step - loss: 0.2044 - accuracy: 0.9586 - val_loss: 0.9388 - val_accuracy: 0.8053\n",
      "Epoch 47/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.93 - ETA: 0s - loss: 0.2067 - accuracy: 0.92 - ETA: 0s - loss: 0.2262 - accuracy: 0.91 - ETA: 0s - loss: 0.1991 - accuracy: 0.92 - ETA: 0s - loss: 0.2069 - accuracy: 0.92 - 1s 3ms/step - loss: 0.2020 - accuracy: 0.9290 - val_loss: 0.9359 - val_accuracy: 0.8053\n",
      "Epoch 48/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - ETA: 0s - loss: 0.0893 - accuracy: 0.96 - ETA: 0s - loss: 0.1339 - accuracy: 0.95 - ETA: 0s - loss: 0.1701 - accuracy: 0.93 - ETA: 0s - loss: 0.1636 - accuracy: 0.93 - 1s 3ms/step - loss: 0.1659 - accuracy: 0.9290 - val_loss: 0.8759 - val_accuracy: 0.8142\n",
      "Epoch 49/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.93 - ETA: 0s - loss: 0.1959 - accuracy: 0.93 - ETA: 0s - loss: 0.1760 - accuracy: 0.95 - ETA: 0s - loss: 0.1967 - accuracy: 0.93 - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9408 - val_loss: 0.8242 - val_accuracy: 0.7965\n",
      "Epoch 50/50\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.93 - ETA: 0s - loss: 0.1210 - accuracy: 0.95 - ETA: 0s - loss: 0.1158 - accuracy: 0.96 - ETA: 0s - loss: 0.1389 - accuracy: 0.95 - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9467 - val_loss: 0.9015 - val_accuracy: 0.7965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b0da70b9c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()\n",
    "print(y_train_hot.shape)\n",
    "print(labels.shape)\n",
    "print(X_train.shape)\n",
    "# Train the CNN model\n",
    "#    X_train: Input data\n",
    "#    y_train_hot: Target data\n",
    "model.fit(X_train, y_train_hot, epochs=config.epochs, validation_data=(X_val, y_val_hot), callbacks=[WandbCallback(data_type=\"image\", labels=labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the keras model\n",
    "model.save(\"ant_cnn_model.h5\")\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the IntelliChirp Biophony CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('ant_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 19, 24)        240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 9, 24)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 7, 48)         10416     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 3, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 3, 48)          6960      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 3, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 101,079\n",
      "Trainable params: 101,079\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  0  0  0  0  8]\n",
      " [ 0  1  0  0  0  2]\n",
      " [ 0  0  1  0  0  7]\n",
      " [ 0  0  0  0  0  1]\n",
      " [ 0  0  0  0  3  2]\n",
      " [ 2  0  1  0  0 36]]\n",
      "Accuracy for class AAT : [0.46666667]\n",
      "Accuracy for class AHV : [0.33333333]\n",
      "Accuracy for class AMA : [0.125]\n",
      "Accuracy for class ART : 0\n",
      "Accuracy for class ASI : [0.]\n",
      "Accuracy for class AVH : [0.6]\n",
      "Accuracy for class AVT : [0.92307692]\n",
      "Overall Accuracy : 0.676056338028169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy for class chirping_birds : [0.8]\\nAccuracy for class crickets : [0.25]\\nAccuracy for class crow : [0.83333333]\\nAccuracy for class frog : [0.3]\\nAccuracy for class insects : [0.85714286]\\nOverall Accuracy : 0.525'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ohe = loaded_model.predict(X_test)  # shape=(n_samples, 12)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)  # only necessary if output has one-hot-encoding, shape=(n_samples)\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_test, y_pred=y_pred_labels)  # shape\n",
    "print(confusion_matrix)\n",
    "\n",
    "for class_i in range(len(labels)) :\n",
    "    indices = np.argwhere(y_test == class_i)\n",
    "    sum = 0\n",
    "    for index in indices:\n",
    "        sum += (y_test[index] == y_pred_labels[index])\n",
    "    if(len(indices) > 0) : mean = sum/len(indices)\n",
    "    else : mean = \"N/A\"\n",
    "    print(\"Accuracy for class\", labels[class_i], \":\", mean)\n",
    "\n",
    "print(\"Overall Accuracy :\", np.mean(y_test == y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[ 0.0000000e+00  1.5258789e-05  0.0000000e+00 ...  3.3020020e-02\n",
      "  1.2680054e-02 -8.7432861e-03]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.01039583\n",
      "\n",
      " AHV :  0.02998595\n",
      "\n",
      " AMA :  0.02692612\n",
      "\n",
      " ART :  0.00021275\n",
      "\n",
      " ASI :  0.00109535\n",
      "\n",
      " AVH :  0.00171419\n",
      "\n",
      " AVT :  0.92966986\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[1. 2.]\n",
      "[-0.03717041 -0.05769348 -0.06455994 ...  0.01766968  0.01895142\n",
      "  0.01779175]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.09363972\n",
      "\n",
      " AHV :  0.27155691\n",
      "\n",
      " AMA :  0.11288872\n",
      "\n",
      " ART :  0.00317154\n",
      "\n",
      " ASI :  0.00362689\n",
      "\n",
      " AVH :  0.00379819\n",
      "\n",
      " AVT :  0.51131809\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[2. 3.]\n",
      "[ 0.02345276  0.02101135  0.01712036 ... -0.01161194 -0.0141449\n",
      " -0.01431274]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.02302537\n",
      "\n",
      " AHV :  0.34436873\n",
      "\n",
      " AMA :  0.12974481\n",
      "\n",
      " ART :  0.00235426\n",
      "\n",
      " ASI :  0.00554969\n",
      "\n",
      " AVH :  0.01236655\n",
      "\n",
      " AVT :  0.48259062\n",
      "GUESS: Nothing\n",
      "[3. 4.]\n",
      "[-0.01583862 -0.01066589 -0.00762939 ... -0.0377655  -0.03556824\n",
      " -0.02685547]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00185250\n",
      "\n",
      " AHV :  0.01309109\n",
      "\n",
      " AMA :  0.00708705\n",
      "\n",
      " ART :  0.00006909\n",
      "\n",
      " ASI :  0.00058765\n",
      "\n",
      " AVH :  0.00124668\n",
      "\n",
      " AVT :  0.97606587\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[4. 5.]\n",
      "[-0.02836609 -0.02510071 -0.02012634 ...  0.0138855  -0.00386047\n",
      " -0.00904846]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00043267\n",
      "\n",
      " AHV :  0.02111147\n",
      "\n",
      " AMA :  0.04168708\n",
      "\n",
      " ART :  0.00007569\n",
      "\n",
      " ASI :  0.00024637\n",
      "\n",
      " AVH :  0.00020514\n",
      "\n",
      " AVT :  0.93624163\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[5. 6.]\n",
      "[-0.00526428  0.00822449  0.01951599 ...  0.02729797  0.02156067\n",
      "  0.01234436]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00642328\n",
      "\n",
      " AHV :  0.20216547\n",
      "\n",
      " AMA :  0.25181180\n",
      "\n",
      " ART :  0.00056665\n",
      "\n",
      " ASI :  0.00074299\n",
      "\n",
      " AVH :  0.00098468\n",
      "\n",
      " AVT :  0.53730518\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[6. 7.]\n",
      "[ 0.00544739  0.00053406  0.00970459 ... -0.02848816 -0.01611328\n",
      " -0.01091003]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00057033\n",
      "\n",
      " AHV :  0.00731208\n",
      "\n",
      " AMA :  0.00087687\n",
      "\n",
      " ART :  0.00000403\n",
      "\n",
      " ASI :  0.00005995\n",
      "\n",
      " AVH :  0.00019443\n",
      "\n",
      " AVT :  0.99098223\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[7. 8.]\n",
      "[-0.0177002  -0.02372742 -0.02700806 ... -0.04304504 -0.04063416\n",
      " -0.03363037]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000483\n",
      "\n",
      " AHV :  0.00022814\n",
      "\n",
      " AMA :  0.00036886\n",
      "\n",
      " ART :  0.00000013\n",
      "\n",
      " ASI :  0.00000414\n",
      "\n",
      " AVH :  0.00000038\n",
      "\n",
      " AVT :  0.99939358\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[8. 9.]\n",
      "[-0.01539612 -0.00108337  0.00718689 ...  0.01161194  0.01818848\n",
      "  0.02700806]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000965\n",
      "\n",
      " AHV :  0.01190078\n",
      "\n",
      " AMA :  0.00533848\n",
      "\n",
      " ART :  0.00000082\n",
      "\n",
      " ASI :  0.00000508\n",
      "\n",
      " AVH :  0.00000422\n",
      "\n",
      " AVT :  0.98274094\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[ 9. 10.]\n",
      "[ 0.03549194  0.04856873  0.05519104 ... -0.02171326 -0.03634644\n",
      " -0.03912354]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00016367\n",
      "\n",
      " AHV :  0.02253050\n",
      "\n",
      " AMA :  0.00854565\n",
      "\n",
      " ART :  0.00000365\n",
      "\n",
      " ASI :  0.00008337\n",
      "\n",
      " AVH :  0.00025015\n",
      "\n",
      " AVT :  0.96842301\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[10. 11.]\n",
      "[-0.02934265 -0.0115509   0.00445557 ... -0.03616333 -0.03759766\n",
      " -0.0304718 ]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00002215\n",
      "\n",
      " AHV :  0.00093671\n",
      "\n",
      " AMA :  0.00037632\n",
      "\n",
      " ART :  0.00000074\n",
      "\n",
      " ASI :  0.00000892\n",
      "\n",
      " AVH :  0.00000542\n",
      "\n",
      " AVT :  0.99864978\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[11. 12.]\n",
      "[-0.03358459 -0.03901672 -0.03933716 ... -0.02337646 -0.02124023\n",
      " -0.02107239]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.01750475\n",
      "\n",
      " AHV :  0.13233173\n",
      "\n",
      " AMA :  0.06346360\n",
      "\n",
      " ART :  0.00163204\n",
      "\n",
      " ASI :  0.00448596\n",
      "\n",
      " AVH :  0.00566114\n",
      "\n",
      " AVT :  0.77492076\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[12. 13.]\n",
      "[-0.00846863  0.00444031  0.00852966 ... -0.00604248 -0.00845337\n",
      " -0.00497437]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00227106\n",
      "\n",
      " AHV :  0.03145981\n",
      "\n",
      " AMA :  0.01022883\n",
      "\n",
      " ART :  0.00009338\n",
      "\n",
      " ASI :  0.00125850\n",
      "\n",
      " AVH :  0.00117838\n",
      "\n",
      " AVT :  0.95350999\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[13. 14.]\n",
      "[-0.00427246 -0.00718689 -0.00811768 ... -0.01966858 -0.01296997\n",
      " -0.01628113]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.01924668\n",
      "\n",
      " AHV :  0.05086352\n",
      "\n",
      " AMA :  0.00325990\n",
      "\n",
      " ART :  0.00030024\n",
      "\n",
      " ASI :  0.00159845\n",
      "\n",
      " AVH :  0.00078041\n",
      "\n",
      " AVT :  0.92395073\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[14. 15.]\n",
      "[-0.02262878 -0.01573181 -0.00117493 ... -0.08956909 -0.0695343\n",
      " -0.04067993]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00017223\n",
      "\n",
      " AHV :  0.01953383\n",
      "\n",
      " AMA :  0.01624575\n",
      "\n",
      " ART :  0.00002341\n",
      "\n",
      " ASI :  0.00031366\n",
      "\n",
      " AVH :  0.00020480\n",
      "\n",
      " AVT :  0.96350634\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[15. 16.]\n",
      "[-0.02532959 -0.01031494 -0.00280762 ... -0.07128906 -0.07106018\n",
      " -0.05839539]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00245207\n",
      "\n",
      " AHV :  0.07802935\n",
      "\n",
      " AMA :  0.02046134\n",
      "\n",
      " ART :  0.00002834\n",
      "\n",
      " ASI :  0.00016393\n",
      "\n",
      " AVH :  0.00104307\n",
      "\n",
      " AVT :  0.89782184\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[16. 17.]\n",
      "[-0.04600525 -0.02149963  0.00523376 ... -0.02526855 -0.02735901\n",
      " -0.03106689]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00007982\n",
      "\n",
      " AHV :  0.00001830\n",
      "\n",
      " AMA :  0.00000174\n",
      "\n",
      " ART :  0.00000002\n",
      "\n",
      " ASI :  0.00000414\n",
      "\n",
      " AVH :  0.00000063\n",
      "\n",
      " AVT :  0.99989533\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[17. 18.]\n",
      "[-0.02043152 -0.01174927 -0.02088928 ...  0.10055542  0.08653259\n",
      "  0.06604004]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000969\n",
      "\n",
      " AHV :  0.00028962\n",
      "\n",
      " AMA :  0.00005419\n",
      "\n",
      " ART :  0.00000001\n",
      "\n",
      " ASI :  0.00000105\n",
      "\n",
      " AVH :  0.00000232\n",
      "\n",
      " AVT :  0.99964309\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[18. 19.]\n",
      "[ 0.04153442  0.01223755 -0.00654602 ...  0.03269958  0.02374268\n",
      "  0.02774048]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000010\n",
      "\n",
      " AHV :  0.00004137\n",
      "\n",
      " AMA :  0.00000706\n",
      "\n",
      " ART :  0.00000000\n",
      "\n",
      " ASI :  0.00000019\n",
      "\n",
      " AVH :  0.00000003\n",
      "\n",
      " AVT :  0.99995124\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[19. 20.]\n",
      "[0.02185059 0.02069092 0.01451111 ... 0.03469849 0.03985596 0.04600525]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000012\n",
      "\n",
      " AHV :  0.00003513\n",
      "\n",
      " AMA :  0.00000929\n",
      "\n",
      " ART :  0.00000000\n",
      "\n",
      " ASI :  0.00000009\n",
      "\n",
      " AVH :  0.00000006\n",
      "\n",
      " AVT :  0.99995530\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[20. 21.]\n",
      "[ 0.0353241   0.01567078 -0.00102234 ...  0.1058197   0.10365295\n",
      "  0.09759521]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00005120\n",
      "\n",
      " AHV :  0.00411852\n",
      "\n",
      " AMA :  0.00619672\n",
      "\n",
      " ART :  0.00000305\n",
      "\n",
      " ASI :  0.00002620\n",
      "\n",
      " AVH :  0.00000808\n",
      "\n",
      " AVT :  0.98959631\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[21. 22.]\n",
      "[ 0.09413147  0.07905579  0.05625916 ... -0.01145935 -0.00245667\n",
      "  0.00479126]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00114753\n",
      "\n",
      " AHV :  0.00382689\n",
      "\n",
      " AMA :  0.00077986\n",
      "\n",
      " ART :  0.00001058\n",
      "\n",
      " ASI :  0.00037801\n",
      "\n",
      " AVH :  0.00018464\n",
      "\n",
      " AVT :  0.99367249\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[22. 23.]\n",
      "[ 0.0037384   0.01168823  0.01628113 ... -0.03440857 -0.05511475\n",
      " -0.08209229]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000152\n",
      "\n",
      " AHV :  0.00005573\n",
      "\n",
      " AMA :  0.00021121\n",
      "\n",
      " ART :  0.00000004\n",
      "\n",
      " ASI :  0.00000169\n",
      "\n",
      " AVH :  0.00000060\n",
      "\n",
      " AVT :  0.99972910\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[23. 24.]\n",
      "[-0.1026001  -0.12590027 -0.14944458 ...  0.03462219  0.02537537\n",
      "  0.02354431]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000002\n",
      "\n",
      " AHV :  0.00002918\n",
      "\n",
      " AMA :  0.00004254\n",
      "\n",
      " ART :  0.00000000\n",
      "\n",
      " ASI :  0.00000003\n",
      "\n",
      " AVH :  0.00000002\n",
      "\n",
      " AVT :  0.99992824\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[24. 25.]\n",
      "[ 0.0196991   0.02836609  0.03103638 ... -0.03009033 -0.03392029\n",
      " -0.03681946]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000001\n",
      "\n",
      " AHV :  0.00000161\n",
      "\n",
      " AMA :  0.00000013\n",
      "\n",
      " ART :  0.00000000\n",
      "\n",
      " ASI :  0.00000000\n",
      "\n",
      " AVH :  0.00000001\n",
      "\n",
      " AVT :  0.99999821\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[25. 26.]\n",
      "[-0.04151917 -0.03933716 -0.03703308 ...  0.05451965  0.0519104\n",
      "  0.05206299]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000180\n",
      "\n",
      " AHV :  0.00018425\n",
      "\n",
      " AMA :  0.00016731\n",
      "\n",
      " ART :  0.00000001\n",
      "\n",
      " ASI :  0.00000116\n",
      "\n",
      " AVH :  0.00000147\n",
      "\n",
      " AVT :  0.99964404\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[26. 27.]\n",
      "[ 0.05670166  0.06253052  0.07643127 ... -0.00396729  0.00715637\n",
      "  0.00585938]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.01121760\n",
      "\n",
      " AHV :  0.07370803\n",
      "\n",
      " AMA :  0.02433188\n",
      "\n",
      " ART :  0.00040088\n",
      "\n",
      " ASI :  0.00094076\n",
      "\n",
      " AVH :  0.00137472\n",
      "\n",
      " AVT :  0.88802618\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[27. 28.]\n",
      "[-0.00222778 -0.01303101 -0.02310181 ...  0.01165771  0.01649475\n",
      "  0.0194397 ]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00336064\n",
      "\n",
      " AHV :  0.08237971\n",
      "\n",
      " AMA :  0.02419341\n",
      "\n",
      " ART :  0.00006977\n",
      "\n",
      " ASI :  0.00062790\n",
      "\n",
      " AVH :  0.00069706\n",
      "\n",
      " AVT :  0.88867158\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[28. 29.]\n",
      "[0.01657104 0.01519775 0.00924683 ... 0.03746033 0.03282166 0.02775574]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.01933225\n",
      "\n",
      " AHV :  0.01141812\n",
      "\n",
      " AMA :  0.00131822\n",
      "\n",
      " ART :  0.00006861\n",
      "\n",
      " ASI :  0.00037114\n",
      "\n",
      " AVH :  0.00009131\n",
      "\n",
      " AVT :  0.96740037\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[29. 30.]\n",
      "[ 0.01919556  0.0135498   0.01724243 ... -0.00575256 -0.01502991\n",
      " -0.02742004]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00067066\n",
      "\n",
      " AHV :  0.00015495\n",
      "\n",
      " AMA :  0.00002473\n",
      "\n",
      " ART :  0.00000080\n",
      "\n",
      " ASI :  0.00005628\n",
      "\n",
      " AVH :  0.00000687\n",
      "\n",
      " AVT :  0.99908578\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[30. 31.]\n",
      "[-0.0322876  -0.0365448  -0.03544617 ... -0.0218811  -0.02978516\n",
      " -0.04052734]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000241\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AHV :  0.00321765\n",
      "\n",
      " AMA :  0.00698048\n",
      "\n",
      " ART :  0.00000044\n",
      "\n",
      " ASI :  0.00000350\n",
      "\n",
      " AVH :  0.00000469\n",
      "\n",
      " AVT :  0.98979086\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[31. 32.]\n",
      "[-0.04328918 -0.03413391 -0.03421021 ...  0.05908203  0.06370544\n",
      "  0.05949402]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00053715\n",
      "\n",
      " AHV :  0.00938936\n",
      "\n",
      " AMA :  0.00308272\n",
      "\n",
      " ART :  0.00004391\n",
      "\n",
      " ASI :  0.00017127\n",
      "\n",
      " AVH :  0.00006393\n",
      "\n",
      " AVT :  0.98671162\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[32. 33.]\n",
      "[ 0.06063843  0.06056213  0.06610107 ... -0.12741089 -0.13371277\n",
      " -0.12313843]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000053\n",
      "\n",
      " AHV :  0.00012500\n",
      "\n",
      " AMA :  0.00003068\n",
      "\n",
      " ART :  0.00000000\n",
      "\n",
      " ASI :  0.00000027\n",
      "\n",
      " AVH :  0.00000024\n",
      "\n",
      " AVT :  0.99984336\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[33. 34.]\n",
      "[-0.09968567 -0.06376648 -0.03105164 ... -0.0138092  -0.01574707\n",
      " -0.01896667]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00000420\n",
      "\n",
      " AHV :  0.00023515\n",
      "\n",
      " AMA :  0.00047268\n",
      "\n",
      " ART :  0.00000002\n",
      "\n",
      " ASI :  0.00000135\n",
      "\n",
      " AVH :  0.00000821\n",
      "\n",
      " AVT :  0.99927837\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[34. 35.]\n",
      "[-0.00811768  0.00149536  0.00953674 ... -0.004776   -0.0010376\n",
      "  0.00231934]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.00044373\n",
      "\n",
      " AHV :  0.00030428\n",
      "\n",
      " AMA :  0.00006797\n",
      "\n",
      " ART :  0.00000190\n",
      "\n",
      " ASI :  0.00005193\n",
      "\n",
      " AVH :  0.00001423\n",
      "\n",
      " AVT :  0.99911588\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[35. 36.]\n",
      "[ 0.00238037  0.00236511  0.00231934 ... -0.00193787  0.0068512\n",
      "  0.00695801]\n",
      "(50, 21)\n",
      "PREDICTED VALUES\n",
      "\n",
      " AAT :  0.06506672\n",
      "\n",
      " AHV :  0.15438803\n",
      "\n",
      " AMA :  0.04633104\n",
      "\n",
      " ART :  0.00296247\n",
      "\n",
      " ASI :  0.00386099\n",
      "\n",
      " AVH :  0.00411445\n",
      "\n",
      " AVT :  0.72327632\n",
      "\n",
      "\n",
      "GUESS:  AVT\n",
      "[{'class': 'AVT', 'timestamp': 0}, {'class': 'AVT', 'timestamp': 1}, {'class': 'Nothing', 'timestamp': 2}, {'class': 'AVT', 'timestamp': 3}, {'class': 'AVT', 'timestamp': 4}, {'class': 'AVT', 'timestamp': 5}, {'class': 'AVT', 'timestamp': 6}, {'class': 'AVT', 'timestamp': 7}, {'class': 'AVT', 'timestamp': 8}, {'class': 'AVT', 'timestamp': 9}, {'class': 'AVT', 'timestamp': 10}, {'class': 'AVT', 'timestamp': 11}, {'class': 'AVT', 'timestamp': 12}, {'class': 'AVT', 'timestamp': 13}, {'class': 'AVT', 'timestamp': 14}, {'class': 'AVT', 'timestamp': 15}, {'class': 'AVT', 'timestamp': 16}, {'class': 'AVT', 'timestamp': 17}, {'class': 'AVT', 'timestamp': 18}, {'class': 'AVT', 'timestamp': 19}, {'class': 'AVT', 'timestamp': 20}, {'class': 'AVT', 'timestamp': 21}, {'class': 'AVT', 'timestamp': 22}, {'class': 'AVT', 'timestamp': 23}, {'class': 'AVT', 'timestamp': 24}, {'class': 'AVT', 'timestamp': 25}, {'class': 'AVT', 'timestamp': 26}, {'class': 'AVT', 'timestamp': 27}, {'class': 'AVT', 'timestamp': 28}, {'class': 'AVT', 'timestamp': 29}, {'class': 'AVT', 'timestamp': 30}, {'class': 'AVT', 'timestamp': 31}, {'class': 'AVT', 'timestamp': 32}, {'class': 'AVT', 'timestamp': 33}, {'class': 'AVT', 'timestamp': 34}, {'class': 'AVT', 'timestamp': 35}]\n"
     ]
    }
   ],
   "source": [
    "## Running the model\n",
    "\n",
    "n_mfcc = config.buckets\n",
    "max_len = config.max_len\n",
    "# convert file to wav2mfcc\n",
    "# Mel-frequency cepstral coefficients\n",
    "file_path = \"./prediction/nature_sc.wav\"\n",
    "big_wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "#print(wave.shape, sr)\n",
    "\n",
    "classification = []\n",
    "\n",
    "for sec_index in range( int(big_wave.shape[0] / sr) ) :\n",
    "    start_sec = sec_index\n",
    "    end_sec = sec_index + 1\n",
    "    \n",
    "    sec_to_trim = np.array( [ float(start_sec), float(end_sec) ] )\n",
    "    print(sec_to_trim)\n",
    "    sec_to_trim = np.ceil( sec_to_trim * sr )\n",
    "\n",
    "    wave = big_wave[int(sec_to_trim[0]) : int(sec_to_trim[1])]\n",
    "    print(wave)\n",
    "\n",
    "    wave = np.asfortranarray(wave[::3])\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)\n",
    "\n",
    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    # Else cutoff the remaining parts\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    # Convert wav to MFCC\n",
    "    prediction_data = wav2mfcc('./prediction/nature_sc.wav')\n",
    "    prediction_data = mfcc\n",
    "    print(prediction_data.shape)\n",
    "    #print(wav2mfcc())\n",
    "    # Reshape to 4 dimensions\n",
    "    prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
    "    #prediction_data = prediction_data.reshape(1, 20, config.max_len, channels)\n",
    "\n",
    "    # Run the model on the inputted file\n",
    "    predicted = loaded_model.predict(prediction_data)\n",
    "\n",
    "    # Output the prediction values for each class\n",
    "    print ('PREDICTED VALUES')\n",
    "    labels_indices = range(len(labels))\n",
    "    max_value = 0\n",
    "    max_value_index = 0\n",
    "    for index in labels_indices:\n",
    "        print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
    "        if predicted[0,index] > max_value:\n",
    "            max_value_index = index\n",
    "            max_value = predicted[0,index]\n",
    "\n",
    "    # Output the prediction\n",
    "    if max_value < 0.5:\n",
    "        print(\"GUESS: Nothing\")\n",
    "        classification.append( { \"class\" : \"Nothing\", \"timestamp\" : start_sec } )\n",
    "    else:\n",
    "        print('\\n\\nGUESS: ', labels[max_value_index])\n",
    "        classification.append( { \"class\" : labels[max_value_index], \"timestamp\" : start_sec } )\n",
    "\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
