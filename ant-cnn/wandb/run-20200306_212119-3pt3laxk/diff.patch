diff --git a/ant-cnn/ant-cnn.ipynb b/ant-cnn/ant-cnn.ipynb
index 27b1e94..a3ec2c4 100644
--- a/ant-cnn/ant-cnn.ipynb
+++ b/ant-cnn/ant-cnn.ipynb
@@ -2,581 +2,9 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 23,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Using TensorFlow backend.\n",
-      "C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3201: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
-      "  if training is 1 or training is True:\n",
-      "C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3207: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
-      "  elif training is 0 or training is False:\n",
-      "ERROR:root:Internal Python error in the inspect module.\n",
-      "Below is the traceback from this internal error.\n",
-      "\n",
-      "ERROR:root:Internal Python error in the inspect module.\n",
-      "Below is the traceback from this internal error.\n",
-      "\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
-      "    # Try the default getinnerframes and Alex's: Alex's fixes some\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
-      "    inspect.findsource = findsource\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
-      "    def _fixed_getinnerframes(etb, context=1, tb_offset=0):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1503, in getinnerframes\n",
-      "    def trace(context=1):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1461, in getframeinfo\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 708, in getsourcefile\n",
-      "    _filename = getsourcefile(object) or getfile(object)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 745, in getmodule\n",
-      "    # Check the main module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
-      "    from . _api.v2 import audio\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
-      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 8, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
-      "    if (await self.run_code(code, result,  async_=asy)):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\n",
-      "    self.showtraceback(running_compiled_code=True)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
-      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1414, in structured_traceback\n",
-      "    self.tb = tb[0]\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1314, in structured_traceback\n",
-      "    mode = self.mode\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\n",
-      "    formatted_exceptions = formatted_exception\n",
-      "TypeError: can only concatenate str (not \"list\") to str\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
-      "    # Try the default getinnerframes and Alex's: Alex's fixes some\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
-      "    inspect.findsource = findsource\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
-      "    def _fixed_getinnerframes(etb, context=1, tb_offset=0):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1503, in getinnerframes\n",
-      "    def trace(context=1):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1461, in getframeinfo\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 708, in getsourcefile\n",
-      "    _filename = getsourcefile(object) or getfile(object)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 745, in getmodule\n",
-      "    # Check the main module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
-      "    from . _api.v2 import audio\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
-      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 8, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
-      "    if (await self.run_code(code, result,  async_=asy)):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\n",
-      "    self.showtraceback(running_compiled_code=True)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
-      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1414, in structured_traceback\n",
-      "    self.tb = tb[0]\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1314, in structured_traceback\n",
-      "    mode = self.mode\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\n",
-      "    formatted_exceptions = formatted_exception\n",
-      "TypeError: can only concatenate str (not \"list\") to str\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n"
-     ]
-    },
-    {
-     "ename": "TypeError",
-     "evalue": "can only concatenate str (not \"list\") to str",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m--> 342\u001b[1;33m             name=name, loader=loader, origin=path)\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mImportError\u001b[0m: Module use of python36.dll conflicts with this version of Python.",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mAttributeError\u001b[0m: 'ImportError' object has no attribute '_render_traceback_'",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3347\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3348\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3350\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[1;31m# tb is a tuple if this is a chained exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1414\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[0mtb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb_offset\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtb_offset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[0mlines_of_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m         \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "from preprocess import *\n",
     "import keras\n",
@@ -590,7 +18,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 24,
    "metadata": {},
    "outputs": [
     {
@@ -598,8 +26,8 @@
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized/runs/iqcktkix\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized/runs/iqcktkix</a><br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1amrp2vv\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1amrp2vv</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -613,17 +41,18 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
-      "Saving vectors of label - 'bus': 100%|| 109/109 [00:04<00:00, 22.23it/s]\n",
-      "Saving vectors of label - 'car_horn': 100%|| 40/40 [00:00<00:00, 68.21it/s]\n",
-      "Saving vectors of label - 'chainsaw': 100%|| 40/40 [00:00<00:00, 43.29it/s]\n",
-      "Saving vectors of label - 'cow': 100%|| 40/40 [00:00<00:00, 54.85it/s]\n",
-      "Saving vectors of label - 'engine': 100%|| 40/40 [00:00<00:00, 54.93it/s]\n",
-      "Saving vectors of label - 'footsteps': 100%|| 40/40 [00:00<00:00, 65.51it/s]\n",
-      "Saving vectors of label - 'hand_saw': 100%|| 40/40 [00:00<00:00, 53.98it/s]\n",
-      "Saving vectors of label - 'hen': 100%|| 40/40 [00:00<00:00, 65.41it/s]\n",
-      "Saving vectors of label - 'rooster': 100%|| 40/40 [00:00<00:00, 68.64it/s]\n",
-      "Saving vectors of label - 'siren': 100%|| 40/40 [00:00<00:00, 55.64it/s]\n"
+      "Saving vectors of label - 'bus': 100%|| 109/109 [00:04<00:00, 22.10it/s]\n",
+      "Saving vectors of label - 'car_horn': 100%|| 40/40 [00:00<00:00, 53.62it/s]\n",
+      "Saving vectors of label - 'chainsaw': 100%|| 40/40 [00:00<00:00, 79.26it/s]\n",
+      "Saving vectors of label - 'cow': 100%|| 40/40 [00:00<00:00, 53.12it/s]\n",
+      "Saving vectors of label - 'engine': 100%|| 40/40 [00:00<00:00, 53.27it/s]\n",
+      "Saving vectors of label - 'footsteps': 100%|| 40/40 [00:00<00:00, 80.86it/s]\n",
+      "Saving vectors of label - 'hand_saw': 100%|| 40/40 [00:00<00:00, 49.58it/s]\n",
+      "Saving vectors of label - 'hen': 100%|| 40/40 [00:01<00:00, 35.87it/s]\n",
+      "Saving vectors of label - 'NO': 100%|| 802/802 [00:14<00:00, 56.67it/s]\n",
+      "Saving vectors of label - 'rooster': 100%|| 40/40 [00:00<00:00, 46.05it/s]\n",
+      "Saving vectors of label - 'siren': 100%|| 40/40 [00:00<00:00, 57.46it/s]\n",
+      "Saving vectors of label - 'train': 100%|| 40/40 [00:00<00:00, 63.46it/s]\n"
      ]
     }
    ],
@@ -637,12 +66,13 @@
     "# Save data to array file first\n",
     "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
     "\n",
-    "labels=[\"bus\", \"car_horn\", \"chainsaw\", \"cow\", \"engine\", \"footsteps\", \"hand_saw\", \"hen\", \"rooster\", \"siren\"]"
+    "labels=np.array([\"bus\", \"car_horn\", \"chainsaw\", \"cow\", \"engine\", \"footsteps\", \n",
+    "                 \"hand_saw\", \"hen\", \"NO\", \"rooster\", \"siren\", \"train\"])"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 25,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -652,17 +82,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 26,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Setting channels to 1 to generalize stereo sound to 1 channel\n",
     "channels = 1\n",
@@ -670,7 +92,7 @@
     "config.batch_size = 100\n",
     "\n",
     "# Number of classes\n",
-    "num_classes = 10\n",
+    "num_classes = 12\n",
     "\n",
     "# Reshape X_train and X_test to include a 4th dimension (channels)\n",
     "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
@@ -679,19 +101,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 27,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "3.0\n"
+      "0.0\n"
      ]
     },
     {
      "data": {
-      "image/png": "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\n",
+      "image/png": "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\n",
       "text/plain": [
        "<Figure size 432x288 with 1 Axes>"
       ]
@@ -710,7 +132,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 28,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -721,7 +143,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 29,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -745,7 +167,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 30,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -757,7 +179,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 31,
    "metadata": {
     "scrolled": false
    },
@@ -767,8 +189,8 @@
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized/runs/7sybendi\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized/runs/7sybendi</a><br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/6r9mxd00\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/6r9mxd00</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -778,134 +200,180 @@
      "metadata": {},
      "output_type": "display_data"
     },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
-     ]
-    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Train on 281 samples, validate on 188 samples\n",
+      "(786, 12)\n",
+      "(12,)\n",
+      "(786, 20, 11, 1)\n",
+      "Train on 786 samples, validate on 525 samples\n",
       "Epoch 1/50\n",
-      "281/281 [==============================] - ETA: 2s - loss: 23.0465 - accuracy: 0.093 - ETA: 0s - loss: 16.3184 - accuracy: 0.085 - 0s 2ms/step - loss: 12.3469 - accuracy: 0.1530 - val_loss: 6.6698 - val_accuracy: 0.2766\n",
+      "786/786 [==============================] - ETA: 14s - loss: 41.3893 - accuracy: 0.0000e+ - ETA: 3s - loss: 19.0839 - accuracy: 0.3359     - ETA: 1s - loss: 12.7220 - accuracy: 0.406 - ETA: 0s - loss: 10.3189 - accuracy: 0.448 - ETA: 0s - loss: 9.9067 - accuracy: 0.455 - ETA: 0s - loss: 8.4874 - accuracy: 0.47 - ETA: 0s - loss: 8.2760 - accuracy: 0.47 - 1s 2ms/step - loss: 7.8985 - accuracy: 0.4796 - val_loss: 3.7482 - val_accuracy: 0.5048\n",
       "Epoch 2/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 5.0918 - accuracy: 0.31 - ETA: 0s - loss: 4.7224 - accuracy: 0.26 - 0s 333us/step - loss: 4.5251 - accuracy: 0.2776 - val_loss: 3.5798 - val_accuracy: 0.3138\n",
+      "786/786 [==============================] - ETA: 0s - loss: 2.8751 - accuracy: 0.53 - ETA: 0s - loss: 2.6696 - accuracy: 0.59 - ETA: 0s - loss: 2.7878 - accuracy: 0.56 - ETA: 0s - loss: 2.9311 - accuracy: 0.55 - ETA: 0s - loss: 3.1142 - accuracy: 0.54 - ETA: 0s - loss: 2.9521 - accuracy: 0.54 - ETA: 0s - loss: 2.6017 - accuracy: 0.57 - ETA: 0s - loss: 2.5088 - accuracy: 0.58 - ETA: 0s - loss: 2.4248 - accuracy: 0.58 - ETA: 0s - loss: 2.3953 - accuracy: 0.58 - ETA: 0s - loss: 2.3496 - accuracy: 0.58 - 1s 907us/step - loss: 2.3214 - accuracy: 0.5852 - val_loss: 2.3697 - val_accuracy: 0.5200\n",
       "Epoch 3/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 2.9302 - accuracy: 0.37 - ETA: 0s - loss: 2.8241 - accuracy: 0.31 - 0s 325us/step - loss: 2.7315 - accuracy: 0.3203 - val_loss: 2.8565 - val_accuracy: 0.3032\n",
+      "786/786 [==============================] - ETA: 0s - loss: 1.4161 - accuracy: 0.65 - ETA: 0s - loss: 1.6083 - accuracy: 0.62 - ETA: 0s - loss: 1.5882 - accuracy: 0.62 - ETA: 0s - loss: 1.5076 - accuracy: 0.62 - ETA: 0s - loss: 1.5036 - accuracy: 0.62 - ETA: 0s - loss: 1.4583 - accuracy: 0.63 - ETA: 0s - loss: 1.4525 - accuracy: 0.63 - ETA: 0s - loss: 1.4467 - accuracy: 0.63 - ETA: 0s - loss: 1.4533 - accuracy: 0.62 - ETA: 0s - loss: 1.4621 - accuracy: 0.62 - ETA: 0s - loss: 1.4568 - accuracy: 0.61 - 1s 1ms/step - loss: 1.4575 - accuracy: 0.6209 - val_loss: 1.7384 - val_accuracy: 0.5010\n",
       "Epoch 4/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.7559 - accuracy: 0.46 - ETA: 0s - loss: 1.7744 - accuracy: 0.48 - 0s 297us/step - loss: 1.7635 - accuracy: 0.4911 - val_loss: 2.7842 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.8590 - accuracy: 0.65 - ETA: 0s - loss: 1.0256 - accuracy: 0.66 - ETA: 0s - loss: 0.9735 - accuracy: 0.68 - ETA: 0s - loss: 1.0898 - accuracy: 0.66 - ETA: 0s - loss: 1.0861 - accuracy: 0.66 - ETA: 0s - loss: 1.1029 - accuracy: 0.66 - ETA: 0s - loss: 1.1645 - accuracy: 0.65 - ETA: 0s - loss: 1.1580 - accuracy: 0.65 - ETA: 0s - loss: 1.1596 - accuracy: 0.65 - ETA: 0s - loss: 1.1699 - accuracy: 0.65 - ETA: 0s - loss: 1.1361 - accuracy: 0.65 - ETA: 0s - loss: 1.1306 - accuracy: 0.65 - 1s 933us/step - loss: 1.1239 - accuracy: 0.6616 - val_loss: 1.5960 - val_accuracy: 0.6038\n",
       "Epoch 5/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.9932 - accuracy: 0.59 - ETA: 0s - loss: 1.4765 - accuracy: 0.55 - 0s 500us/step - loss: 1.3992 - accuracy: 0.5658 - val_loss: 2.4757 - val_accuracy: 0.3511\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.81 - ETA: 0s - loss: 0.9726 - accuracy: 0.69 - ETA: 0s - loss: 0.9078 - accuracy: 0.71 - ETA: 0s - loss: 0.8755 - accuracy: 0.73 - ETA: 0s - loss: 0.9555 - accuracy: 0.72 - ETA: 0s - loss: 0.9802 - accuracy: 0.71 - ETA: 0s - loss: 0.9681 - accuracy: 0.72 - ETA: 0s - loss: 0.9767 - accuracy: 0.72 - 1s 694us/step - loss: 0.9939 - accuracy: 0.7188 - val_loss: 1.6639 - val_accuracy: 0.6114\n",
       "Epoch 6/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.0645 - accuracy: 0.65 - ETA: 0s - loss: 1.3214 - accuracy: 0.63 - 0s 539us/step - loss: 1.2217 - accuracy: 0.6548 - val_loss: 2.8309 - val_accuracy: 0.3617\n",
+      "786/786 [==============================] - ETA: 0s - loss: 1.1690 - accuracy: 0.68 - ETA: 0s - loss: 0.7755 - accuracy: 0.76 - ETA: 0s - loss: 0.8286 - accuracy: 0.76 - ETA: 0s - loss: 0.8169 - accuracy: 0.76 - ETA: 0s - loss: 0.8528 - accuracy: 0.74 - ETA: 0s - loss: 0.8440 - accuracy: 0.74 - ETA: 0s - loss: 0.8567 - accuracy: 0.74 - ETA: 0s - loss: 0.8828 - accuracy: 0.74 - 1s 652us/step - loss: 0.9023 - accuracy: 0.7392 - val_loss: 1.5622 - val_accuracy: 0.5581\n",
       "Epoch 7/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.7947 - accuracy: 0.78 - ETA: 0s - loss: 1.0072 - accuracy: 0.69 - 0s 374us/step - loss: 1.0246 - accuracy: 0.7011 - val_loss: 2.5759 - val_accuracy: 0.4202\n",
+      "786/786 [==============================] - ETA: 0s - loss: 1.1563 - accuracy: 0.62 - ETA: 0s - loss: 0.8858 - accuracy: 0.71 - ETA: 0s - loss: 0.8777 - accuracy: 0.72 - ETA: 0s - loss: 0.8177 - accuracy: 0.74 - ETA: 0s - loss: 0.7599 - accuracy: 0.76 - ETA: 0s - loss: 0.7668 - accuracy: 0.75 - ETA: 0s - loss: 0.7568 - accuracy: 0.75 - ETA: 0s - loss: 0.8014 - accuracy: 0.73 - ETA: 0s - loss: 0.7997 - accuracy: 0.73 - 1s 750us/step - loss: 0.8023 - accuracy: 0.7366 - val_loss: 1.5658 - val_accuracy: 0.6229\n",
       "Epoch 8/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.75 - ETA: 0s - loss: 1.0584 - accuracy: 0.65 - 0s 335us/step - loss: 0.9949 - accuracy: 0.6797 - val_loss: 2.7374 - val_accuracy: 0.4096\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.8746 - accuracy: 0.71 - ETA: 0s - loss: 0.8200 - accuracy: 0.73 - ETA: 0s - loss: 0.8164 - accuracy: 0.72 - ETA: 0s - loss: 0.8039 - accuracy: 0.72 - ETA: 0s - loss: 0.8076 - accuracy: 0.73 - ETA: 0s - loss: 0.7682 - accuracy: 0.74 - ETA: 0s - loss: 0.7845 - accuracy: 0.73 - ETA: 0s - loss: 0.7771 - accuracy: 0.74 - ETA: 0s - loss: 0.7672 - accuracy: 0.74 - ETA: 0s - loss: 0.7478 - accuracy: 0.75 - 1s 864us/step - loss: 0.7322 - accuracy: 0.7646 - val_loss: 1.7614 - val_accuracy: 0.6076\n",
       "Epoch 9/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.78 - 0s 288us/step - loss: 0.8002 - accuracy: 0.7722 - val_loss: 2.5783 - val_accuracy: 0.4096\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.90 - ETA: 1s - loss: 0.5812 - accuracy: 0.81 - ETA: 0s - loss: 0.6722 - accuracy: 0.76 - ETA: 0s - loss: 0.6822 - accuracy: 0.78 - ETA: 0s - loss: 0.6438 - accuracy: 0.79 - ETA: 0s - loss: 0.6635 - accuracy: 0.79 - ETA: 0s - loss: 0.6866 - accuracy: 0.77 - ETA: 0s - loss: 0.6784 - accuracy: 0.78 - ETA: 0s - loss: 0.7416 - accuracy: 0.76 - ETA: 0s - loss: 0.7149 - accuracy: 0.77 - 1s 802us/step - loss: 0.7300 - accuracy: 0.7608 - val_loss: 1.6688 - val_accuracy: 0.6190\n",
       "Epoch 10/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.81 - ETA: 0s - loss: 0.7422 - accuracy: 0.78 - ETA: 0s - loss: 0.7563 - accuracy: 0.77 - 0s 730us/step - loss: 0.7588 - accuracy: 0.7722 - val_loss: 2.8751 - val_accuracy: 0.3883\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.84 - ETA: 0s - loss: 0.5362 - accuracy: 0.87 - ETA: 0s - loss: 0.5841 - accuracy: 0.83 - ETA: 0s - loss: 0.5983 - accuracy: 0.81 - ETA: 0s - loss: 0.6448 - accuracy: 0.80 - ETA: 0s - loss: 0.6545 - accuracy: 0.80 - ETA: 0s - loss: 0.6575 - accuracy: 0.79 - ETA: 0s - loss: 0.6796 - accuracy: 0.78 - ETA: 0s - loss: 0.6781 - accuracy: 0.78 - ETA: 0s - loss: 0.6713 - accuracy: 0.78 - ETA: 0s - loss: 0.6669 - accuracy: 0.78 - ETA: 0s - loss: 0.6815 - accuracy: 0.78 - 1s 1ms/step - loss: 0.6789 - accuracy: 0.7824 - val_loss: 1.5347 - val_accuracy: 0.5733\n",
       "Epoch 11/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.2013 - accuracy: 0.75 - ETA: 0s - loss: 0.6930 - accuracy: 0.81 - 0s 501us/step - loss: 0.6858 - accuracy: 0.8185 - val_loss: 2.6259 - val_accuracy: 0.3564\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.90 - ETA: 0s - loss: 0.6488 - accuracy: 0.90 - ETA: 0s - loss: 0.6705 - accuracy: 0.88 - ETA: 0s - loss: 0.6633 - accuracy: 0.87 - ETA: 0s - loss: 0.6379 - accuracy: 0.86 - ETA: 0s - loss: 0.5438 - accuracy: 0.86 - ETA: 0s - loss: 0.5704 - accuracy: 0.86 - ETA: 0s - loss: 0.5672 - accuracy: 0.84 - ETA: 0s - loss: 0.5742 - accuracy: 0.84 - ETA: 0s - loss: 0.5753 - accuracy: 0.84 - ETA: 0s - loss: 0.5749 - accuracy: 0.84 - ETA: 0s - loss: 0.5837 - accuracy: 0.83 - ETA: 0s - loss: 0.5911 - accuracy: 0.82 - ETA: 0s - loss: 0.5971 - accuracy: 0.81 - ETA: 0s - loss: 0.5890 - accuracy: 0.82 - ETA: 0s - loss: 0.5828 - accuracy: 0.82 - ETA: 0s - loss: 0.5780 - accuracy: 0.82 - 1s 1ms/step - loss: 0.5756 - accuracy: 0.8270 - val_loss: 1.6123 - val_accuracy: 0.6095\n",
       "Epoch 12/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.93 - ETA: 0s - loss: 0.5313 - accuracy: 0.84 - 0s 320us/step - loss: 0.5298 - accuracy: 0.8470 - val_loss: 2.7889 - val_accuracy: 0.3511\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.96 - ETA: 0s - loss: 0.4756 - accuracy: 0.87 - ETA: 0s - loss: 0.4419 - accuracy: 0.88 - ETA: 0s - loss: 0.4589 - accuracy: 0.86 - ETA: 0s - loss: 0.4508 - accuracy: 0.87 - ETA: 0s - loss: 0.4871 - accuracy: 0.85 - ETA: 0s - loss: 0.4795 - accuracy: 0.85 - ETA: 0s - loss: 0.4887 - accuracy: 0.85 - ETA: 0s - loss: 0.4958 - accuracy: 0.84 - ETA: 0s - loss: 0.4979 - accuracy: 0.84 - 1s 877us/step - loss: 0.4997 - accuracy: 0.8499 - val_loss: 1.5122 - val_accuracy: 0.5905\n",
       "Epoch 13/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.84 - ETA: 0s - loss: 0.5497 - accuracy: 0.84 - 0s 340us/step - loss: 0.5385 - accuracy: 0.8505 - val_loss: 2.6226 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.93 - ETA: 1s - loss: 0.3172 - accuracy: 0.92 - ETA: 0s - loss: 0.4618 - accuracy: 0.85 - ETA: 0s - loss: 0.4221 - accuracy: 0.87 - ETA: 0s - loss: 0.4113 - accuracy: 0.87 - ETA: 0s - loss: 0.4279 - accuracy: 0.86 - ETA: 0s - loss: 0.4253 - accuracy: 0.86 - ETA: 0s - loss: 0.4316 - accuracy: 0.86 - ETA: 0s - loss: 0.4476 - accuracy: 0.85 - ETA: 0s - loss: 0.4546 - accuracy: 0.85 - ETA: 0s - loss: 0.4486 - accuracy: 0.85 - ETA: 0s - loss: 0.4511 - accuracy: 0.85 - 1s 1ms/step - loss: 0.4653 - accuracy: 0.8448 - val_loss: 1.5808 - val_accuracy: 0.6229\n",
       "Epoch 14/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.90 - ETA: 0s - loss: 0.5003 - accuracy: 0.87 - 0s 353us/step - loss: 0.4798 - accuracy: 0.8826 - val_loss: 2.9803 - val_accuracy: 0.3138\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.84 - ETA: 0s - loss: 0.4442 - accuracy: 0.87 - ETA: 0s - loss: 0.4139 - accuracy: 0.87 - ETA: 0s - loss: 0.4230 - accuracy: 0.87 - ETA: 0s - loss: 0.4472 - accuracy: 0.85 - ETA: 0s - loss: 0.4109 - accuracy: 0.87 - ETA: 0s - loss: 0.4306 - accuracy: 0.87 - ETA: 0s - loss: 0.4371 - accuracy: 0.87 - 1s 640us/step - loss: 0.4532 - accuracy: 0.8651 - val_loss: 1.6259 - val_accuracy: 0.5943\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
       "Epoch 15/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.84 - 0s 276us/step - loss: 0.4402 - accuracy: 0.9004 - val_loss: 2.6732 - val_accuracy: 0.4043\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.93 - ETA: 0s - loss: 0.3933 - accuracy: 0.88 - ETA: 0s - loss: 0.3637 - accuracy: 0.88 - ETA: 0s - loss: 0.3850 - accuracy: 0.87 - ETA: 0s - loss: 0.3955 - accuracy: 0.86 - ETA: 0s - loss: 0.3836 - accuracy: 0.87 - ETA: 0s - loss: 0.3795 - accuracy: 0.87 - 0s 629us/step - loss: 0.3974 - accuracy: 0.8728 - val_loss: 1.6721 - val_accuracy: 0.5867\n",
       "Epoch 16/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.93 - ETA: 0s - loss: 0.3664 - accuracy: 0.89 - 0s 327us/step - loss: 0.3706 - accuracy: 0.8897 - val_loss: 2.9172 - val_accuracy: 0.3457\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.87 - ETA: 0s - loss: 0.3617 - accuracy: 0.88 - ETA: 0s - loss: 0.3557 - accuracy: 0.88 - ETA: 0s - loss: 0.3570 - accuracy: 0.88 - ETA: 0s - loss: 0.3872 - accuracy: 0.87 - ETA: 0s - loss: 0.3624 - accuracy: 0.88 - ETA: 0s - loss: 0.3615 - accuracy: 0.89 - ETA: 0s - loss: 0.3600 - accuracy: 0.88 - ETA: 0s - loss: 0.3695 - accuracy: 0.88 - ETA: 0s - loss: 0.3713 - accuracy: 0.88 - ETA: 0s - loss: 0.3720 - accuracy: 0.89 - ETA: 0s - loss: 0.3679 - accuracy: 0.89 - ETA: 0s - loss: 0.3733 - accuracy: 0.89 - ETA: 0s - loss: 0.3727 - accuracy: 0.89 - 1s 1ms/step - loss: 0.3702 - accuracy: 0.8957 - val_loss: 1.7526 - val_accuracy: 0.6267\n",
       "Epoch 17/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - 0s 261us/step - loss: 0.3737 - accuracy: 0.9004 - val_loss: 2.7488 - val_accuracy: 0.4043\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.96 - ETA: 0s - loss: 0.3978 - accuracy: 0.91 - ETA: 0s - loss: 0.3887 - accuracy: 0.87 - ETA: 0s - loss: 0.3724 - accuracy: 0.89 - ETA: 0s - loss: 0.4111 - accuracy: 0.87 - ETA: 0s - loss: 0.4132 - accuracy: 0.86 - ETA: 0s - loss: 0.4061 - accuracy: 0.87 - ETA: 0s - loss: 0.4206 - accuracy: 0.86 - ETA: 0s - loss: 0.4250 - accuracy: 0.86 - ETA: 0s - loss: 0.4187 - accuracy: 0.86 - ETA: 0s - loss: 0.4179 - accuracy: 0.86 - ETA: 0s - loss: 0.4144 - accuracy: 0.86 - 1s 1ms/step - loss: 0.4070 - accuracy: 0.8702 - val_loss: 1.8099 - val_accuracy: 0.6286\n",
       "Epoch 18/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.90 - ETA: 0s - loss: 0.3444 - accuracy: 0.91 - 0s 328us/step - loss: 0.3300 - accuracy: 0.9217 - val_loss: 2.8965 - val_accuracy: 0.4255\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.93 - ETA: 1s - loss: 0.2799 - accuracy: 0.93 - ETA: 1s - loss: 0.2942 - accuracy: 0.92 - ETA: 0s - loss: 0.3046 - accuracy: 0.91 - ETA: 0s - loss: 0.2756 - accuracy: 0.93 - ETA: 0s - loss: 0.2944 - accuracy: 0.92 - ETA: 0s - loss: 0.3007 - accuracy: 0.92 - ETA: 0s - loss: 0.2978 - accuracy: 0.93 - ETA: 0s - loss: 0.2934 - accuracy: 0.92 - ETA: 0s - loss: 0.2962 - accuracy: 0.92 - ETA: 0s - loss: 0.2996 - accuracy: 0.92 - 1s 1ms/step - loss: 0.2977 - accuracy: 0.9224 - val_loss: 1.8292 - val_accuracy: 0.6171\n",
       "Epoch 19/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.93 - ETA: 0s - loss: 0.3102 - accuracy: 0.91 - 0s 381us/step - loss: 0.3142 - accuracy: 0.9146 - val_loss: 3.0782 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.4610 - accuracy: 0.84 - ETA: 0s - loss: 0.2895 - accuracy: 0.89 - ETA: 0s - loss: 0.3365 - accuracy: 0.85 - ETA: 0s - loss: 0.3183 - accuracy: 0.87 - ETA: 0s - loss: 0.3028 - accuracy: 0.89 - ETA: 0s - loss: 0.2984 - accuracy: 0.89 - ETA: 0s - loss: 0.3039 - accuracy: 0.89 - ETA: 0s - loss: 0.2906 - accuracy: 0.90 - ETA: 0s - loss: 0.2913 - accuracy: 0.90 - ETA: 0s - loss: 0.2944 - accuracy: 0.90 - ETA: 0s - loss: 0.2999 - accuracy: 0.90 - 1s 1ms/step - loss: 0.2900 - accuracy: 0.9084 - val_loss: 1.7671 - val_accuracy: 0.6076\n",
       "Epoch 20/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.87 - ETA: 0s - loss: 0.2662 - accuracy: 0.94 - 0s 349us/step - loss: 0.2553 - accuracy: 0.9466 - val_loss: 2.9722 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.90 - ETA: 0s - loss: 0.2449 - accuracy: 0.92 - ETA: 0s - loss: 0.2512 - accuracy: 0.93 - ETA: 0s - loss: 0.2386 - accuracy: 0.94 - ETA: 0s - loss: 0.2479 - accuracy: 0.93 - ETA: 0s - loss: 0.2393 - accuracy: 0.93 - ETA: 0s - loss: 0.2533 - accuracy: 0.92 - ETA: 0s - loss: 0.2470 - accuracy: 0.92 - ETA: 0s - loss: 0.2478 - accuracy: 0.93 - ETA: 0s - loss: 0.2549 - accuracy: 0.92 - ETA: 0s - loss: 0.2616 - accuracy: 0.92 - ETA: 0s - loss: 0.2616 - accuracy: 0.92 - ETA: 0s - loss: 0.2614 - accuracy: 0.92 - ETA: 0s - loss: 0.2538 - accuracy: 0.92 - ETA: 0s - loss: 0.2523 - accuracy: 0.92 - ETA: 0s - loss: 0.2477 - accuracy: 0.93 - 2s 2ms/step - loss: 0.2509 - accuracy: 0.9313 - val_loss: 1.7548 - val_accuracy: 0.6152\n",
       "Epoch 21/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.84 - ETA: 0s - loss: 0.2778 - accuracy: 0.92 - 0s 328us/step - loss: 0.2780 - accuracy: 0.9288 - val_loss: 3.1543 - val_accuracy: 0.3777\n",
+      " 32/786 [>.............................] - ETA: 2s - loss: 0.4735 - accuracy: 0.8125"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.127134). Check your callbacks.\n",
+      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      " 64/786 [=>............................] - ETA: 3s - loss: 0.3440 - accuracy: 0.9062"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.108799). Check your callbacks.\n",
+      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "786/786 [==============================] - ETA: 3s - loss: 0.2993 - accuracy: 0.92 - ETA: 2s - loss: 0.2714 - accuracy: 0.93 - ETA: 1s - loss: 0.2657 - accuracy: 0.92 - ETA: 0s - loss: 0.2651 - accuracy: 0.92 - ETA: 0s - loss: 0.2832 - accuracy: 0.91 - ETA: 0s - loss: 0.2768 - accuracy: 0.92 - ETA: 0s - loss: 0.2655 - accuracy: 0.92 - ETA: 0s - loss: 0.2609 - accuracy: 0.92 - 1s 1ms/step - loss: 0.2525 - accuracy: 0.9300 - val_loss: 1.8758 - val_accuracy: 0.5924\n",
       "Epoch 22/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.93 - ETA: 0s - loss: 0.2018 - accuracy: 0.95 - 0s 312us/step - loss: 0.2135 - accuracy: 0.9573 - val_loss: 3.0016 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.96 - ETA: 0s - loss: 0.1477 - accuracy: 0.96 - ETA: 0s - loss: 0.2686 - accuracy: 0.93 - ETA: 0s - loss: 0.2672 - accuracy: 0.92 - ETA: 0s - loss: 0.2561 - accuracy: 0.93 - ETA: 0s - loss: 0.2388 - accuracy: 0.93 - ETA: 0s - loss: 0.2346 - accuracy: 0.93 - 0s 552us/step - loss: 0.2399 - accuracy: 0.9313 - val_loss: 1.9240 - val_accuracy: 0.5962\n",
       "Epoch 23/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 1.00 - ETA: 0s - loss: 0.1672 - accuracy: 0.96 - 0s 391us/step - loss: 0.1630 - accuracy: 0.9680 - val_loss: 2.9483 - val_accuracy: 0.4149\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.93 - ETA: 0s - loss: 0.2092 - accuracy: 0.94 - ETA: 0s - loss: 0.1762 - accuracy: 0.95 - ETA: 0s - loss: 0.1810 - accuracy: 0.95 - ETA: 0s - loss: 0.1774 - accuracy: 0.95 - ETA: 0s - loss: 0.1784 - accuracy: 0.95 - ETA: 0s - loss: 0.1821 - accuracy: 0.95 - 0s 572us/step - loss: 0.1978 - accuracy: 0.9466 - val_loss: 1.9176 - val_accuracy: 0.5790\n",
       "Epoch 24/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 1.00 - ETA: 0s - loss: 0.1391 - accuracy: 0.97 - ETA: 0s - loss: 0.1322 - accuracy: 0.98 - 0s 742us/step - loss: 0.1495 - accuracy: 0.9786 - val_loss: 3.1443 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.96 - ETA: 0s - loss: 0.2475 - accuracy: 0.95 - ETA: 0s - loss: 0.2076 - accuracy: 0.96 - ETA: 0s - loss: 0.1718 - accuracy: 0.97 - ETA: 0s - loss: 0.2022 - accuracy: 0.95 - ETA: 0s - loss: 0.1902 - accuracy: 0.96 - ETA: 0s - loss: 0.2031 - accuracy: 0.95 - ETA: 0s - loss: 0.2184 - accuracy: 0.94 - 1s 647us/step - loss: 0.2285 - accuracy: 0.9402 - val_loss: 1.9214 - val_accuracy: 0.6019\n",
       "Epoch 25/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.96 - ETA: 0s - loss: 0.1644 - accuracy: 0.96 - 0s 345us/step - loss: 0.1596 - accuracy: 0.9680 - val_loss: 3.1408 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.96 - ETA: 0s - loss: 0.1584 - accuracy: 0.96 - ETA: 0s - loss: 0.1320 - accuracy: 0.97 - ETA: 0s - loss: 0.1398 - accuracy: 0.96 - ETA: 0s - loss: 0.1607 - accuracy: 0.95 - ETA: 0s - loss: 0.1711 - accuracy: 0.94 - ETA: 0s - loss: 0.1929 - accuracy: 0.94 - ETA: 0s - loss: 0.1912 - accuracy: 0.94 - ETA: 0s - loss: 0.1985 - accuracy: 0.94 - 1s 763us/step - loss: 0.1936 - accuracy: 0.9427 - val_loss: 1.9897 - val_accuracy: 0.6095\n",
       "Epoch 26/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.96 - 0s 279us/step - loss: 0.1713 - accuracy: 0.9644 - val_loss: 3.3056 - val_accuracy: 0.3883\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.93 - ETA: 0s - loss: 0.2212 - accuracy: 0.92 - ETA: 0s - loss: 0.1704 - accuracy: 0.95 - ETA: 0s - loss: 0.1753 - accuracy: 0.96 - ETA: 0s - loss: 0.1809 - accuracy: 0.95 - ETA: 0s - loss: 0.1734 - accuracy: 0.95 - ETA: 0s - loss: 0.1724 - accuracy: 0.95 - ETA: 0s - loss: 0.1723 - accuracy: 0.96 - ETA: 0s - loss: 0.1742 - accuracy: 0.95 - 1s 765us/step - loss: 0.1788 - accuracy: 0.9593 - val_loss: 2.0668 - val_accuracy: 0.6000\n",
       "Epoch 27/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 1.00 - ETA: 0s - loss: 0.1034 - accuracy: 0.98 - 0s 358us/step - loss: 0.1384 - accuracy: 0.9786 - val_loss: 3.1630 - val_accuracy: 0.3564\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.93 - ETA: 0s - loss: 0.1210 - accuracy: 0.96 - ETA: 0s - loss: 0.1136 - accuracy: 0.98 - ETA: 0s - loss: 0.1235 - accuracy: 0.97 - ETA: 0s - loss: 0.1212 - accuracy: 0.97 - ETA: 0s - loss: 0.1390 - accuracy: 0.97 - ETA: 0s - loss: 0.1633 - accuracy: 0.97 - ETA: 0s - loss: 0.1523 - accuracy: 0.97 - ETA: 0s - loss: 0.1562 - accuracy: 0.97 - ETA: 0s - loss: 0.1550 - accuracy: 0.97 - ETA: 0s - loss: 0.1540 - accuracy: 0.97 - 1s 818us/step - loss: 0.1518 - accuracy: 0.9707 - val_loss: 2.1080 - val_accuracy: 0.5867\n",
       "Epoch 28/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 1.00 - 0s 334us/step - loss: 0.1158 - accuracy: 0.9786 - val_loss: 3.2077 - val_accuracy: 0.3936\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.96 - ETA: 0s - loss: 0.1278 - accuracy: 0.96 - ETA: 0s - loss: 0.1445 - accuracy: 0.96 - ETA: 0s - loss: 0.1497 - accuracy: 0.96 - ETA: 0s - loss: 0.1454 - accuracy: 0.96 - ETA: 0s - loss: 0.1284 - accuracy: 0.97 - ETA: 0s - loss: 0.1356 - accuracy: 0.96 - ETA: 0s - loss: 0.1329 - accuracy: 0.96 - ETA: 0s - loss: 0.1358 - accuracy: 0.97 - 1s 807us/step - loss: 0.1345 - accuracy: 0.9695 - val_loss: 2.2867 - val_accuracy: 0.6095\n",
       "Epoch 29/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 1.00 - ETA: 0s - loss: 0.1380 - accuracy: 0.97 - ETA: 0s - loss: 0.1156 - accuracy: 0.98 - 0s 595us/step - loss: 0.1128 - accuracy: 0.9822 - val_loss: 3.3168 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 1.00 - ETA: 0s - loss: 0.0737 - accuracy: 0.97 - ETA: 0s - loss: 0.0746 - accuracy: 0.98 - ETA: 0s - loss: 0.0885 - accuracy: 0.98 - ETA: 0s - loss: 0.0888 - accuracy: 0.98 - ETA: 0s - loss: 0.0997 - accuracy: 0.98 - ETA: 0s - loss: 0.0960 - accuracy: 0.98 - ETA: 0s - loss: 0.1024 - accuracy: 0.98 - ETA: 0s - loss: 0.1084 - accuracy: 0.98 - ETA: 0s - loss: 0.1102 - accuracy: 0.98 - 1s 765us/step - loss: 0.1125 - accuracy: 0.9796 - val_loss: 2.3736 - val_accuracy: 0.6114\n",
       "Epoch 30/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 1.00 - ETA: 0s - loss: 0.0954 - accuracy: 0.98 - 0s 515us/step - loss: 0.0994 - accuracy: 0.9893 - val_loss: 3.3483 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.96 - ETA: 0s - loss: 0.1475 - accuracy: 0.96 - ETA: 0s - loss: 0.1407 - accuracy: 0.95 - ETA: 0s - loss: 0.1268 - accuracy: 0.96 - ETA: 0s - loss: 0.1453 - accuracy: 0.95 - ETA: 0s - loss: 0.1554 - accuracy: 0.95 - ETA: 0s - loss: 0.1546 - accuracy: 0.95 - ETA: 0s - loss: 0.1489 - accuracy: 0.95 - 0s 610us/step - loss: 0.1528 - accuracy: 0.9580 - val_loss: 2.3472 - val_accuracy: 0.6114\n",
       "Epoch 31/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 1.00 - 0s 258us/step - loss: 0.0910 - accuracy: 0.9786 - val_loss: 3.3935 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.93 - ETA: 0s - loss: 0.2259 - accuracy: 0.93 - ETA: 0s - loss: 0.2051 - accuracy: 0.93 - ETA: 0s - loss: 0.2333 - accuracy: 0.91 - ETA: 0s - loss: 0.1883 - accuracy: 0.94 - ETA: 0s - loss: 0.2040 - accuracy: 0.93 - ETA: 0s - loss: 0.1967 - accuracy: 0.94 - ETA: 0s - loss: 0.2106 - accuracy: 0.94 - ETA: 0s - loss: 0.1909 - accuracy: 0.94 - ETA: 0s - loss: 0.1849 - accuracy: 0.95 - ETA: 0s - loss: 0.1912 - accuracy: 0.94 - 1s 1ms/step - loss: 0.2001 - accuracy: 0.9440 - val_loss: 2.3742 - val_accuracy: 0.5867\n",
       "Epoch 32/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 1.00 - ETA: 0s - loss: 0.1474 - accuracy: 0.98 - 0s 411us/step - loss: 0.1534 - accuracy: 0.9822 - val_loss: 3.4210 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.93 - ETA: 0s - loss: 0.2788 - accuracy: 0.89 - ETA: 0s - loss: 0.2477 - accuracy: 0.92 - ETA: 0s - loss: 0.2326 - accuracy: 0.93 - ETA: 0s - loss: 0.2144 - accuracy: 0.94 - ETA: 0s - loss: 0.2025 - accuracy: 0.95 - ETA: 0s - loss: 0.1949 - accuracy: 0.95 - ETA: 0s - loss: 0.1880 - accuracy: 0.95 - ETA: 0s - loss: 0.1886 - accuracy: 0.95 - 1s 693us/step - loss: 0.1854 - accuracy: 0.9567 - val_loss: 2.1224 - val_accuracy: 0.6133\n",
       "Epoch 33/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.93 - ETA: 0s - loss: 0.1145 - accuracy: 0.98 - 0s 453us/step - loss: 0.1363 - accuracy: 0.9822 - val_loss: 3.5561 - val_accuracy: 0.4096\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.0825 - accuracy: 1.00 - ETA: 0s - loss: 0.1264 - accuracy: 0.96 - ETA: 0s - loss: 0.1557 - accuracy: 0.96 - ETA: 0s - loss: 0.1355 - accuracy: 0.96 - ETA: 0s - loss: 0.1537 - accuracy: 0.96 - ETA: 0s - loss: 0.1607 - accuracy: 0.96 - ETA: 0s - loss: 0.1567 - accuracy: 0.96 - 0s 591us/step - loss: 0.1600 - accuracy: 0.9618 - val_loss: 2.5098 - val_accuracy: 0.6095\n",
       "Epoch 34/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.96 - ETA: 0s - loss: 0.1624 - accuracy: 0.95 - 0s 365us/step - loss: 0.1564 - accuracy: 0.9537 - val_loss: 3.7636 - val_accuracy: 0.3883\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.93 - ETA: 0s - loss: 0.1988 - accuracy: 0.93 - ETA: 0s - loss: 0.1518 - accuracy: 0.95 - ETA: 0s - loss: 0.1335 - accuracy: 0.96 - ETA: 0s - loss: 0.1369 - accuracy: 0.96 - ETA: 0s - loss: 0.1555 - accuracy: 0.95 - ETA: 0s - loss: 0.1552 - accuracy: 0.95 - ETA: 0s - loss: 0.1496 - accuracy: 0.95 - ETA: 0s - loss: 0.1507 - accuracy: 0.95 - ETA: 0s - loss: 0.1458 - accuracy: 0.95 - 1s 868us/step - loss: 0.1495 - accuracy: 0.9580 - val_loss: 2.4801 - val_accuracy: 0.6019\n",
       "Epoch 35/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.96 - ETA: 0s - loss: 0.1620 - accuracy: 0.94 - 0s 436us/step - loss: 0.1161 - accuracy: 0.9680 - val_loss: 3.4313 - val_accuracy: 0.3617\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.00 - ETA: 0s - loss: 0.0736 - accuracy: 0.99 - ETA: 0s - loss: 0.0967 - accuracy: 0.97 - ETA: 0s - loss: 0.0825 - accuracy: 0.98 - ETA: 0s - loss: 0.0910 - accuracy: 0.97 - ETA: 0s - loss: 0.0996 - accuracy: 0.97 - ETA: 0s - loss: 0.0959 - accuracy: 0.97 - ETA: 0s - loss: 0.0904 - accuracy: 0.97 - ETA: 0s - loss: 0.1005 - accuracy: 0.97 - ETA: 0s - loss: 0.0993 - accuracy: 0.97 - 1s 849us/step - loss: 0.1012 - accuracy: 0.9758 - val_loss: 2.2849 - val_accuracy: 0.6038\n",
       "Epoch 36/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.96 - ETA: 0s - loss: 0.1088 - accuracy: 0.98 - 0s 341us/step - loss: 0.1037 - accuracy: 0.9822 - val_loss: 3.5027 - val_accuracy: 0.3404\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 1.00 - ETA: 0s - loss: 0.0717 - accuracy: 1.00 - ETA: 0s - loss: 0.0621 - accuracy: 1.00 - ETA: 0s - loss: 0.0608 - accuracy: 1.00 - ETA: 0s - loss: 0.0607 - accuracy: 0.99 - ETA: 0s - loss: 0.0624 - accuracy: 0.99 - ETA: 0s - loss: 0.0677 - accuracy: 0.99 - ETA: 0s - loss: 0.0707 - accuracy: 0.99 - 1s 872us/step - loss: 0.0768 - accuracy: 0.9898 - val_loss: 2.4238 - val_accuracy: 0.6324\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
       "Epoch 37/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 1.00 - 0s 276us/step - loss: 0.0928 - accuracy: 0.9786 - val_loss: 3.4027 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.0595 - accuracy: 1.00 - ETA: 1s - loss: 0.0748 - accuracy: 0.98 - ETA: 1s - loss: 0.0721 - accuracy: 0.98 - ETA: 0s - loss: 0.0850 - accuracy: 0.98 - ETA: 0s - loss: 0.0742 - accuracy: 0.98 - ETA: 0s - loss: 0.0747 - accuracy: 0.98 - ETA: 0s - loss: 0.0704 - accuracy: 0.98 - ETA: 0s - loss: 0.0736 - accuracy: 0.98 - ETA: 0s - loss: 0.0728 - accuracy: 0.98 - ETA: 0s - loss: 0.0750 - accuracy: 0.97 - ETA: 0s - loss: 0.0725 - accuracy: 0.98 - ETA: 0s - loss: 0.0759 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0747 - accuracy: 0.9809 - val_loss: 2.4118 - val_accuracy: 0.5943\n",
       "Epoch 38/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 1.00 - ETA: 0s - loss: 0.1070 - accuracy: 0.98 - 0s 527us/step - loss: 0.1131 - accuracy: 0.9858 - val_loss: 3.4673 - val_accuracy: 0.4043\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 1.00 - ETA: 0s - loss: 0.0499 - accuracy: 1.00 - ETA: 0s - loss: 0.0501 - accuracy: 1.00 - ETA: 0s - loss: 0.0463 - accuracy: 1.00 - ETA: 0s - loss: 0.0684 - accuracy: 0.99 - ETA: 0s - loss: 0.0727 - accuracy: 0.98 - ETA: 0s - loss: 0.0701 - accuracy: 0.98 - ETA: 0s - loss: 0.0706 - accuracy: 0.98 - 0s 613us/step - loss: 0.0759 - accuracy: 0.9860 - val_loss: 2.5814 - val_accuracy: 0.6133\n",
       "Epoch 39/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - ETA: 0s - loss: 0.0613 - accuracy: 0.99 - 0s 518us/step - loss: 0.0732 - accuracy: 0.9929 - val_loss: 3.5865 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.96 - ETA: 0s - loss: 0.0499 - accuracy: 0.99 - ETA: 0s - loss: 0.0443 - accuracy: 0.99 - ETA: 0s - loss: 0.0453 - accuracy: 0.99 - ETA: 0s - loss: 0.0546 - accuracy: 0.98 - ETA: 0s - loss: 0.0545 - accuracy: 0.99 - ETA: 0s - loss: 0.0517 - accuracy: 0.99 - ETA: 0s - loss: 0.0492 - accuracy: 0.99 - ETA: 0s - loss: 0.0608 - accuracy: 0.99 - ETA: 0s - loss: 0.0596 - accuracy: 0.99 - 1s 850us/step - loss: 0.0615 - accuracy: 0.9911 - val_loss: 2.5546 - val_accuracy: 0.6019\n",
       "Epoch 40/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 1.00 - 0s 257us/step - loss: 0.0709 - accuracy: 0.9858 - val_loss: 3.4783 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.0322 - accuracy: 1.00 - ETA: 1s - loss: 0.0370 - accuracy: 0.98 - ETA: 0s - loss: 0.0731 - accuracy: 0.97 - ETA: 0s - loss: 0.0648 - accuracy: 0.97 - ETA: 0s - loss: 0.0597 - accuracy: 0.98 - ETA: 0s - loss: 0.0560 - accuracy: 0.98 - ETA: 0s - loss: 0.0583 - accuracy: 0.98 - ETA: 0s - loss: 0.0661 - accuracy: 0.98 - ETA: 0s - loss: 0.0629 - accuracy: 0.98 - ETA: 0s - loss: 0.0686 - accuracy: 0.98 - ETA: 0s - loss: 0.0655 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0610 - accuracy: 0.9873 - val_loss: 2.6306 - val_accuracy: 0.6076\n",
       "Epoch 41/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.96 - 0s 248us/step - loss: 0.0775 - accuracy: 0.9858 - val_loss: 3.5490 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - ETA: 0s - loss: 0.0429 - accuracy: 0.98 - ETA: 0s - loss: 0.0985 - accuracy: 0.98 - ETA: 0s - loss: 0.0815 - accuracy: 0.98 - ETA: 0s - loss: 0.0787 - accuracy: 0.98 - ETA: 0s - loss: 0.0740 - accuracy: 0.98 - ETA: 0s - loss: 0.0690 - accuracy: 0.98 - ETA: 0s - loss: 0.0647 - accuracy: 0.99 - ETA: 0s - loss: 0.0618 - accuracy: 0.99 - ETA: 0s - loss: 0.0596 - accuracy: 0.99 - 1s 892us/step - loss: 0.0557 - accuracy: 0.9936 - val_loss: 2.5926 - val_accuracy: 0.6000\n",
       "Epoch 42/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 1.00 - ETA: 0s - loss: 0.0730 - accuracy: 0.98 - 0s 363us/step - loss: 0.0740 - accuracy: 0.9858 - val_loss: 3.8505 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.0352 - accuracy: 1.00 - ETA: 0s - loss: 0.0452 - accuracy: 0.99 - ETA: 0s - loss: 0.0472 - accuracy: 0.99 - ETA: 0s - loss: 0.0402 - accuracy: 0.99 - ETA: 0s - loss: 0.0385 - accuracy: 0.99 - ETA: 0s - loss: 0.0512 - accuracy: 0.99 - ETA: 0s - loss: 0.0477 - accuracy: 0.99 - ETA: 0s - loss: 0.0458 - accuracy: 0.99 - 1s 747us/step - loss: 0.0480 - accuracy: 0.9936 - val_loss: 2.7000 - val_accuracy: 0.6076\n",
       "Epoch 43/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 1.00 - ETA: 0s - loss: 0.0645 - accuracy: 0.98 - 0s 449us/step - loss: 0.0596 - accuracy: 0.9893 - val_loss: 3.6512 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.96 - ETA: 0s - loss: 0.1466 - accuracy: 0.95 - ETA: 0s - loss: 0.1215 - accuracy: 0.96 - ETA: 1s - loss: 0.1062 - accuracy: 0.97 - ETA: 0s - loss: 0.0944 - accuracy: 0.97 - ETA: 0s - loss: 0.0731 - accuracy: 0.98 - ETA: 0s - loss: 0.0717 - accuracy: 0.97 - ETA: 0s - loss: 0.0635 - accuracy: 0.98 - ETA: 0s - loss: 0.0630 - accuracy: 0.98 - 1s 830us/step - loss: 0.0622 - accuracy: 0.9860 - val_loss: 2.6268 - val_accuracy: 0.6152\n",
       "Epoch 44/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.00 - 0s 252us/step - loss: 0.0542 - accuracy: 0.9929 - val_loss: 3.6441 - val_accuracy: 0.3670\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 1.00 - ETA: 0s - loss: 0.0306 - accuracy: 1.00 - ETA: 0s - loss: 0.0373 - accuracy: 0.99 - ETA: 0s - loss: 0.0401 - accuracy: 0.99 - ETA: 0s - loss: 0.0429 - accuracy: 0.98 - ETA: 0s - loss: 0.0437 - accuracy: 0.99 - ETA: 0s - loss: 0.0451 - accuracy: 0.99 - ETA: 0s - loss: 0.0494 - accuracy: 0.99 - ETA: 0s - loss: 0.0469 - accuracy: 0.99 - ETA: 0s - loss: 0.0461 - accuracy: 0.99 - 1s 798us/step - loss: 0.0453 - accuracy: 0.9911 - val_loss: 2.6666 - val_accuracy: 0.5943\n",
       "Epoch 45/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 1.00 - 0s 275us/step - loss: 0.0468 - accuracy: 0.9893 - val_loss: 3.6158 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.96 - ETA: 0s - loss: 0.0447 - accuracy: 0.98 - ETA: 0s - loss: 0.0513 - accuracy: 0.98 - ETA: 0s - loss: 0.0640 - accuracy: 0.98 - ETA: 0s - loss: 0.0625 - accuracy: 0.98 - ETA: 0s - loss: 0.0549 - accuracy: 0.98 - ETA: 0s - loss: 0.0677 - accuracy: 0.98 - ETA: 0s - loss: 0.0717 - accuracy: 0.98 - ETA: 0s - loss: 0.0663 - accuracy: 0.98 - ETA: 0s - loss: 0.0642 - accuracy: 0.98 - ETA: 0s - loss: 0.0617 - accuracy: 0.98 - ETA: 0s - loss: 0.0598 - accuracy: 0.98 - ETA: 0s - loss: 0.0579 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0556 - accuracy: 0.9885 - val_loss: 2.7483 - val_accuracy: 0.6000\n",
       "Epoch 46/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - ETA: 0s - loss: 0.0425 - accuracy: 0.99 - 0s 486us/step - loss: 0.0504 - accuracy: 0.9929 - val_loss: 3.6831 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.96 - ETA: 0s - loss: 0.0712 - accuracy: 0.98 - ETA: 0s - loss: 0.0661 - accuracy: 0.98 - ETA: 0s - loss: 0.0604 - accuracy: 0.98 - ETA: 0s - loss: 0.0562 - accuracy: 0.98 - ETA: 0s - loss: 0.0534 - accuracy: 0.98 - ETA: 0s - loss: 0.0514 - accuracy: 0.98 - ETA: 0s - loss: 0.0444 - accuracy: 0.99 - ETA: 0s - loss: 0.0450 - accuracy: 0.99 - 1s 804us/step - loss: 0.0451 - accuracy: 0.9911 - val_loss: 2.6932 - val_accuracy: 0.5886\n",
       "Epoch 47/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - ETA: 0s - loss: 0.1069 - accuracy: 0.99 - 0s 357us/step - loss: 0.0945 - accuracy: 0.9929 - val_loss: 3.7183 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.00 - ETA: 1s - loss: 0.0173 - accuracy: 1.00 - ETA: 1s - loss: 0.0178 - accuracy: 1.00 - ETA: 1s - loss: 0.0151 - accuracy: 1.00 - ETA: 0s - loss: 0.0261 - accuracy: 0.99 - ETA: 0s - loss: 0.0353 - accuracy: 0.99 - ETA: 0s - loss: 0.0386 - accuracy: 0.98 - ETA: 0s - loss: 0.0397 - accuracy: 0.99 - ETA: 0s - loss: 0.0412 - accuracy: 0.98 - ETA: 0s - loss: 0.0383 - accuracy: 0.98 - ETA: 0s - loss: 0.0375 - accuracy: 0.98 - ETA: 0s - loss: 0.0479 - accuracy: 0.98 - ETA: 0s - loss: 0.0428 - accuracy: 0.98 - ETA: 0s - loss: 0.0420 - accuracy: 0.98 - ETA: 0s - loss: 0.0420 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0413 - accuracy: 0.9898 - val_loss: 2.7521 - val_accuracy: 0.6152\n",
       "Epoch 48/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.00 - 0s 257us/step - loss: 0.0545 - accuracy: 0.9858 - val_loss: 3.7581 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.00 - ETA: 0s - loss: 0.0285 - accuracy: 0.98 - ETA: 0s - loss: 0.0396 - accuracy: 0.98 - ETA: 0s - loss: 0.0364 - accuracy: 0.98 - ETA: 0s - loss: 0.0385 - accuracy: 0.99 - ETA: 0s - loss: 0.0435 - accuracy: 0.99 - ETA: 0s - loss: 0.0413 - accuracy: 0.99 - ETA: 0s - loss: 0.0389 - accuracy: 0.99 - ETA: 0s - loss: 0.0382 - accuracy: 0.99 - ETA: 0s - loss: 0.0401 - accuracy: 0.98 - ETA: 0s - loss: 0.0437 - accuracy: 0.98 - ETA: 0s - loss: 0.0411 - accuracy: 0.98 - ETA: 0s - loss: 0.0397 - accuracy: 0.99 - 1s 1ms/step - loss: 0.0406 - accuracy: 0.9898 - val_loss: 2.8030 - val_accuracy: 0.6057\n",
       "Epoch 49/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.00 - ETA: 0s - loss: 0.0681 - accuracy: 0.98 - 0s 358us/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 3.9350 - val_accuracy: 0.3723\n",
-      "Epoch 50/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.0738 - accuracy: 0.98 - 0s 555us/step - loss: 0.0570 - accuracy: 0.9893 - val_loss: 3.7512 - val_accuracy: 0.3670\n"
+      "786/786 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.93 - ETA: 0s - loss: 0.1687 - accuracy: 0.94 - ETA: 0s - loss: 0.1087 - accuracy: 0.96 - ETA: 0s - loss: 0.1192 - accuracy: 0.96 - ETA: 0s - loss: 0.1068 - accuracy: 0.97 - ETA: 0s - loss: 0.0982 - accuracy: 0.97 - ETA: 0s - loss: 0.0901 - accuracy: 0.97 - ETA: 0s - loss: 0.0843 - accuracy: 0.98 - ETA: 0s - loss: 0.0736 - accuracy: 0.98 - ETA: 0s - loss: 0.0654 - accuracy: 0.98 - ETA: 0s - loss: 0.0637 - accuracy: 0.98 - ETA: 0s - loss: 0.0647 - accuracy: 0.98 - ETA: 0s - loss: 0.0633 - accuracy: 0.98 - ETA: 0s - loss: 0.0600 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0592 - accuracy: 0.9873 - val_loss: 2.8111 - val_accuracy: 0.5695\n",
+      "Epoch 50/50\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "786/786 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.96 - ETA: 0s - loss: 0.0826 - accuracy: 0.97 - ETA: 0s - loss: 0.0723 - accuracy: 0.98 - ETA: 0s - loss: 0.0632 - accuracy: 0.98 - ETA: 0s - loss: 0.0570 - accuracy: 0.98 - ETA: 0s - loss: 0.0486 - accuracy: 0.98 - ETA: 0s - loss: 0.0445 - accuracy: 0.99 - ETA: 0s - loss: 0.0414 - accuracy: 0.99 - ETA: 0s - loss: 0.0705 - accuracy: 0.98 - ETA: 0s - loss: 0.0665 - accuracy: 0.98 - ETA: 0s - loss: 0.0593 - accuracy: 0.98 - ETA: 0s - loss: 0.0744 - accuracy: 0.98 - ETA: 0s - loss: 0.0691 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0730 - accuracy: 0.9847 - val_loss: 2.8125 - val_accuracy: 0.6076\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<keras.callbacks.callbacks.History at 0x16ff36d33c8>"
+       "<keras.callbacks.callbacks.History at 0x2d69ad5c288>"
       ]
      },
-     "execution_count": 10,
+     "execution_count": 31,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "wandb.init()\n",
-    "\n",
+    "print(y_train_hot.shape)\n",
+    "print(labels.shape)\n",
+    "print(X_train.shape)\n",
     "# Train the CNN model\n",
     "#    X_train: Input data\n",
     "#    y_train_hot: Target data\n",
@@ -914,7 +382,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 32,
    "metadata": {},
    "outputs": [
     {
@@ -940,7 +408,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 33,
    "metadata": {
     "scrolled": true
    },
@@ -954,29 +422,29 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 34,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Model: \"sequential_1\"\n",
+      "Model: \"sequential_2\"\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
-      "conv2d_1 (Conv2D)            (None, 18, 9, 32)         320       \n",
+      "conv2d_2 (Conv2D)            (None, 18, 9, 32)         320       \n",
       "_________________________________________________________________\n",
-      "max_pooling2d_1 (MaxPooling2 (None, 9, 4, 32)          0         \n",
+      "max_pooling2d_2 (MaxPooling2 (None, 9, 4, 32)          0         \n",
       "_________________________________________________________________\n",
-      "flatten_1 (Flatten)          (None, 1152)              0         \n",
+      "flatten_2 (Flatten)          (None, 1152)              0         \n",
       "_________________________________________________________________\n",
-      "dense_1 (Dense)              (None, 128)               147584    \n",
+      "dense_3 (Dense)              (None, 128)               147584    \n",
       "_________________________________________________________________\n",
-      "dense_2 (Dense)              (None, 10)                1290      \n",
+      "dense_4 (Dense)              (None, 12)                1548      \n",
       "=================================================================\n",
-      "Total params: 149,194\n",
-      "Trainable params: 149,194\n",
+      "Total params: 149,452\n",
+      "Trainable params: 149,452\n",
       "Non-trainable params: 0\n",
       "_________________________________________________________________\n"
      ]
@@ -989,48 +457,82 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": 58,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
+      "(1590863,) 44100\n",
+      "(20, 11)\n",
       "PREDICTED VALUES\n",
       "\n",
-      " bus :  0.00002306\n",
+      " bus :  0.00000000\n",
+      "\n",
+      " car_horn :  0.00000000\n",
       "\n",
-      " car_horn :  0.98330659\n",
+      " chainsaw :  0.49116364\n",
       "\n",
-      " chainsaw :  0.00023836\n",
+      " cow :  0.00002702\n",
       "\n",
-      " cow :  0.00675107\n",
+      " engine :  0.00059148\n",
       "\n",
-      " engine :  0.00007791\n",
+      " footsteps :  0.00000002\n",
       "\n",
-      " footsteps :  0.00000021\n",
+      " hand_saw :  0.00468383\n",
       "\n",
-      " hand_saw :  0.00959078\n",
+      " hen :  0.00000036\n",
       "\n",
-      " hen :  0.00000000\n",
+      " NO :  0.50340044\n",
       "\n",
-      " rooster :  0.00001190\n",
+      " rooster :  0.00008686\n",
       "\n",
-      " siren :  0.00000016\n",
+      " siren :  0.00004624\n",
       "\n",
+      " train :  0.00000000\n",
       "\n",
-      "GUESS:  car_horn\n"
+      "\n",
+      "GUESS:  NO\n"
      ]
     }
    ],
    "source": [
     "## Running the model\n",
     "\n",
-    "# Convert wav to MFCC\n",
-    "prediction_data = wav2mfcc('./prediction/cow.wav')\n",
+    "n_mfcc = 20\n",
+    "max_len = 11\n",
+    "# convert file to wav2mfcc\n",
+    "# Mel-frequency cepstral coefficients\n",
+    "file_path = \"./prediction/nature_sc.wav\"\n",
+    "wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
+    "print(wave.shape, sr)\n",
+    "\n",
+    "sec_to_trim = np.array( [ float(20), float(22) ] )\n",
+    "sec_to_trim = np.ceil( sec_to_trim * sr )\n",
+    "\n",
+    "wave = wave[int(sec_to_trim[0]) : int(sec_to_trim[1])]\n",
+    "\n",
+    "wave = np.asfortranarray(wave[::3])\n",
+    "mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)\n",
     "\n",
+    "# If maximum length exceeds mfcc lengths then pad the remaining ones\n",
+    "if (max_len > mfcc.shape[1]):\n",
+    "    pad_width = max_len - mfcc.shape[1]\n",
+    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
+    "\n",
+    "# Else cutoff the remaining parts\n",
+    "else:\n",
+    "    mfcc = mfcc[:, :max_len]\n",
+    "\n",
+    "# Convert wav to MFCC\n",
+    "prediction_data = wav2mfcc('./prediction/nature_sc.wav')\n",
+    "prediction_data = mfcc\n",
+    "print(prediction_data.shape)\n",
+    "#print(wav2mfcc())\n",
     "# Reshape to 4 dimensions\n",
     "prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
+    "prediction_data = prediction_data.reshape(1, 20, config.max_len, channels)\n",
     "\n",
     "# Run the model on the inputted file\n",
     "predicted = loaded_model.predict(prediction_data)\n",
@@ -1077,7 +579,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.8.2"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
diff --git a/ant-cnn/preprocess.py b/ant-cnn/preprocess.py
index e5fe230..9b18914 100644
--- a/ant-cnn/preprocess.py
+++ b/ant-cnn/preprocess.py
@@ -18,7 +18,7 @@ def get_labels(path=DATA_PATH):
 
 # convert file to wav2mfcc
 # Mel-frequency cepstral coefficients
-def wav2mfcc(file_path, n_mfcc=20, max_len=11):
+def wav2mfcc(file_path, n_mfcc=30, max_len=11):
     wave, sr = librosa.load(file_path, mono=True, sr=None)
     wave = np.asfortranarray(wave[::3])
     mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)
