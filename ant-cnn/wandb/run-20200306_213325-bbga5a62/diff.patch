diff --git a/ant-cnn/ant-cnn.ipynb b/ant-cnn/ant-cnn.ipynb
index 27b1e94..fe34e85 100644
--- a/ant-cnn/ant-cnn.ipynb
+++ b/ant-cnn/ant-cnn.ipynb
@@ -2,581 +2,9 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 61,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Using TensorFlow backend.\n",
-      "C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3201: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
-      "  if training is 1 or training is True:\n",
-      "C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3207: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
-      "  elif training is 0 or training is False:\n",
-      "ERROR:root:Internal Python error in the inspect module.\n",
-      "Below is the traceback from this internal error.\n",
-      "\n",
-      "ERROR:root:Internal Python error in the inspect module.\n",
-      "Below is the traceback from this internal error.\n",
-      "\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
-      "    # Try the default getinnerframes and Alex's: Alex's fixes some\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
-      "    inspect.findsource = findsource\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
-      "    def _fixed_getinnerframes(etb, context=1, tb_offset=0):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1503, in getinnerframes\n",
-      "    def trace(context=1):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1461, in getframeinfo\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 708, in getsourcefile\n",
-      "    _filename = getsourcefile(object) or getfile(object)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 745, in getmodule\n",
-      "    # Check the main module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
-      "    from . _api.v2 import audio\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
-      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 8, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
-      "    if (await self.run_code(code, result,  async_=asy)):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\n",
-      "    self.showtraceback(running_compiled_code=True)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
-      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1414, in structured_traceback\n",
-      "    self.tb = tb[0]\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1314, in structured_traceback\n",
-      "    mode = self.mode\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\n",
-      "    formatted_exceptions = formatted_exception\n",
-      "TypeError: can only concatenate str (not \"list\") to str\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
-      "    # Try the default getinnerframes and Alex's: Alex's fixes some\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
-      "    inspect.findsource = findsource\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
-      "    def _fixed_getinnerframes(etb, context=1, tb_offset=0):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1503, in getinnerframes\n",
-      "    def trace(context=1):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 1461, in getframeinfo\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 708, in getsourcefile\n",
-      "    _filename = getsourcefile(object) or getfile(object)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\inspect.py\", line 745, in getmodule\n",
-      "    # Check the main module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
-      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
-      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
-      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
-      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
-      "    from . _api.v2 import audio\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
-      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 8, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
-      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
-      "  File \"<ipython-input-3-301b462f29c8>\", line 1, in <module>\n",
-      "    from preprocess import *\n",
-      "  File \"C:\\Users\\heyjo\\Documents\\School\\Capstone\\intellichirp-snaw-NN\\NN\\ant-cnn\\preprocess.py\", line 4, in <module>\n",
-      "    from keras.utils import to_categorical\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
-      "    from . import utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
-      "    from . import conv_utils\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
-      "    from .. import backend as K\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
-      "    from .load_backend import epsilon\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
-      "    from .tensorflow_backend import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
-      "    import tensorflow as tf\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\n",
-      "    from tensorflow_core import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
-      "    from tensorflow.python.tools import module_util as _module_util\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
-      "    module = self._load()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
-      "    module = _importlib.import_module(self.__name__)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
-      "    from tensorflow.python import pywrap_tensorflow\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
-      "    raise ImportError(msg)\n",
-      "ImportError: Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
-      "    if (await self.run_code(code, result,  async_=asy)):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\n",
-      "    self.showtraceback(running_compiled_code=True)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2046, in showtraceback\n",
-      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1414, in structured_traceback\n",
-      "    self.tb = tb[0]\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1314, in structured_traceback\n",
-      "    mode = self.mode\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1183, in structured_traceback\n",
-      "    formatted_exceptions = formatted_exception\n",
-      "TypeError: can only concatenate str (not \"list\") to str\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
-      "    stb = value._render_traceback_()\n",
-      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
-      "\n",
-      "During handling of the above exception, another exception occurred:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
-      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
-      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
-      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 242, in load_module\n",
-      "    else:\n",
-      "  File \"C:\\Users\\heyjo\\.conda\\envs\\capstone\\lib\\imp.py\", line 342, in load_dynamic\n",
-      "    name=name, loader=loader, origin=path)\n",
-      "ImportError: Module use of python36.dll conflicts with this version of Python.\n",
-      "\n",
-      "\n",
-      "Failed to load the native TensorFlow runtime.\n",
-      "\n",
-      "See https://www.tensorflow.org/install/errors\n",
-      "\n",
-      "for some common reasons and solutions.  Include the entire stack trace\n",
-      "above this error message when asking for help.\n"
-     ]
-    },
-    {
-     "ename": "TypeError",
-     "evalue": "can only concatenate str (not \"list\") to str",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m--> 342\u001b[1;33m             name=name, loader=loader, origin=path)\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mImportError\u001b[0m: Module use of python36.dll conflicts with this version of Python.",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mAttributeError\u001b[0m: 'ImportError' object has no attribute '_render_traceback_'",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3347\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3348\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3350\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[1;31m# tb is a tuple if this is a chained exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1414\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[0mtb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb_offset\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtb_offset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;32m~\\.conda\\envs\\capstone\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[0mlines_of_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m         \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
-      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "from preprocess import *\n",
     "import keras\n",
@@ -590,7 +18,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 62,
    "metadata": {},
    "outputs": [
     {
@@ -598,8 +26,8 @@
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized/runs/iqcktkix\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized/runs/iqcktkix</a><br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/3pt3laxk\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/3pt3laxk</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -613,17 +41,18 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
-      "Saving vectors of label - 'bus': 100%|███████████████████████████████████████████████| 109/109 [00:04<00:00, 22.23it/s]\n",
-      "Saving vectors of label - 'car_horn': 100%|████████████████████████████████████████████| 40/40 [00:00<00:00, 68.21it/s]\n",
-      "Saving vectors of label - 'chainsaw': 100%|████████████████████████████████████████████| 40/40 [00:00<00:00, 43.29it/s]\n",
-      "Saving vectors of label - 'cow': 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 54.85it/s]\n",
-      "Saving vectors of label - 'engine': 100%|██████████████████████████████████████████████| 40/40 [00:00<00:00, 54.93it/s]\n",
-      "Saving vectors of label - 'footsteps': 100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 65.51it/s]\n",
-      "Saving vectors of label - 'hand_saw': 100%|████████████████████████████████████████████| 40/40 [00:00<00:00, 53.98it/s]\n",
-      "Saving vectors of label - 'hen': 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 65.41it/s]\n",
-      "Saving vectors of label - 'rooster': 100%|█████████████████████████████████████████████| 40/40 [00:00<00:00, 68.64it/s]\n",
-      "Saving vectors of label - 'siren': 100%|███████████████████████████████████████████████| 40/40 [00:00<00:00, 55.64it/s]\n"
+      "Saving vectors of label - 'bus': 100%|███████████████████████████████████████████████| 109/109 [00:05<00:00, 18.64it/s]\n",
+      "Saving vectors of label - 'car_horn': 100%|████████████████████████████████████████████| 40/40 [00:00<00:00, 56.17it/s]\n",
+      "Saving vectors of label - 'chainsaw': 100%|████████████████████████████████████████████| 40/40 [00:00<00:00, 49.70it/s]\n",
+      "Saving vectors of label - 'cow': 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 40.59it/s]\n",
+      "Saving vectors of label - 'engine': 100%|██████████████████████████████████████████████| 40/40 [00:00<00:00, 56.57it/s]\n",
+      "Saving vectors of label - 'footsteps': 100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 60.95it/s]\n",
+      "Saving vectors of label - 'hand_saw': 100%|████████████████████████████████████████████| 40/40 [00:00<00:00, 44.56it/s]\n",
+      "Saving vectors of label - 'hen': 100%|█████████████████████████████████████████████████| 40/40 [00:00<00:00, 56.17it/s]\n",
+      "Saving vectors of label - 'NO': 100%|████████████████████████████████████████████████| 802/802 [00:14<00:00, 54.50it/s]\n",
+      "Saving vectors of label - 'rooster': 100%|█████████████████████████████████████████████| 40/40 [00:00<00:00, 62.47it/s]\n",
+      "Saving vectors of label - 'siren': 100%|███████████████████████████████████████████████| 40/40 [00:00<00:00, 57.62it/s]\n",
+      "Saving vectors of label - 'train': 100%|███████████████████████████████████████████████| 40/40 [00:00<00:00, 54.87it/s]\n"
      ]
     }
    ],
@@ -637,12 +66,13 @@
     "# Save data to array file first\n",
     "save_data_to_array(max_len=config.max_len, n_mfcc=config.buckets)\n",
     "\n",
-    "labels=[\"bus\", \"car_horn\", \"chainsaw\", \"cow\", \"engine\", \"footsteps\", \"hand_saw\", \"hen\", \"rooster\", \"siren\"]"
+    "labels=np.array([\"bus\", \"car_horn\", \"chainsaw\", \"cow\", \"engine\", \"footsteps\", \n",
+    "                 \"hand_saw\", \"hen\", \"NO\", \"rooster\", \"siren\", \"train\"])"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 63,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -652,17 +82,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 64,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Setting channels to 1 to generalize stereo sound to 1 channel\n",
     "channels = 1\n",
@@ -670,7 +92,7 @@
     "config.batch_size = 100\n",
     "\n",
     "# Number of classes\n",
-    "num_classes = 10\n",
+    "num_classes = 12\n",
     "\n",
     "# Reshape X_train and X_test to include a 4th dimension (channels)\n",
     "X_train = X_train.reshape(X_train.shape[0], config.buckets, config.max_len, channels)\n",
@@ -679,19 +101,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 65,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "3.0\n"
+      "0.0\n"
      ]
     },
     {
      "data": {
-      "image/png": "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\n",
+      "image/png": "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\n",
       "text/plain": [
        "<Figure size 432x288 with 1 Axes>"
       ]
@@ -710,7 +132,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 66,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -721,7 +143,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 67,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -745,7 +167,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 68,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -757,7 +179,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 69,
    "metadata": {
     "scrolled": false
    },
@@ -767,8 +189,8 @@
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/stevenenriquez/uncategorized/runs/7sybendi\" target=\"_blank\">https://app.wandb.ai/stevenenriquez/uncategorized/runs/7sybendi</a><br/>\n",
+       "                Project page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1m9tku22\" target=\"_blank\">https://app.wandb.ai/joshekruse/intellichirp-snaw-NN/runs/1m9tku22</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -778,134 +200,156 @@
      "metadata": {},
      "output_type": "display_data"
     },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
-     ]
-    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Train on 281 samples, validate on 188 samples\n",
+      "(786, 12)\n",
+      "(12,)\n",
+      "(786, 20, 11, 1)\n",
+      "Train on 786 samples, validate on 525 samples\n",
       "Epoch 1/50\n",
-      "281/281 [==============================] - ETA: 2s - loss: 23.0465 - accuracy: 0.093 - ETA: 0s - loss: 16.3184 - accuracy: 0.085 - 0s 2ms/step - loss: 12.3469 - accuracy: 0.1530 - val_loss: 6.6698 - val_accuracy: 0.2766\n",
+      "786/786 [==============================] - ETA: 13s - loss: 21.9162 - accuracy: 0.03 - ETA: 4s - loss: 12.3656 - accuracy: 0.3854 - ETA: 3s - loss: 12.2906 - accuracy: 0.406 - ETA: 1s - loss: 9.7848 - accuracy: 0.468 - ETA: 1s - loss: 8.4230 - accuracy: 0.51 - ETA: 1s - loss: 8.0626 - accuracy: 0.47 - ETA: 0s - loss: 7.0726 - accuracy: 0.43 - ETA: 0s - loss: 6.6844 - accuracy: 0.44 - ETA: 0s - loss: 6.4649 - accuracy: 0.45 - ETA: 0s - loss: 6.0351 - accuracy: 0.46 - ETA: 0s - loss: 5.7450 - accuracy: 0.47 - 1s 2ms/step - loss: 5.4936 - accuracy: 0.4860 - val_loss: 2.5591 - val_accuracy: 0.5543\n",
       "Epoch 2/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 5.0918 - accuracy: 0.31 - ETA: 0s - loss: 4.7224 - accuracy: 0.26 - 0s 333us/step - loss: 4.5251 - accuracy: 0.2776 - val_loss: 3.5798 - val_accuracy: 0.3138\n",
+      "786/786 [==============================] - ETA: 0s - loss: 1.9318 - accuracy: 0.56 - ETA: 0s - loss: 2.0338 - accuracy: 0.56 - ETA: 0s - loss: 1.9369 - accuracy: 0.53 - ETA: 0s - loss: 1.9988 - accuracy: 0.51 - ETA: 0s - loss: 1.9806 - accuracy: 0.52 - ETA: 0s - loss: 1.9365 - accuracy: 0.54 - ETA: 0s - loss: 1.9343 - accuracy: 0.56 - ETA: 0s - loss: 1.9150 - accuracy: 0.57 - ETA: 0s - loss: 1.9115 - accuracy: 0.56 - ETA: 0s - loss: 1.8963 - accuracy: 0.55 - ETA: 0s - loss: 1.9053 - accuracy: 0.56 - ETA: 0s - loss: 1.8606 - accuracy: 0.56 - ETA: 0s - loss: 1.8112 - accuracy: 0.57 - 1s 1ms/step - loss: 1.7944 - accuracy: 0.5738 - val_loss: 1.7693 - val_accuracy: 0.6000\n",
       "Epoch 3/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 2.9302 - accuracy: 0.37 - ETA: 0s - loss: 2.8241 - accuracy: 0.31 - 0s 325us/step - loss: 2.7315 - accuracy: 0.3203 - val_loss: 2.8565 - val_accuracy: 0.3032\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.9520 - accuracy: 0.68 - ETA: 0s - loss: 0.9342 - accuracy: 0.68 - ETA: 0s - loss: 1.2337 - accuracy: 0.61 - ETA: 0s - loss: 1.2145 - accuracy: 0.62 - ETA: 0s - loss: 1.2343 - accuracy: 0.62 - ETA: 0s - loss: 1.3236 - accuracy: 0.60 - ETA: 0s - loss: 1.2307 - accuracy: 0.63 - ETA: 0s - loss: 1.2523 - accuracy: 0.63 - ETA: 0s - loss: 1.3097 - accuracy: 0.62 - ETA: 0s - loss: 1.2671 - accuracy: 0.64 - ETA: 0s - loss: 1.2691 - accuracy: 0.64 - 1s 882us/step - loss: 1.2732 - accuracy: 0.6399 - val_loss: 1.6988 - val_accuracy: 0.5314\n",
       "Epoch 4/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.7559 - accuracy: 0.46 - ETA: 0s - loss: 1.7744 - accuracy: 0.48 - 0s 297us/step - loss: 1.7635 - accuracy: 0.4911 - val_loss: 2.7842 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 1.0155 - accuracy: 0.62 - ETA: 0s - loss: 1.0566 - accuracy: 0.63 - ETA: 0s - loss: 1.0122 - accuracy: 0.67 - ETA: 0s - loss: 1.0091 - accuracy: 0.70 - ETA: 0s - loss: 1.0333 - accuracy: 0.69 - ETA: 0s - loss: 1.0380 - accuracy: 0.68 - ETA: 0s - loss: 1.0148 - accuracy: 0.68 - ETA: 0s - loss: 1.0978 - accuracy: 0.67 - ETA: 0s - loss: 1.0901 - accuracy: 0.68 - ETA: 0s - loss: 1.1084 - accuracy: 0.67 - ETA: 0s - loss: 1.1136 - accuracy: 0.67 - ETA: 0s - loss: 1.1183 - accuracy: 0.67 - 1s 1ms/step - loss: 1.0833 - accuracy: 0.6743 - val_loss: 1.8150 - val_accuracy: 0.6152\n",
       "Epoch 5/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.9932 - accuracy: 0.59 - ETA: 0s - loss: 1.4765 - accuracy: 0.55 - 0s 500us/step - loss: 1.3992 - accuracy: 0.5658 - val_loss: 2.4757 - val_accuracy: 0.3511\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.8432 - accuracy: 0.75 - ETA: 0s - loss: 0.8707 - accuracy: 0.75 - ETA: 0s - loss: 0.8388 - accuracy: 0.73 - ETA: 0s - loss: 0.8985 - accuracy: 0.71 - ETA: 0s - loss: 0.9348 - accuracy: 0.71 - ETA: 0s - loss: 0.9513 - accuracy: 0.70 - ETA: 0s - loss: 0.9583 - accuracy: 0.69 - ETA: 0s - loss: 0.9468 - accuracy: 0.69 - ETA: 0s - loss: 0.9354 - accuracy: 0.69 - ETA: 0s - loss: 0.9218 - accuracy: 0.70 - ETA: 0s - loss: 0.9154 - accuracy: 0.71 - 1s 919us/step - loss: 0.9059 - accuracy: 0.7176 - val_loss: 1.7286 - val_accuracy: 0.5676\n",
       "Epoch 6/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.0645 - accuracy: 0.65 - ETA: 0s - loss: 1.3214 - accuracy: 0.63 - 0s 539us/step - loss: 1.2217 - accuracy: 0.6548 - val_loss: 2.8309 - val_accuracy: 0.3617\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.75 - ETA: 0s - loss: 0.7729 - accuracy: 0.79 - ETA: 0s - loss: 0.7429 - accuracy: 0.78 - ETA: 0s - loss: 0.8222 - accuracy: 0.75 - ETA: 0s - loss: 0.9085 - accuracy: 0.73 - ETA: 0s - loss: 0.8969 - accuracy: 0.71 - ETA: 0s - loss: 0.8864 - accuracy: 0.72 - ETA: 0s - loss: 0.8600 - accuracy: 0.72 - ETA: 0s - loss: 0.8553 - accuracy: 0.72 - ETA: 0s - loss: 0.8287 - accuracy: 0.73 - ETA: 0s - loss: 0.8312 - accuracy: 0.73 - ETA: 0s - loss: 0.8192 - accuracy: 0.73 - ETA: 0s - loss: 0.8564 - accuracy: 0.73 - 1s 1ms/step - loss: 0.8995 - accuracy: 0.7277 - val_loss: 1.7172 - val_accuracy: 0.5124\n",
       "Epoch 7/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.7947 - accuracy: 0.78 - ETA: 0s - loss: 1.0072 - accuracy: 0.69 - 0s 374us/step - loss: 1.0246 - accuracy: 0.7011 - val_loss: 2.5759 - val_accuracy: 0.4202\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.9112 - accuracy: 0.62 - ETA: 0s - loss: 1.1176 - accuracy: 0.57 - ETA: 1s - loss: 1.0615 - accuracy: 0.62 - ETA: 0s - loss: 0.9317 - accuracy: 0.68 - ETA: 0s - loss: 0.8904 - accuracy: 0.69 - ETA: 0s - loss: 0.9892 - accuracy: 0.67 - ETA: 0s - loss: 1.0517 - accuracy: 0.67 - ETA: 0s - loss: 1.0433 - accuracy: 0.66 - ETA: 0s - loss: 1.0467 - accuracy: 0.66 - ETA: 0s - loss: 1.0315 - accuracy: 0.67 - ETA: 0s - loss: 1.0078 - accuracy: 0.67 - ETA: 0s - loss: 0.9882 - accuracy: 0.68 - ETA: 0s - loss: 0.9852 - accuracy: 0.68 - ETA: 0s - loss: 0.9815 - accuracy: 0.68 - ETA: 0s - loss: 0.9848 - accuracy: 0.68 - 1s 1ms/step - loss: 0.9622 - accuracy: 0.6959 - val_loss: 1.7907 - val_accuracy: 0.6171\n",
       "Epoch 8/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.75 - ETA: 0s - loss: 1.0584 - accuracy: 0.65 - 0s 335us/step - loss: 0.9949 - accuracy: 0.6797 - val_loss: 2.7374 - val_accuracy: 0.4096\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.93 - ETA: 1s - loss: 0.4561 - accuracy: 0.89 - ETA: 0s - loss: 0.6055 - accuracy: 0.81 - ETA: 0s - loss: 0.6041 - accuracy: 0.81 - ETA: 0s - loss: 0.5946 - accuracy: 0.82 - ETA: 0s - loss: 0.6078 - accuracy: 0.82 - ETA: 0s - loss: 0.6935 - accuracy: 0.79 - ETA: 0s - loss: 0.6670 - accuracy: 0.80 - ETA: 0s - loss: 0.6592 - accuracy: 0.80 - ETA: 0s - loss: 0.6742 - accuracy: 0.79 - ETA: 0s - loss: 0.6807 - accuracy: 0.79 - ETA: 0s - loss: 0.6911 - accuracy: 0.78 - ETA: 0s - loss: 0.7054 - accuracy: 0.77 - ETA: 0s - loss: 0.6978 - accuracy: 0.77 - 1s 1ms/step - loss: 0.7103 - accuracy: 0.7723 - val_loss: 1.5131 - val_accuracy: 0.5867\n",
       "Epoch 9/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.78 - 0s 288us/step - loss: 0.8002 - accuracy: 0.7722 - val_loss: 2.5783 - val_accuracy: 0.4096\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.84 - ETA: 0s - loss: 0.7282 - accuracy: 0.76 - ETA: 0s - loss: 0.6784 - accuracy: 0.75 - ETA: 0s - loss: 0.6719 - accuracy: 0.75 - ETA: 0s - loss: 0.6301 - accuracy: 0.77 - ETA: 0s - loss: 0.6523 - accuracy: 0.77 - ETA: 0s - loss: 0.6447 - accuracy: 0.77 - ETA: 0s - loss: 0.6373 - accuracy: 0.78 - ETA: 0s - loss: 0.6326 - accuracy: 0.79 - ETA: 0s - loss: 0.6116 - accuracy: 0.80 - ETA: 0s - loss: 0.6147 - accuracy: 0.79 - ETA: 0s - loss: 0.5908 - accuracy: 0.80 - 1s 915us/step - loss: 0.5973 - accuracy: 0.8092 - val_loss: 1.5913 - val_accuracy: 0.6210\n",
       "Epoch 10/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.81 - ETA: 0s - loss: 0.7422 - accuracy: 0.78 - ETA: 0s - loss: 0.7563 - accuracy: 0.77 - 0s 730us/step - loss: 0.7588 - accuracy: 0.7722 - val_loss: 2.8751 - val_accuracy: 0.3883\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.4102 - accuracy: 0.90 - ETA: 0s - loss: 0.4209 - accuracy: 0.88 - ETA: 1s - loss: 0.4435 - accuracy: 0.86 - ETA: 0s - loss: 0.4535 - accuracy: 0.85 - ETA: 0s - loss: 0.4877 - accuracy: 0.84 - ETA: 0s - loss: 0.5155 - accuracy: 0.82 - ETA: 0s - loss: 0.5010 - accuracy: 0.83 - ETA: 0s - loss: 0.5118 - accuracy: 0.83 - ETA: 0s - loss: 0.5300 - accuracy: 0.83 - ETA: 0s - loss: 0.5402 - accuracy: 0.83 - ETA: 0s - loss: 0.5289 - accuracy: 0.83 - ETA: 0s - loss: 0.5373 - accuracy: 0.82 - ETA: 0s - loss: 0.5832 - accuracy: 0.81 - ETA: 0s - loss: 0.6115 - accuracy: 0.81 - ETA: 0s - loss: 0.6116 - accuracy: 0.81 - 1s 1ms/step - loss: 0.6072 - accuracy: 0.8092 - val_loss: 1.6803 - val_accuracy: 0.6305\n",
       "Epoch 11/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 1.2013 - accuracy: 0.75 - ETA: 0s - loss: 0.6930 - accuracy: 0.81 - 0s 501us/step - loss: 0.6858 - accuracy: 0.8185 - val_loss: 2.6259 - val_accuracy: 0.3564\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.71 - ETA: 0s - loss: 0.4520 - accuracy: 0.84 - ETA: 0s - loss: 0.5207 - accuracy: 0.81 - ETA: 0s - loss: 0.5468 - accuracy: 0.80 - ETA: 0s - loss: 0.5496 - accuracy: 0.80 - ETA: 0s - loss: 0.5351 - accuracy: 0.81 - ETA: 0s - loss: 0.5135 - accuracy: 0.82 - ETA: 0s - loss: 0.5044 - accuracy: 0.82 - ETA: 0s - loss: 0.4997 - accuracy: 0.82 - ETA: 0s - loss: 0.5224 - accuracy: 0.82 - ETA: 0s - loss: 0.5253 - accuracy: 0.82 - ETA: 0s - loss: 0.5127 - accuracy: 0.82 - 1s 1ms/step - loss: 0.5113 - accuracy: 0.8295 - val_loss: 1.9395 - val_accuracy: 0.6286\n",
       "Epoch 12/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.93 - ETA: 0s - loss: 0.5313 - accuracy: 0.84 - 0s 320us/step - loss: 0.5298 - accuracy: 0.8470 - val_loss: 2.7889 - val_accuracy: 0.3511\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.90 - ETA: 0s - loss: 0.4063 - accuracy: 0.84 - ETA: 0s - loss: 0.4466 - accuracy: 0.84 - ETA: 0s - loss: 0.4442 - accuracy: 0.85 - ETA: 0s - loss: 0.4251 - accuracy: 0.86 - ETA: 0s - loss: 0.4401 - accuracy: 0.86 - ETA: 0s - loss: 0.4299 - accuracy: 0.86 - ETA: 0s - loss: 0.4208 - accuracy: 0.85 - ETA: 0s - loss: 0.4214 - accuracy: 0.86 - ETA: 0s - loss: 0.4173 - accuracy: 0.86 - ETA: 0s - loss: 0.4121 - accuracy: 0.86 - ETA: 0s - loss: 0.4154 - accuracy: 0.86 - ETA: 0s - loss: 0.4259 - accuracy: 0.86 - 1s 1ms/step - loss: 0.4201 - accuracy: 0.8651 - val_loss: 1.6163 - val_accuracy: 0.6324\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
       "Epoch 13/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.84 - ETA: 0s - loss: 0.5497 - accuracy: 0.84 - 0s 340us/step - loss: 0.5385 - accuracy: 0.8505 - val_loss: 2.6226 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.84 - ETA: 0s - loss: 0.3056 - accuracy: 0.90 - ETA: 1s - loss: 0.2930 - accuracy: 0.90 - ETA: 1s - loss: 0.2798 - accuracy: 0.91 - ETA: 0s - loss: 0.3089 - accuracy: 0.90 - ETA: 0s - loss: 0.3126 - accuracy: 0.89 - ETA: 0s - loss: 0.3224 - accuracy: 0.90 - ETA: 0s - loss: 0.3215 - accuracy: 0.90 - 1s 740us/step - loss: 0.3225 - accuracy: 0.9059 - val_loss: 1.6643 - val_accuracy: 0.6381\n",
       "Epoch 14/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.90 - ETA: 0s - loss: 0.5003 - accuracy: 0.87 - 0s 353us/step - loss: 0.4798 - accuracy: 0.8826 - val_loss: 2.9803 - val_accuracy: 0.3138\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.93 - ETA: 0s - loss: 0.2581 - accuracy: 0.93 - ETA: 0s - loss: 0.2615 - accuracy: 0.93 - ETA: 0s - loss: 0.2539 - accuracy: 0.92 - ETA: 0s - loss: 0.2979 - accuracy: 0.90 - ETA: 0s - loss: 0.3017 - accuracy: 0.90 - ETA: 0s - loss: 0.2919 - accuracy: 0.91 - ETA: 0s - loss: 0.2844 - accuracy: 0.91 - ETA: 0s - loss: 0.2696 - accuracy: 0.93 - ETA: 0s - loss: 0.2793 - accuracy: 0.93 - ETA: 0s - loss: 0.2861 - accuracy: 0.93 - 1s 851us/step - loss: 0.3026 - accuracy: 0.9249 - val_loss: 1.7164 - val_accuracy: 0.6210\n",
       "Epoch 15/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.84 - 0s 276us/step - loss: 0.4402 - accuracy: 0.9004 - val_loss: 2.6732 - val_accuracy: 0.4043\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.96 - ETA: 0s - loss: 0.2094 - accuracy: 0.93 - ETA: 0s - loss: 0.2115 - accuracy: 0.94 - ETA: 0s - loss: 0.2225 - accuracy: 0.93 - ETA: 0s - loss: 0.2325 - accuracy: 0.94 - ETA: 0s - loss: 0.2496 - accuracy: 0.94 - ETA: 0s - loss: 0.2440 - accuracy: 0.93 - ETA: 0s - loss: 0.2413 - accuracy: 0.93 - ETA: 0s - loss: 0.2418 - accuracy: 0.93 - ETA: 0s - loss: 0.2591 - accuracy: 0.92 - ETA: 0s - loss: 0.2600 - accuracy: 0.92 - 1s 865us/step - loss: 0.2592 - accuracy: 0.9275 - val_loss: 1.7823 - val_accuracy: 0.5981\n",
       "Epoch 16/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.93 - ETA: 0s - loss: 0.3664 - accuracy: 0.89 - 0s 327us/step - loss: 0.3706 - accuracy: 0.8897 - val_loss: 2.9172 - val_accuracy: 0.3457\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.1611 - accuracy: 1.00 - ETA: 0s - loss: 0.1475 - accuracy: 0.97 - ETA: 0s - loss: 0.1519 - accuracy: 0.97 - ETA: 0s - loss: 0.1811 - accuracy: 0.96 - ETA: 0s - loss: 0.1841 - accuracy: 0.95 - ETA: 0s - loss: 0.1894 - accuracy: 0.95 - ETA: 0s - loss: 0.2184 - accuracy: 0.94 - ETA: 0s - loss: 0.2253 - accuracy: 0.93 - ETA: 0s - loss: 0.2279 - accuracy: 0.93 - ETA: 0s - loss: 0.2220 - accuracy: 0.94 - ETA: 0s - loss: 0.2211 - accuracy: 0.94 - ETA: 0s - loss: 0.2190 - accuracy: 0.94 - ETA: 0s - loss: 0.2215 - accuracy: 0.94 - ETA: 0s - loss: 0.2178 - accuracy: 0.94 - 1s 1ms/step - loss: 0.2184 - accuracy: 0.9402 - val_loss: 1.7079 - val_accuracy: 0.6229\n",
       "Epoch 17/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - 0s 261us/step - loss: 0.3737 - accuracy: 0.9004 - val_loss: 2.7488 - val_accuracy: 0.4043\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.93 - ETA: 0s - loss: 0.2857 - accuracy: 0.91 - ETA: 0s - loss: 0.2398 - accuracy: 0.93 - ETA: 0s - loss: 0.2177 - accuracy: 0.95 - ETA: 0s - loss: 0.2221 - accuracy: 0.95 - ETA: 0s - loss: 0.2295 - accuracy: 0.95 - ETA: 0s - loss: 0.2256 - accuracy: 0.95 - ETA: 0s - loss: 0.2101 - accuracy: 0.96 - ETA: 0s - loss: 0.2102 - accuracy: 0.95 - ETA: 0s - loss: 0.2167 - accuracy: 0.95 - ETA: 0s - loss: 0.2149 - accuracy: 0.95 - 1s 897us/step - loss: 0.2059 - accuracy: 0.9593 - val_loss: 1.8165 - val_accuracy: 0.6324\n",
       "Epoch 18/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.90 - ETA: 0s - loss: 0.3444 - accuracy: 0.91 - 0s 328us/step - loss: 0.3300 - accuracy: 0.9217 - val_loss: 2.8965 - val_accuracy: 0.4255\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1594 - accuracy: 0.96 - ETA: 0s - loss: 0.1654 - accuracy: 0.96 - ETA: 0s - loss: 0.1293 - accuracy: 0.97 - ETA: 0s - loss: 0.1367 - accuracy: 0.96 - ETA: 0s - loss: 0.1427 - accuracy: 0.96 - ETA: 0s - loss: 0.1499 - accuracy: 0.96 - ETA: 0s - loss: 0.1608 - accuracy: 0.96 - ETA: 0s - loss: 0.1743 - accuracy: 0.96 - ETA: 0s - loss: 0.1742 - accuracy: 0.96 - ETA: 0s - loss: 0.1704 - accuracy: 0.96 - ETA: 0s - loss: 0.1697 - accuracy: 0.96 - ETA: 0s - loss: 0.1754 - accuracy: 0.95 - ETA: 0s - loss: 0.1763 - accuracy: 0.96 - ETA: 0s - loss: 0.1847 - accuracy: 0.95 - 1s 1ms/step - loss: 0.1846 - accuracy: 0.9567 - val_loss: 2.0230 - val_accuracy: 0.6514\n",
       "Epoch 19/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.93 - ETA: 0s - loss: 0.3102 - accuracy: 0.91 - 0s 381us/step - loss: 0.3142 - accuracy: 0.9146 - val_loss: 3.0782 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.90 - ETA: 0s - loss: 0.2988 - accuracy: 0.93 - ETA: 0s - loss: 0.2830 - accuracy: 0.92 - ETA: 0s - loss: 0.2691 - accuracy: 0.93 - ETA: 0s - loss: 0.2717 - accuracy: 0.91 - ETA: 0s - loss: 0.2677 - accuracy: 0.91 - ETA: 0s - loss: 0.2576 - accuracy: 0.92 - ETA: 0s - loss: 0.2680 - accuracy: 0.91 - ETA: 0s - loss: 0.2651 - accuracy: 0.92 - ETA: 0s - loss: 0.2571 - accuracy: 0.92 - ETA: 0s - loss: 0.2531 - accuracy: 0.92 - ETA: 0s - loss: 0.2482 - accuracy: 0.92 - ETA: 0s - loss: 0.2550 - accuracy: 0.92 - 1s 1ms/step - loss: 0.2524 - accuracy: 0.9249 - val_loss: 1.6976 - val_accuracy: 0.6286\n",
       "Epoch 20/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.87 - ETA: 0s - loss: 0.2662 - accuracy: 0.94 - 0s 349us/step - loss: 0.2553 - accuracy: 0.9466 - val_loss: 2.9722 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.1785 - accuracy: 0.96 - ETA: 0s - loss: 0.1109 - accuracy: 0.98 - ETA: 0s - loss: 0.1249 - accuracy: 0.98 - ETA: 0s - loss: 0.1473 - accuracy: 0.97 - ETA: 0s - loss: 0.1357 - accuracy: 0.97 - ETA: 0s - loss: 0.1480 - accuracy: 0.97 - ETA: 0s - loss: 0.1451 - accuracy: 0.97 - ETA: 0s - loss: 0.1443 - accuracy: 0.97 - ETA: 0s - loss: 0.1442 - accuracy: 0.97 - ETA: 0s - loss: 0.1491 - accuracy: 0.96 - ETA: 0s - loss: 0.1461 - accuracy: 0.96 - 1s 1ms/step - loss: 0.1482 - accuracy: 0.9656 - val_loss: 1.8271 - val_accuracy: 0.6267\n",
       "Epoch 21/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.84 - ETA: 0s - loss: 0.2778 - accuracy: 0.92 - 0s 328us/step - loss: 0.2780 - accuracy: 0.9288 - val_loss: 3.1543 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 1.00 - ETA: 0s - loss: 0.1153 - accuracy: 0.96 - ETA: 0s - loss: 0.1512 - accuracy: 0.96 - ETA: 0s - loss: 0.1461 - accuracy: 0.96 - ETA: 0s - loss: 0.1501 - accuracy: 0.95 - ETA: 0s - loss: 0.1638 - accuracy: 0.95 - ETA: 0s - loss: 0.1563 - accuracy: 0.96 - ETA: 0s - loss: 0.1545 - accuracy: 0.96 - ETA: 0s - loss: 0.1583 - accuracy: 0.96 - ETA: 0s - loss: 0.1651 - accuracy: 0.95 - ETA: 0s - loss: 0.1602 - accuracy: 0.96 - ETA: 0s - loss: 0.1631 - accuracy: 0.95 - ETA: 0s - loss: 0.1611 - accuracy: 0.96 - ETA: 0s - loss: 0.1690 - accuracy: 0.95 - 1s 1ms/step - loss: 0.1678 - accuracy: 0.9567 - val_loss: 1.8493 - val_accuracy: 0.6114\n",
       "Epoch 22/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.93 - ETA: 0s - loss: 0.2018 - accuracy: 0.95 - 0s 312us/step - loss: 0.2135 - accuracy: 0.9573 - val_loss: 3.0016 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 1.00 - ETA: 0s - loss: 0.1512 - accuracy: 0.96 - ETA: 0s - loss: 0.1494 - accuracy: 0.96 - ETA: 0s - loss: 0.1701 - accuracy: 0.96 - ETA: 0s - loss: 0.1690 - accuracy: 0.96 - ETA: 0s - loss: 0.1619 - accuracy: 0.97 - ETA: 0s - loss: 0.1499 - accuracy: 0.97 - ETA: 0s - loss: 0.1661 - accuracy: 0.96 - ETA: 0s - loss: 0.1622 - accuracy: 0.96 - ETA: 0s - loss: 0.1588 - accuracy: 0.96 - ETA: 0s - loss: 0.1566 - accuracy: 0.96 - ETA: 0s - loss: 0.1572 - accuracy: 0.96 - ETA: 0s - loss: 0.1539 - accuracy: 0.96 - 1s 1ms/step - loss: 0.1518 - accuracy: 0.9695 - val_loss: 1.8508 - val_accuracy: 0.6457\n",
       "Epoch 23/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 1.00 - ETA: 0s - loss: 0.1672 - accuracy: 0.96 - 0s 391us/step - loss: 0.1630 - accuracy: 0.9680 - val_loss: 2.9483 - val_accuracy: 0.4149\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.96 - ETA: 0s - loss: 0.0900 - accuracy: 0.98 - ETA: 0s - loss: 0.0845 - accuracy: 0.98 - ETA: 0s - loss: 0.0994 - accuracy: 0.97 - ETA: 0s - loss: 0.0984 - accuracy: 0.97 - ETA: 0s - loss: 0.1446 - accuracy: 0.96 - ETA: 0s - loss: 0.1333 - accuracy: 0.97 - ETA: 0s - loss: 0.1302 - accuracy: 0.97 - ETA: 0s - loss: 0.1259 - accuracy: 0.97 - ETA: 0s - loss: 0.1205 - accuracy: 0.97 - ETA: 0s - loss: 0.1302 - accuracy: 0.97 - ETA: 0s - loss: 0.1278 - accuracy: 0.97 - ETA: 0s - loss: 0.1233 - accuracy: 0.97 - ETA: 0s - loss: 0.1187 - accuracy: 0.98 - 1s 1ms/step - loss: 0.1225 - accuracy: 0.9796 - val_loss: 1.9598 - val_accuracy: 0.6343\n",
       "Epoch 24/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 1.00 - ETA: 0s - loss: 0.1391 - accuracy: 0.97 - ETA: 0s - loss: 0.1322 - accuracy: 0.98 - 0s 742us/step - loss: 0.1495 - accuracy: 0.9786 - val_loss: 3.1443 - val_accuracy: 0.3723\n",
-      "Epoch 25/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.96 - ETA: 0s - loss: 0.1644 - accuracy: 0.96 - 0s 345us/step - loss: 0.1596 - accuracy: 0.9680 - val_loss: 3.1408 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.96 - ETA: 0s - loss: 0.1401 - accuracy: 0.98 - ETA: 0s - loss: 0.1215 - accuracy: 0.99 - ETA: 0s - loss: 0.1206 - accuracy: 0.98 - ETA: 0s - loss: 0.1169 - accuracy: 0.98 - ETA: 0s - loss: 0.1096 - accuracy: 0.99 - ETA: 0s - loss: 0.0985 - accuracy: 0.99 - ETA: 0s - loss: 0.0967 - accuracy: 0.98 - ETA: 0s - loss: 0.0964 - accuracy: 0.99 - ETA: 0s - loss: 0.0928 - accuracy: 0.99 - ETA: 0s - loss: 0.0919 - accuracy: 0.99 - ETA: 0s - loss: 0.0995 - accuracy: 0.98 - ETA: 0s - loss: 0.1078 - accuracy: 0.98 - ETA: 0s - loss: 0.1080 - accuracy: 0.98 - ETA: 0s - loss: 0.1142 - accuracy: 0.98 - ETA: 0s - loss: 0.1160 - accuracy: 0.98 - ETA: 0s - loss: 0.1142 - accuracy: 0.98 - 1s 2ms/step - loss: 0.1123 - accuracy: 0.9835 - val_loss: 2.3322 - val_accuracy: 0.6343\n",
+      "Epoch 25/50\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "786/786 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.96 - ETA: 1s - loss: 0.3394 - accuracy: 0.95 - ETA: 0s - loss: 0.1959 - accuracy: 0.97 - ETA: 0s - loss: 0.1689 - accuracy: 0.97 - ETA: 0s - loss: 0.2122 - accuracy: 0.97 - ETA: 0s - loss: 0.1802 - accuracy: 0.97 - ETA: 0s - loss: 0.1698 - accuracy: 0.97 - ETA: 0s - loss: 0.1604 - accuracy: 0.97 - ETA: 0s - loss: 0.1491 - accuracy: 0.97 - 1s 727us/step - loss: 0.1389 - accuracy: 0.9784 - val_loss: 2.0874 - val_accuracy: 0.6476\n",
       "Epoch 26/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.96 - 0s 279us/step - loss: 0.1713 - accuracy: 0.9644 - val_loss: 3.3056 - val_accuracy: 0.3883\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 1.00 - ETA: 0s - loss: 0.1029 - accuracy: 0.96 - ETA: 0s - loss: 0.1355 - accuracy: 0.97 - ETA: 0s - loss: 0.1234 - accuracy: 0.98 - ETA: 0s - loss: 0.0992 - accuracy: 0.98 - ETA: 0s - loss: 0.0926 - accuracy: 0.98 - ETA: 0s - loss: 0.1040 - accuracy: 0.98 - ETA: 0s - loss: 0.1000 - accuracy: 0.98 - ETA: 0s - loss: 0.1064 - accuracy: 0.97 - ETA: 0s - loss: 0.1043 - accuracy: 0.98 - 1s 827us/step - loss: 0.1028 - accuracy: 0.9809 - val_loss: 1.9369 - val_accuracy: 0.6057\n",
       "Epoch 27/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 1.00 - ETA: 0s - loss: 0.1034 - accuracy: 0.98 - 0s 358us/step - loss: 0.1384 - accuracy: 0.9786 - val_loss: 3.1630 - val_accuracy: 0.3564\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.90 - ETA: 0s - loss: 0.1248 - accuracy: 0.95 - ETA: 0s - loss: 0.0986 - accuracy: 0.97 - ETA: 0s - loss: 0.1046 - accuracy: 0.97 - ETA: 0s - loss: 0.0963 - accuracy: 0.97 - ETA: 0s - loss: 0.0951 - accuracy: 0.97 - ETA: 0s - loss: 0.0926 - accuracy: 0.97 - ETA: 0s - loss: 0.0917 - accuracy: 0.97 - ETA: 0s - loss: 0.0946 - accuracy: 0.97 - ETA: 0s - loss: 0.1012 - accuracy: 0.97 - ETA: 0s - loss: 0.1000 - accuracy: 0.97 - 1s 954us/step - loss: 0.1062 - accuracy: 0.9707 - val_loss: 2.1511 - val_accuracy: 0.6324\n",
       "Epoch 28/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 1.00 - 0s 334us/step - loss: 0.1158 - accuracy: 0.9786 - val_loss: 3.2077 - val_accuracy: 0.3936\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 1.00 - ETA: 0s - loss: 0.1027 - accuracy: 0.97 - ETA: 0s - loss: 0.0925 - accuracy: 0.98 - ETA: 0s - loss: 0.1142 - accuracy: 0.98 - ETA: 0s - loss: 0.1060 - accuracy: 0.98 - ETA: 0s - loss: 0.1050 - accuracy: 0.98 - ETA: 0s - loss: 0.1410 - accuracy: 0.97 - ETA: 0s - loss: 0.1435 - accuracy: 0.97 - 0s 607us/step - loss: 0.1365 - accuracy: 0.9758 - val_loss: 2.2867 - val_accuracy: 0.6438\n",
       "Epoch 29/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 1.00 - ETA: 0s - loss: 0.1380 - accuracy: 0.97 - ETA: 0s - loss: 0.1156 - accuracy: 0.98 - 0s 595us/step - loss: 0.1128 - accuracy: 0.9822 - val_loss: 3.3168 - val_accuracy: 0.3989\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 1.00 - ETA: 0s - loss: 0.2079 - accuracy: 0.97 - ETA: 0s - loss: 0.1607 - accuracy: 0.96 - ETA: 0s - loss: 0.1365 - accuracy: 0.96 - ETA: 0s - loss: 0.1237 - accuracy: 0.97 - ETA: 0s - loss: 0.1174 - accuracy: 0.97 - ETA: 0s - loss: 0.1292 - accuracy: 0.97 - ETA: 0s - loss: 0.1329 - accuracy: 0.96 - ETA: 0s - loss: 0.1496 - accuracy: 0.96 - ETA: 0s - loss: 0.1526 - accuracy: 0.96 - ETA: 0s - loss: 0.1498 - accuracy: 0.96 - ETA: 0s - loss: 0.1440 - accuracy: 0.96 - 1s 1ms/step - loss: 0.1410 - accuracy: 0.9631 - val_loss: 2.1652 - val_accuracy: 0.6286\n",
       "Epoch 30/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 1.00 - ETA: 0s - loss: 0.0954 - accuracy: 0.98 - 0s 515us/step - loss: 0.0994 - accuracy: 0.9893 - val_loss: 3.3483 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - ETA: 0s - loss: 0.0685 - accuracy: 0.97 - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.1085 - accuracy: 0.96 - ETA: 0s - loss: 0.1006 - accuracy: 0.96 - ETA: 0s - loss: 0.1058 - accuracy: 0.97 - ETA: 0s - loss: 0.1017 - accuracy: 0.97 - ETA: 0s - loss: 0.0960 - accuracy: 0.97 - ETA: 0s - loss: 0.0975 - accuracy: 0.97 - ETA: 0s - loss: 0.0985 - accuracy: 0.97 - ETA: 0s - loss: 0.0935 - accuracy: 0.97 - 1s 962us/step - loss: 0.0996 - accuracy: 0.9771 - val_loss: 2.1410 - val_accuracy: 0.6324\n",
       "Epoch 31/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 1.00 - 0s 258us/step - loss: 0.0910 - accuracy: 0.9786 - val_loss: 3.3935 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 1.00 - ETA: 0s - loss: 0.0822 - accuracy: 0.96 - ETA: 0s - loss: 0.0755 - accuracy: 0.97 - ETA: 0s - loss: 0.0684 - accuracy: 0.98 - ETA: 0s - loss: 0.0755 - accuracy: 0.97 - ETA: 0s - loss: 0.0879 - accuracy: 0.97 - ETA: 0s - loss: 0.0966 - accuracy: 0.97 - ETA: 0s - loss: 0.0928 - accuracy: 0.97 - ETA: 0s - loss: 0.0870 - accuracy: 0.97 - ETA: 0s - loss: 0.0838 - accuracy: 0.97 - ETA: 0s - loss: 0.0866 - accuracy: 0.97 - 1s 898us/step - loss: 0.0925 - accuracy: 0.9758 - val_loss: 2.2010 - val_accuracy: 0.6229\n",
       "Epoch 32/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 1.00 - ETA: 0s - loss: 0.1474 - accuracy: 0.98 - 0s 411us/step - loss: 0.1534 - accuracy: 0.9822 - val_loss: 3.4210 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.00 - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - ETA: 0s - loss: 0.0398 - accuracy: 1.00 - ETA: 0s - loss: 0.0362 - accuracy: 1.00 - ETA: 0s - loss: 0.0381 - accuracy: 1.00 - ETA: 0s - loss: 0.0623 - accuracy: 0.99 - ETA: 0s - loss: 0.0745 - accuracy: 0.98 - ETA: 0s - loss: 0.0716 - accuracy: 0.98 - ETA: 0s - loss: 0.0715 - accuracy: 0.98 - ETA: 0s - loss: 0.0629 - accuracy: 0.98 - ETA: 0s - loss: 0.0798 - accuracy: 0.98 - ETA: 0s - loss: 0.0775 - accuracy: 0.98 - ETA: 0s - loss: 0.0751 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0718 - accuracy: 0.9873 - val_loss: 2.0527 - val_accuracy: 0.6457\n",
       "Epoch 33/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.93 - ETA: 0s - loss: 0.1145 - accuracy: 0.98 - 0s 453us/step - loss: 0.1363 - accuracy: 0.9822 - val_loss: 3.5561 - val_accuracy: 0.4096\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.0228 - accuracy: 1.00 - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - ETA: 0s - loss: 0.0309 - accuracy: 0.99 - ETA: 0s - loss: 0.0527 - accuracy: 0.99 - ETA: 0s - loss: 0.0502 - accuracy: 0.99 - ETA: 0s - loss: 0.0495 - accuracy: 0.99 - ETA: 0s - loss: 0.0539 - accuracy: 0.98 - ETA: 0s - loss: 0.0552 - accuracy: 0.98 - ETA: 0s - loss: 0.0537 - accuracy: 0.98 - ETA: 0s - loss: 0.0525 - accuracy: 0.98 - 1s 888us/step - loss: 0.0510 - accuracy: 0.9898 - val_loss: 2.4093 - val_accuracy: 0.6476\n",
       "Epoch 34/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.96 - ETA: 0s - loss: 0.1624 - accuracy: 0.95 - 0s 365us/step - loss: 0.1564 - accuracy: 0.9537 - val_loss: 3.7636 - val_accuracy: 0.3883\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - ETA: 0s - loss: 0.0780 - accuracy: 0.99 - ETA: 0s - loss: 0.1391 - accuracy: 0.98 - ETA: 0s - loss: 0.1430 - accuracy: 0.98 - ETA: 0s - loss: 0.1420 - accuracy: 0.98 - ETA: 0s - loss: 0.1232 - accuracy: 0.98 - ETA: 0s - loss: 0.1186 - accuracy: 0.98 - ETA: 0s - loss: 0.1286 - accuracy: 0.98 - ETA: 0s - loss: 0.1244 - accuracy: 0.98 - ETA: 0s - loss: 0.1309 - accuracy: 0.97 - 1s 950us/step - loss: 0.1284 - accuracy: 0.9784 - val_loss: 2.1528 - val_accuracy: 0.6305\n",
       "Epoch 35/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.96 - ETA: 0s - loss: 0.1620 - accuracy: 0.94 - 0s 436us/step - loss: 0.1161 - accuracy: 0.9680 - val_loss: 3.4313 - val_accuracy: 0.3617\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.96 - ETA: 1s - loss: 0.1270 - accuracy: 0.98 - ETA: 0s - loss: 0.0991 - accuracy: 0.97 - ETA: 0s - loss: 0.0834 - accuracy: 0.98 - ETA: 0s - loss: 0.0821 - accuracy: 0.98 - ETA: 0s - loss: 0.0892 - accuracy: 0.98 - ETA: 0s - loss: 0.0791 - accuracy: 0.98 - ETA: 0s - loss: 0.0817 - accuracy: 0.98 - ETA: 0s - loss: 0.0822 - accuracy: 0.98 - ETA: 0s - loss: 0.0773 - accuracy: 0.98 - ETA: 0s - loss: 0.0743 - accuracy: 0.98 - ETA: 0s - loss: 0.0723 - accuracy: 0.98 - ETA: 0s - loss: 0.0690 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0772 - accuracy: 0.9847 - val_loss: 2.1421 - val_accuracy: 0.6362\n",
       "Epoch 36/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.96 - ETA: 0s - loss: 0.1088 - accuracy: 0.98 - 0s 341us/step - loss: 0.1037 - accuracy: 0.9822 - val_loss: 3.5027 - val_accuracy: 0.3404\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - ETA: 0s - loss: 0.0452 - accuracy: 0.98 - ETA: 0s - loss: 0.0415 - accuracy: 0.99 - ETA: 0s - loss: 0.0524 - accuracy: 0.98 - ETA: 0s - loss: 0.0408 - accuracy: 0.99 - ETA: 0s - loss: 0.0372 - accuracy: 0.99 - ETA: 0s - loss: 0.0355 - accuracy: 0.99 - ETA: 0s - loss: 0.0364 - accuracy: 0.99 - ETA: 0s - loss: 0.0409 - accuracy: 0.99 - ETA: 0s - loss: 0.0378 - accuracy: 0.99 - ETA: 0s - loss: 0.0419 - accuracy: 0.99 - ETA: 0s - loss: 0.0413 - accuracy: 0.99 - 1s 1ms/step - loss: 0.0408 - accuracy: 0.9924 - val_loss: 2.2301 - val_accuracy: 0.6419\n",
       "Epoch 37/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 1.00 - 0s 276us/step - loss: 0.0928 - accuracy: 0.9786 - val_loss: 3.4027 - val_accuracy: 0.3830\n",
-      "Epoch 38/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 1.00 - ETA: 0s - loss: 0.1070 - accuracy: 0.98 - 0s 527us/step - loss: 0.1131 - accuracy: 0.9858 - val_loss: 3.4673 - val_accuracy: 0.4043\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 1.00 - ETA: 0s - loss: 0.0440 - accuracy: 0.99 - ETA: 0s - loss: 0.0571 - accuracy: 0.98 - ETA: 0s - loss: 0.0570 - accuracy: 0.98 - ETA: 0s - loss: 0.0466 - accuracy: 0.99 - ETA: 0s - loss: 0.0394 - accuracy: 0.99 - ETA: 0s - loss: 0.0460 - accuracy: 0.99 - ETA: 0s - loss: 0.0651 - accuracy: 0.99 - ETA: 0s - loss: 0.0595 - accuracy: 0.99 - ETA: 0s - loss: 0.0586 - accuracy: 0.99 - 1s 874us/step - loss: 0.0572 - accuracy: 0.9911 - val_loss: 2.3092 - val_accuracy: 0.6305\n",
+      "Epoch 38/50\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "786/786 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.96 - ETA: 0s - loss: 0.1452 - accuracy: 0.96 - ETA: 0s - loss: 0.1117 - accuracy: 0.97 - ETA: 0s - loss: 0.0923 - accuracy: 0.98 - ETA: 0s - loss: 0.0838 - accuracy: 0.98 - ETA: 0s - loss: 0.0759 - accuracy: 0.98 - ETA: 0s - loss: 0.0628 - accuracy: 0.98 - ETA: 0s - loss: 0.0589 - accuracy: 0.99 - ETA: 0s - loss: 0.0486 - accuracy: 0.99 - ETA: 0s - loss: 0.0536 - accuracy: 0.99 - ETA: 0s - loss: 0.0520 - accuracy: 0.99 - ETA: 0s - loss: 0.0514 - accuracy: 0.99 - ETA: 0s - loss: 0.0466 - accuracy: 0.99 - 1s 1ms/step - loss: 0.0465 - accuracy: 0.9924 - val_loss: 2.2731 - val_accuracy: 0.6267\n",
       "Epoch 39/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - ETA: 0s - loss: 0.0613 - accuracy: 0.99 - 0s 518us/step - loss: 0.0732 - accuracy: 0.9929 - val_loss: 3.5865 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.00 - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - ETA: 0s - loss: 0.0416 - accuracy: 0.99 - ETA: 0s - loss: 0.0357 - accuracy: 0.99 - ETA: 0s - loss: 0.0433 - accuracy: 0.99 - ETA: 0s - loss: 0.0405 - accuracy: 0.99 - ETA: 0s - loss: 0.0478 - accuracy: 0.99 - 0s 572us/step - loss: 0.0441 - accuracy: 0.9949 - val_loss: 2.3407 - val_accuracy: 0.6419\n",
       "Epoch 40/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 1.00 - 0s 257us/step - loss: 0.0709 - accuracy: 0.9858 - val_loss: 3.4783 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 1s - loss: 0.0873 - accuracy: 0.96 - ETA: 1s - loss: 0.0467 - accuracy: 0.98 - ETA: 1s - loss: 0.0367 - accuracy: 0.98 - ETA: 0s - loss: 0.0498 - accuracy: 0.98 - ETA: 0s - loss: 0.0450 - accuracy: 0.98 - ETA: 0s - loss: 0.0455 - accuracy: 0.98 - ETA: 0s - loss: 0.0466 - accuracy: 0.98 - 0s 586us/step - loss: 0.0466 - accuracy: 0.9873 - val_loss: 2.2532 - val_accuracy: 0.6362\n",
       "Epoch 41/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.2000 - accuracy: 0.96 - 0s 248us/step - loss: 0.0775 - accuracy: 0.9858 - val_loss: 3.5490 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.00 - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - ETA: 0s - loss: 0.0274 - accuracy: 0.99 - ETA: 0s - loss: 0.0241 - accuracy: 0.99 - ETA: 0s - loss: 0.0231 - accuracy: 0.99 - ETA: 0s - loss: 0.0456 - accuracy: 0.98 - ETA: 0s - loss: 0.0500 - accuracy: 0.98 - ETA: 0s - loss: 0.0538 - accuracy: 0.98 - ETA: 0s - loss: 0.0545 - accuracy: 0.98 - ETA: 0s - loss: 0.0562 - accuracy: 0.98 - ETA: 0s - loss: 0.0539 - accuracy: 0.98 - ETA: 0s - loss: 0.0586 - accuracy: 0.98 - ETA: 0s - loss: 0.0542 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0518 - accuracy: 0.9885 - val_loss: 2.4294 - val_accuracy: 0.6362\n",
       "Epoch 42/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 1.00 - ETA: 0s - loss: 0.0730 - accuracy: 0.98 - 0s 363us/step - loss: 0.0740 - accuracy: 0.9858 - val_loss: 3.8505 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - ETA: 0s - loss: 0.0137 - accuracy: 0.99 - ETA: 0s - loss: 0.0272 - accuracy: 0.99 - ETA: 0s - loss: 0.0358 - accuracy: 0.99 - ETA: 0s - loss: 0.0357 - accuracy: 0.99 - ETA: 0s - loss: 0.0408 - accuracy: 0.99 - ETA: 0s - loss: 0.0399 - accuracy: 0.99 - ETA: 0s - loss: 0.0387 - accuracy: 0.99 - 1s 1ms/step - loss: 0.0406 - accuracy: 0.9911 - val_loss: 2.5147 - val_accuracy: 0.6400\n",
       "Epoch 43/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 1.00 - ETA: 0s - loss: 0.0645 - accuracy: 0.98 - 0s 449us/step - loss: 0.0596 - accuracy: 0.9893 - val_loss: 3.6512 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.96 - ETA: 0s - loss: 0.0319 - accuracy: 0.98 - ETA: 0s - loss: 0.0468 - accuracy: 0.98 - ETA: 0s - loss: 0.0361 - accuracy: 0.99 - ETA: 0s - loss: 0.0341 - accuracy: 0.99 - ETA: 0s - loss: 0.0324 - accuracy: 0.99 - ETA: 0s - loss: 0.0299 - accuracy: 0.99 - ETA: 0s - loss: 0.0282 - accuracy: 0.99 - ETA: 0s - loss: 0.0286 - accuracy: 0.99 - ETA: 0s - loss: 0.0295 - accuracy: 0.99 - ETA: 0s - loss: 0.0281 - accuracy: 0.99 - ETA: 0s - loss: 0.0273 - accuracy: 0.99 - ETA: 0s - loss: 0.0272 - accuracy: 0.99 - ETA: 0s - loss: 0.0489 - accuracy: 0.98 - ETA: 0s - loss: 0.0458 - accuracy: 0.99 - ETA: 0s - loss: 0.0555 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0574 - accuracy: 0.9885 - val_loss: 2.7610 - val_accuracy: 0.6476\n",
       "Epoch 44/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.00 - 0s 252us/step - loss: 0.0542 - accuracy: 0.9929 - val_loss: 3.6441 - val_accuracy: 0.3670\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.96 - ETA: 0s - loss: 0.2291 - accuracy: 0.97 - ETA: 0s - loss: 0.2425 - accuracy: 0.96 - ETA: 0s - loss: 0.2335 - accuracy: 0.95 - ETA: 0s - loss: 0.2177 - accuracy: 0.95 - ETA: 0s - loss: 0.2162 - accuracy: 0.95 - ETA: 0s - loss: 0.2113 - accuracy: 0.95 - ETA: 0s - loss: 0.1950 - accuracy: 0.95 - ETA: 0s - loss: 0.1789 - accuracy: 0.95 - ETA: 0s - loss: 0.1916 - accuracy: 0.95 - ETA: 0s - loss: 0.1859 - accuracy: 0.95 - ETA: 0s - loss: 0.1806 - accuracy: 0.95 - ETA: 0s - loss: 0.1806 - accuracy: 0.95 - 1s 1ms/step - loss: 0.1768 - accuracy: 0.9567 - val_loss: 2.5142 - val_accuracy: 0.6324\n",
       "Epoch 45/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 1.00 - 0s 275us/step - loss: 0.0468 - accuracy: 0.9893 - val_loss: 3.6158 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.93 - ETA: 0s - loss: 0.0859 - accuracy: 0.96 - ETA: 0s - loss: 0.2650 - accuracy: 0.94 - ETA: 0s - loss: 0.2837 - accuracy: 0.91 - ETA: 0s - loss: 0.2675 - accuracy: 0.91 - ETA: 0s - loss: 0.2785 - accuracy: 0.90 - ETA: 0s - loss: 0.2833 - accuracy: 0.90 - ETA: 0s - loss: 0.3052 - accuracy: 0.90 - ETA: 0s - loss: 0.3537 - accuracy: 0.89 - ETA: 0s - loss: 0.3398 - accuracy: 0.90 - ETA: 0s - loss: 0.3300 - accuracy: 0.90 - ETA: 0s - loss: 0.3450 - accuracy: 0.89 - ETA: 0s - loss: 0.3817 - accuracy: 0.89 - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8919 - val_loss: 2.6439 - val_accuracy: 0.5600\n",
       "Epoch 46/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - ETA: 0s - loss: 0.0425 - accuracy: 0.99 - 0s 486us/step - loss: 0.0504 - accuracy: 0.9929 - val_loss: 3.6831 - val_accuracy: 0.3777\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.87 - ETA: 0s - loss: 0.4583 - accuracy: 0.84 - ETA: 1s - loss: 0.4942 - accuracy: 0.84 - ETA: 1s - loss: 0.4980 - accuracy: 0.85 - ETA: 1s - loss: 0.4560 - accuracy: 0.85 - ETA: 1s - loss: 0.4855 - accuracy: 0.84 - ETA: 0s - loss: 0.4693 - accuracy: 0.84 - ETA: 0s - loss: 0.4540 - accuracy: 0.85 - ETA: 0s - loss: 0.4513 - accuracy: 0.84 - ETA: 0s - loss: 0.4413 - accuracy: 0.85 - ETA: 0s - loss: 0.3994 - accuracy: 0.87 - ETA: 0s - loss: 0.3979 - accuracy: 0.87 - ETA: 0s - loss: 0.4044 - accuracy: 0.86 - ETA: 0s - loss: 0.4176 - accuracy: 0.86 - ETA: 0s - loss: 0.4183 - accuracy: 0.86 - ETA: 0s - loss: 0.4268 - accuracy: 0.85 - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8613 - val_loss: 2.5139 - val_accuracy: 0.6305\n",
       "Epoch 47/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - ETA: 0s - loss: 0.1069 - accuracy: 0.99 - 0s 357us/step - loss: 0.0945 - accuracy: 0.9929 - val_loss: 3.7183 - val_accuracy: 0.3830\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.93 - ETA: 0s - loss: 0.3164 - accuracy: 0.86 - ETA: 0s - loss: 0.2836 - accuracy: 0.88 - ETA: 0s - loss: 0.2541 - accuracy: 0.89 - ETA: 0s - loss: 0.2547 - accuracy: 0.90 - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - ETA: 0s - loss: 0.2437 - accuracy: 0.90 - ETA: 0s - loss: 0.2350 - accuracy: 0.91 - ETA: 0s - loss: 0.2551 - accuracy: 0.90 - ETA: 0s - loss: 0.2621 - accuracy: 0.91 - ETA: 0s - loss: 0.2678 - accuracy: 0.91 - ETA: 0s - loss: 0.2751 - accuracy: 0.90 - ETA: 0s - loss: 0.2708 - accuracy: 0.90 - ETA: 0s - loss: 0.2582 - accuracy: 0.91 - ETA: 0s - loss: 0.2552 - accuracy: 0.90 - ETA: 0s - loss: 0.2599 - accuracy: 0.90 - 1s 1ms/step - loss: 0.2561 - accuracy: 0.9084 - val_loss: 2.1917 - val_accuracy: 0.6152\n",
       "Epoch 48/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.00 - 0s 257us/step - loss: 0.0545 - accuracy: 0.9858 - val_loss: 3.7581 - val_accuracy: 0.3989\n",
-      "Epoch 49/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.00 - ETA: 0s - loss: 0.0681 - accuracy: 0.98 - 0s 358us/step - loss: 0.0656 - accuracy: 0.9822 - val_loss: 3.9350 - val_accuracy: 0.3723\n",
+      "786/786 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 1.00 - ETA: 0s - loss: 0.0876 - accuracy: 0.98 - ETA: 0s - loss: 0.1415 - accuracy: 0.98 - ETA: 0s - loss: 0.1787 - accuracy: 0.96 - ETA: 0s - loss: 0.1589 - accuracy: 0.96 - ETA: 0s - loss: 0.1545 - accuracy: 0.96 - ETA: 0s - loss: 0.1441 - accuracy: 0.96 - ETA: 0s - loss: 0.1376 - accuracy: 0.96 - ETA: 0s - loss: 0.1396 - accuracy: 0.96 - ETA: 0s - loss: 0.1461 - accuracy: 0.95 - ETA: 0s - loss: 0.1437 - accuracy: 0.95 - ETA: 0s - loss: 0.1396 - accuracy: 0.96 - ETA: 0s - loss: 0.1444 - accuracy: 0.96 - ETA: 0s - loss: 0.1401 - accuracy: 0.96 - ETA: 0s - loss: 0.1355 - accuracy: 0.96 - ETA: 0s - loss: 0.1471 - accuracy: 0.96 - ETA: 0s - loss: 0.1499 - accuracy: 0.96 - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9618 - val_loss: 2.4153 - val_accuracy: 0.6457\n",
+      "Epoch 49/50\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "786/786 [==============================] - ETA: 1s - loss: 0.0378 - accuracy: 1.00 - ETA: 0s - loss: 0.0667 - accuracy: 0.97 - ETA: 1s - loss: 0.0643 - accuracy: 0.98 - ETA: 1s - loss: 0.0751 - accuracy: 0.97 - ETA: 0s - loss: 0.0727 - accuracy: 0.97 - ETA: 0s - loss: 0.0708 - accuracy: 0.98 - ETA: 0s - loss: 0.0733 - accuracy: 0.98 - ETA: 0s - loss: 0.0693 - accuracy: 0.98 - ETA: 0s - loss: 0.0696 - accuracy: 0.98 - ETA: 0s - loss: 0.0692 - accuracy: 0.98 - ETA: 0s - loss: 0.0683 - accuracy: 0.98 - ETA: 0s - loss: 0.0698 - accuracy: 0.98 - ETA: 0s - loss: 0.0734 - accuracy: 0.97 - ETA: 0s - loss: 0.0728 - accuracy: 0.97 - 1s 1ms/step - loss: 0.0700 - accuracy: 0.9796 - val_loss: 2.2057 - val_accuracy: 0.5924\n",
       "Epoch 50/50\n",
-      "281/281 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - ETA: 0s - loss: 0.0738 - accuracy: 0.98 - 0s 555us/step - loss: 0.0570 - accuracy: 0.9893 - val_loss: 3.7512 - val_accuracy: 0.3670\n"
+      "786/786 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 1.00 - ETA: 0s - loss: 0.0591 - accuracy: 0.98 - ETA: 1s - loss: 0.0618 - accuracy: 0.97 - ETA: 1s - loss: 0.0543 - accuracy: 0.98 - ETA: 1s - loss: 0.0474 - accuracy: 0.98 - ETA: 1s - loss: 0.0686 - accuracy: 0.97 - ETA: 0s - loss: 0.0750 - accuracy: 0.97 - ETA: 0s - loss: 0.0904 - accuracy: 0.96 - ETA: 0s - loss: 0.0866 - accuracy: 0.96 - ETA: 0s - loss: 0.0925 - accuracy: 0.96 - ETA: 0s - loss: 0.0827 - accuracy: 0.97 - ETA: 0s - loss: 0.0781 - accuracy: 0.97 - ETA: 0s - loss: 0.0724 - accuracy: 0.97 - ETA: 0s - loss: 0.0737 - accuracy: 0.97 - ETA: 0s - loss: 0.0717 - accuracy: 0.97 - ETA: 0s - loss: 0.0782 - accuracy: 0.97 - 1s 1ms/step - loss: 0.0757 - accuracy: 0.9784 - val_loss: 2.3378 - val_accuracy: 0.6305\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<keras.callbacks.callbacks.History at 0x16ff36d33c8>"
+       "<keras.callbacks.callbacks.History at 0x2d6a4b89788>"
       ]
      },
-     "execution_count": 10,
+     "execution_count": 69,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
     "wandb.init()\n",
-    "\n",
+    "print(y_train_hot.shape)\n",
+    "print(labels.shape)\n",
+    "print(X_train.shape)\n",
     "# Train the CNN model\n",
     "#    X_train: Input data\n",
     "#    y_train_hot: Target data\n",
@@ -914,7 +358,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 70,
    "metadata": {},
    "outputs": [
     {
@@ -940,7 +384,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 71,
    "metadata": {
     "scrolled": true
    },
@@ -954,29 +398,29 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 72,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Model: \"sequential_1\"\n",
+      "Model: \"sequential_3\"\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
-      "conv2d_1 (Conv2D)            (None, 18, 9, 32)         320       \n",
+      "conv2d_3 (Conv2D)            (None, 18, 9, 32)         320       \n",
       "_________________________________________________________________\n",
-      "max_pooling2d_1 (MaxPooling2 (None, 9, 4, 32)          0         \n",
+      "max_pooling2d_3 (MaxPooling2 (None, 9, 4, 32)          0         \n",
       "_________________________________________________________________\n",
-      "flatten_1 (Flatten)          (None, 1152)              0         \n",
+      "flatten_3 (Flatten)          (None, 1152)              0         \n",
       "_________________________________________________________________\n",
-      "dense_1 (Dense)              (None, 128)               147584    \n",
+      "dense_5 (Dense)              (None, 128)               147584    \n",
       "_________________________________________________________________\n",
-      "dense_2 (Dense)              (None, 10)                1290      \n",
+      "dense_6 (Dense)              (None, 12)                1548      \n",
       "=================================================================\n",
-      "Total params: 149,194\n",
-      "Trainable params: 149,194\n",
+      "Total params: 149,452\n",
+      "Trainable params: 149,452\n",
       "Non-trainable params: 0\n",
       "_________________________________________________________________\n"
      ]
@@ -989,68 +433,556 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
+      "[0. 1.]\n",
+      "[ 0.0000000e+00  1.5258789e-05  0.0000000e+00 ...  3.3020020e-02\n",
+      "  1.2680054e-02 -8.7432861e-03]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.18899116\n",
+      "\n",
+      " car_horn :  0.01972581\n",
+      "\n",
+      " chainsaw :  0.00544587\n",
+      "\n",
+      " cow :  0.00003149\n",
+      "\n",
+      " engine :  0.33729187\n",
+      "\n",
+      " footsteps :  0.02647908\n",
+      "\n",
+      " hand_saw :  0.00124176\n",
+      "\n",
+      " hen :  0.00085190\n",
+      "\n",
+      " NO :  0.41615146\n",
+      "\n",
+      " rooster :  0.00352489\n",
+      "\n",
+      " siren :  0.00000906\n",
+      "\n",
+      " train :  0.00025569\n",
+      "GUESS: Nothing\n",
+      "[1. 2.]\n",
+      "[-0.03717041 -0.05769348 -0.06455994 ...  0.01766968  0.01895142\n",
+      "  0.01779175]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00000142\n",
+      "\n",
+      " car_horn :  0.00089724\n",
+      "\n",
+      " chainsaw :  0.00000457\n",
+      "\n",
+      " cow :  0.00000133\n",
+      "\n",
+      " engine :  0.01100342\n",
+      "\n",
+      " footsteps :  0.00000097\n",
+      "\n",
+      " hand_saw :  0.00000003\n",
+      "\n",
+      " hen :  0.00000144\n",
+      "\n",
+      " NO :  0.98807877\n",
+      "\n",
+      " rooster :  0.00000004\n",
+      "\n",
+      " siren :  0.00001074\n",
+      "\n",
+      " train :  0.00000001\n",
+      "\n",
+      "\n",
+      "GUESS:  NO\n",
+      "[2. 3.]\n",
+      "[ 0.02345276  0.02101135  0.01712036 ... -0.01161194 -0.0141449\n",
+      " -0.01431274]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.77033883\n",
+      "\n",
+      " car_horn :  0.00036573\n",
+      "\n",
+      " chainsaw :  0.00812833\n",
+      "\n",
+      " cow :  0.00000410\n",
+      "\n",
+      " engine :  0.08186522\n",
+      "\n",
+      " footsteps :  0.00062018\n",
+      "\n",
+      " hand_saw :  0.00007000\n",
+      "\n",
+      " hen :  0.00103445\n",
+      "\n",
+      " NO :  0.13652739\n",
+      "\n",
+      " rooster :  0.00090429\n",
+      "\n",
+      " siren :  0.00006481\n",
+      "\n",
+      " train :  0.00007663\n",
+      "\n",
+      "\n",
+      "GUESS:  bus\n",
+      "[3. 4.]\n",
+      "[-0.01583862 -0.01066589 -0.00762939 ... -0.0377655  -0.03556824\n",
+      " -0.02685547]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00869095\n",
+      "\n",
+      " car_horn :  0.03988067\n",
+      "\n",
+      " chainsaw :  0.00014766\n",
+      "\n",
+      " cow :  0.00000277\n",
+      "\n",
+      " engine :  0.07430156\n",
+      "\n",
+      " footsteps :  0.00007438\n",
+      "\n",
+      " hand_saw :  0.00000607\n",
+      "\n",
+      " hen :  0.00005607\n",
+      "\n",
+      " NO :  0.85636342\n",
+      "\n",
+      " rooster :  0.00011844\n",
+      "\n",
+      " siren :  0.00084657\n",
+      "\n",
+      " train :  0.01951146\n",
+      "\n",
+      "\n",
+      "GUESS:  NO\n",
+      "[4. 5.]\n",
+      "[-0.02836609 -0.02510071 -0.02012634 ...  0.0138855  -0.00386047\n",
+      " -0.00904846]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00007984\n",
+      "\n",
+      " car_horn :  0.00000050\n",
+      "\n",
+      " chainsaw :  0.00007196\n",
+      "\n",
+      " cow :  0.00000000\n",
+      "\n",
+      " engine :  0.00061454\n",
+      "\n",
+      " footsteps :  0.00000303\n",
+      "\n",
+      " hand_saw :  0.00000029\n",
+      "\n",
+      " hen :  0.00000502\n",
+      "\n",
+      " NO :  0.99921131\n",
+      "\n",
+      " rooster :  0.00000000\n",
+      "\n",
+      " siren :  0.00001237\n",
+      "\n",
+      " train :  0.00000118\n",
+      "\n",
+      "\n",
+      "GUESS:  NO\n",
+      "[5. 6.]\n",
+      "[-0.00526428  0.00822449  0.01951599 ...  0.02729797  0.02156067\n",
+      "  0.01234436]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00060453\n",
+      "\n",
+      " car_horn :  0.00053406\n",
+      "\n",
+      " chainsaw :  0.00185106\n",
+      "\n",
+      " cow :  0.00002060\n",
+      "\n",
+      " engine :  0.56115299\n",
+      "\n",
+      " footsteps :  0.00013776\n",
+      "\n",
+      " hand_saw :  0.00001533\n",
+      "\n",
+      " hen :  0.00019742\n",
+      "\n",
+      " NO :  0.43452746\n",
+      "\n",
+      " rooster :  0.00014421\n",
+      "\n",
+      " siren :  0.00080162\n",
+      "\n",
+      " train :  0.00001300\n",
+      "\n",
+      "\n",
+      "GUESS:  engine\n",
+      "[6. 7.]\n",
+      "[ 0.00544739  0.00053406  0.00970459 ... -0.02848816 -0.01611328\n",
+      " -0.01091003]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00370212\n",
+      "\n",
+      " car_horn :  0.00009890\n",
+      "\n",
+      " chainsaw :  0.08339411\n",
+      "\n",
+      " cow :  0.00000520\n",
+      "\n",
+      " engine :  0.89548981\n",
+      "\n",
+      " footsteps :  0.00230497\n",
+      "\n",
+      " hand_saw :  0.00003558\n",
+      "\n",
+      " hen :  0.00016270\n",
+      "\n",
+      " NO :  0.01472530\n",
+      "\n",
+      " rooster :  0.00008010\n",
+      "\n",
+      " siren :  0.00000099\n",
+      "\n",
+      " train :  0.00000022\n",
+      "\n",
+      "\n",
+      "GUESS:  engine\n",
+      "[7. 8.]\n",
+      "[-0.0177002  -0.02372742 -0.02700806 ... -0.04304504 -0.04063416\n",
+      " -0.03363037]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00060445\n",
+      "\n",
+      " car_horn :  0.00016385\n",
+      "\n",
+      " chainsaw :  0.00068215\n",
+      "\n",
+      " cow :  0.00002643\n",
+      "\n",
+      " engine :  0.03192073\n",
+      "\n",
+      " footsteps :  0.00251030\n",
+      "\n",
+      " hand_saw :  0.00036416\n",
+      "\n",
+      " hen :  0.00041075\n",
+      "\n",
+      " NO :  0.96194029\n",
+      "\n",
+      " rooster :  0.00000763\n",
+      "\n",
+      " siren :  0.00136895\n",
+      "\n",
+      " train :  0.00000036\n",
+      "\n",
+      "\n",
+      "GUESS:  NO\n",
+      "[8. 9.]\n",
+      "[-0.01539612 -0.00108337  0.00718689 ...  0.01161194  0.01818848\n",
+      "  0.02700806]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00000633\n",
+      "\n",
+      " car_horn :  0.00022728\n",
+      "\n",
+      " chainsaw :  0.80613172\n",
+      "\n",
+      " cow :  0.00049074\n",
+      "\n",
+      " engine :  0.00377018\n",
+      "\n",
+      " footsteps :  0.00004836\n",
+      "\n",
+      " hand_saw :  0.00123845\n",
+      "\n",
+      " hen :  0.00000112\n",
+      "\n",
+      " NO :  0.18760407\n",
+      "\n",
+      " rooster :  0.00004394\n",
+      "\n",
+      " siren :  0.00043786\n",
+      "\n",
+      " train :  0.00000002\n",
+      "\n",
+      "\n",
+      "GUESS:  chainsaw\n",
+      "[ 9. 10.]\n",
+      "[ 0.03549194  0.04856873  0.05519104 ... -0.02171326 -0.03634644\n",
+      " -0.03912354]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00002877\n",
+      "\n",
+      " car_horn :  0.00020951\n",
+      "\n",
+      " chainsaw :  0.01863052\n",
+      "\n",
+      " cow :  0.00000018\n",
+      "\n",
+      " engine :  0.55732745\n",
+      "\n",
+      " footsteps :  0.00001145\n",
+      "\n",
+      " hand_saw :  0.00000283\n",
+      "\n",
+      " hen :  0.00000034\n",
+      "\n",
+      " NO :  0.42375427\n",
+      "\n",
+      " rooster :  0.00000017\n",
+      "\n",
+      " siren :  0.00003454\n",
+      "\n",
+      " train :  0.00000000\n",
+      "\n",
+      "\n",
+      "GUESS:  engine\n",
+      "[10. 11.]\n",
+      "[-0.02934265 -0.0115509   0.00445557 ... -0.03616333 -0.03759766\n",
+      " -0.0304718 ]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.00050059\n",
+      "\n",
+      " car_horn :  0.00011994\n",
+      "\n",
+      " chainsaw :  0.54708499\n",
+      "\n",
+      " cow :  0.00257223\n",
+      "\n",
+      " engine :  0.38954812\n",
+      "\n",
+      " footsteps :  0.00000514\n",
+      "\n",
+      " hand_saw :  0.00000613\n",
+      "\n",
+      " hen :  0.00000702\n",
+      "\n",
+      " NO :  0.00352609\n",
+      "\n",
+      " rooster :  0.05654177\n",
+      "\n",
+      " siren :  0.00008773\n",
+      "\n",
+      " train :  0.00000018\n",
+      "\n",
+      "\n",
+      "GUESS:  chainsaw\n",
+      "[11. 12.]\n",
+      "[-0.03358459 -0.03901672 -0.03933716 ... -0.02337646 -0.02124023\n",
+      " -0.02107239]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.04605614\n",
+      "\n",
+      " car_horn :  0.00087326\n",
+      "\n",
+      " chainsaw :  0.00321500\n",
+      "\n",
+      " cow :  0.00002840\n",
+      "\n",
+      " engine :  0.00758816\n",
+      "\n",
+      " footsteps :  0.00078170\n",
+      "\n",
+      " hand_saw :  0.00133857\n",
+      "\n",
+      " hen :  0.00118017\n",
+      "\n",
+      " NO :  0.91494197\n",
+      "\n",
+      " rooster :  0.00470826\n",
+      "\n",
+      " siren :  0.00029028\n",
+      "\n",
+      " train :  0.01899806\n",
+      "\n",
+      "\n",
+      "GUESS:  NO\n",
+      "[12. 13.]\n",
+      "[-0.00846863  0.00444031  0.00852966 ... -0.00604248 -0.00845337\n",
+      " -0.00497437]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
+      "\n",
+      " bus :  0.73755270\n",
+      "\n",
+      " car_horn :  0.00243227\n",
+      "\n",
+      " chainsaw :  0.01868698\n",
+      "\n",
+      " cow :  0.00015510\n",
+      "\n",
+      " engine :  0.17819746\n",
+      "\n",
+      " footsteps :  0.00773424\n",
+      "\n",
+      " hand_saw :  0.00029096\n",
+      "\n",
+      " hen :  0.00539754\n",
+      "\n",
+      " NO :  0.01902335\n",
+      "\n",
+      " rooster :  0.02820140\n",
+      "\n",
+      " siren :  0.00025591\n",
+      "\n",
+      " train :  0.00207221\n",
+      "\n",
+      "\n",
+      "GUESS:  bus\n",
+      "[13. 14.]\n",
+      "[-0.00427246 -0.00718689 -0.00811768 ... -0.01966858 -0.01296997\n",
+      " -0.01628113]\n",
+      "(20, 11)\n",
       "PREDICTED VALUES\n",
       "\n",
-      " bus :  0.00002306\n",
+      " bus :  0.28526244\n",
+      "\n",
+      " car_horn :  0.00111227\n",
       "\n",
-      " car_horn :  0.98330659\n",
+      " chainsaw :  0.00329474\n",
       "\n",
-      " chainsaw :  0.00023836\n",
+      " cow :  0.00003080\n",
       "\n",
-      " cow :  0.00675107\n",
+      " engine :  0.01268300\n",
       "\n",
-      " engine :  0.00007791\n",
+      " footsteps :  0.00087293\n",
       "\n",
-      " footsteps :  0.00000021\n",
+      " hand_saw :  0.00017666\n",
       "\n",
-      " hand_saw :  0.00959078\n",
+      " hen :  0.00458841\n",
       "\n",
-      " hen :  0.00000000\n",
+      " NO :  0.63280058\n",
       "\n",
-      " rooster :  0.00001190\n",
+      " rooster :  0.00466741\n",
       "\n",
-      " siren :  0.00000016\n",
+      " siren :  0.00238588\n",
+      "\n",
+      " train :  0.05212500\n",
+      "\n",
+      "\n",
+      "GUESS:  NO\n",
+      "[14. 15.]\n",
+      "[-0.02262878 -0.01573181 -0.00117493 ... -0.08956909 -0.0695343\n",
+      " -0.04067993]\n",
+      "(20, 11)\n",
+      "PREDICTED VALUES\n",
       "\n",
+      " bus :  0.00322473\n",
       "\n",
-      "GUESS:  car_horn\n"
+      " car_horn :  0.00016304\n",
+      "\n",
+      " chainsaw :  0.06885776\n",
+      "\n",
+      " cow :  0.00002457\n",
+      "\n",
+      " engine :  0.92677271\n",
+      "\n",
+      " footsteps :  0.00003485\n",
+      "\n",
+      " hand_saw :  0.00002373\n",
+      "\n",
+      " hen :  0.00000450\n",
+      "\n",
+      " NO :  0.00084113\n",
+      "\n",
+      " rooster :  0.00004370\n",
+      "\n",
+      " siren :  0.00000639\n",
+      "\n",
+      " train :  0.00000296"
      ]
     }
    ],
    "source": [
     "## Running the model\n",
     "\n",
-    "# Convert wav to MFCC\n",
-    "prediction_data = wav2mfcc('./prediction/cow.wav')\n",
+    "n_mfcc = 20\n",
+    "max_len = 11\n",
+    "# convert file to wav2mfcc\n",
+    "# Mel-frequency cepstral coefficients\n",
+    "file_path = \"./prediction/nature_sc.wav\"\n",
+    "big_wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
+    "#print(wave.shape, sr)\n",
+    "\n",
+    "classification = []\n",
+    "\n",
+    "for index in range( int(big_wave.shape[0] / sr) ) :\n",
+    "    sec_to_trim = np.array( [ float(index), float(index+1) ] )\n",
+    "    print(sec_to_trim)\n",
+    "    sec_to_trim = np.ceil( sec_to_trim * sr )\n",
+    "\n",
+    "    wave = big_wave[int(sec_to_trim[0]) : int(sec_to_trim[1])]\n",
+    "    print(wave)\n",
+    "\n",
+    "    wave = np.asfortranarray(wave[::3])\n",
+    "    mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)\n",
+    "\n",
+    "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
+    "    if (max_len > mfcc.shape[1]):\n",
+    "        pad_width = max_len - mfcc.shape[1]\n",
+    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
+    "\n",
+    "    # Else cutoff the remaining parts\n",
+    "    else:\n",
+    "        mfcc = mfcc[:, :max_len]\n",
+    "\n",
+    "    # Convert wav to MFCC\n",
+    "    prediction_data = wav2mfcc('./prediction/nature_sc.wav')\n",
+    "    prediction_data = mfcc\n",
+    "    print(prediction_data.shape)\n",
+    "    #print(wav2mfcc())\n",
+    "    # Reshape to 4 dimensions\n",
+    "    prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
+    "    prediction_data = prediction_data.reshape(1, 20, config.max_len, channels)\n",
     "\n",
-    "# Reshape to 4 dimensions\n",
-    "prediction_data = prediction_data.reshape(1, config.buckets, config.max_len, channels)\n",
+    "    # Run the model on the inputted file\n",
+    "    predicted = loaded_model.predict(prediction_data)\n",
     "\n",
-    "# Run the model on the inputted file\n",
-    "predicted = loaded_model.predict(prediction_data)\n",
+    "    # Output the prediction values for each class\n",
+    "    print ('PREDICTED VALUES')\n",
+    "    labels_indices = range(len(labels))\n",
+    "    max_value = 0\n",
+    "    max_value_index = 0\n",
+    "    for index in labels_indices:\n",
+    "        print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
+    "        if predicted[0,index] > max_value:\n",
+    "            max_value_index = index\n",
+    "            max_value = predicted[0,index]\n",
     "\n",
-    "# Output the prediction values for each class\n",
-    "print ('PREDICTED VALUES')\n",
-    "labels_indices = range(len(labels))\n",
-    "max_value = 0\n",
-    "max_value_index = 0\n",
-    "for index in labels_indices:\n",
-    "    print('\\n', labels[index], \": \", '%.08f' % predicted[0,index])\n",
-    "    if predicted[0,index] > max_value:\n",
-    "        max_value_index = index\n",
-    "        max_value = predicted[0,index]\n",
+    "    # Output the prediction\n",
+    "    if max_value < 0.5:\n",
+    "        print(\"GUESS: Nothing\")\n",
+    "        classification.append( { \"class\" : \"Nothing\", \"timestamp\" : index } )\n",
+    "    else:\n",
+    "        print('\\n\\nGUESS: ', labels[max_value_index])\n",
+    "        classification.append( { \"class\" : labels[max_value_index], \"timestamp\" : index } )\n",
     "\n",
-    "# Output the prediction\n",
-    "if max_value < 0.5:\n",
-    "    print(\"GUESS: Nothing\")\n",
-    "else:\n",
-    "    print('\\n\\nGUESS: ', labels[max_value_index])"
+    "print(classification)"
    ]
   },
   {
@@ -1077,7 +1009,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.8.2"
+   "version": "3.7.4"
   }
  },
  "nbformat": 4,
diff --git a/ant-cnn/preprocess.py b/ant-cnn/preprocess.py
index e5fe230..9b18914 100644
--- a/ant-cnn/preprocess.py
+++ b/ant-cnn/preprocess.py
@@ -18,7 +18,7 @@ def get_labels(path=DATA_PATH):
 
 # convert file to wav2mfcc
 # Mel-frequency cepstral coefficients
-def wav2mfcc(file_path, n_mfcc=20, max_len=11):
+def wav2mfcc(file_path, n_mfcc=30, max_len=11):
     wave, sr = librosa.load(file_path, mono=True, sr=None)
     wave = np.asfortranarray(wave[::3])
     mfcc = librosa.feature.mfcc(wave, sr=16000, n_mfcc=n_mfcc)
